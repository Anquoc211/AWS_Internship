<!doctype html><html lang=en class="js csstransforms3d"><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.134.3"><meta name=description content><meta name=author content="thienlh@thienlu.com"><link rel=icon href=https://anquoc211.github.io/AWS_Internship/images/favicon.png type=image/png><title>Blog 2 :: Internship Report</title>
<link href=https://anquoc211.github.io/AWS_Internship/css/nucleus.css?1765072081 rel=stylesheet><link href=https://anquoc211.github.io/AWS_Internship/css/fontawesome-all.min.css?1765072081 rel=stylesheet><link href=https://anquoc211.github.io/AWS_Internship/css/hybrid.css?1765072081 rel=stylesheet><link href=https://anquoc211.github.io/AWS_Internship/css/featherlight.min.css?1765072081 rel=stylesheet><link href=https://anquoc211.github.io/AWS_Internship/css/perfect-scrollbar.min.css?1765072081 rel=stylesheet><link href=https://anquoc211.github.io/AWS_Internship/css/auto-complete.css?1765072081 rel=stylesheet><link href=https://anquoc211.github.io/AWS_Internship/css/atom-one-dark-reasonable.css?1765072081 rel=stylesheet><link href=https://anquoc211.github.io/AWS_Internship/css/theme.css?1765072081 rel=stylesheet><link href=https://anquoc211.github.io/AWS_Internship/css/hugo-theme.css?1765072081 rel=stylesheet><link href=https://anquoc211.github.io/AWS_Internship/css/theme-workshop.css?1765072081 rel=stylesheet><script src=https://anquoc211.github.io/AWS_Internship/js/jquery-3.3.1.min.js?1765072081></script><style>:root #header+#content>#left>#rlblock_left{display:none!important}</style></head><body data-url=https://anquoc211.github.io/AWS_Internship/3-blogstranslated/3.2-blog2/><nav id=sidebar class=showVisitedLinks><div id=header-wrapper><div id=header><a id=logo href=https://anquoc211.github.io/AWS_Internship/><svg id="Layer_1" data-name="Layer 1" viewBox="0 0 60 30" width="30%"><defs><style>.cls-1{fill:#fff}.cls-2{fill:#f90;fill-rule:evenodd}</style></defs><title>AWS-Logo_White-Color</title><path class="cls-1" d="M14.09 10.85a4.7 4.7.0 00.19 1.48 7.73 7.73.0 00.54 1.19.77.77.0 01.12.38.64.64.0 01-.32.49l-1 .7a.83.83.0 01-.44.15.69.69.0 01-.49-.23 3.8 3.8.0 01-.6-.77q-.25-.42-.51-1a6.14 6.14.0 01-4.89 2.3 4.54 4.54.0 01-3.32-1.19 4.27 4.27.0 01-1.22-3.2 4.28 4.28.0 011.46-3.4A6.06 6.06.0 017.69 6.46a12.47 12.47.0 011.76.13q.92.13 1.91.36V5.73a3.65 3.65.0 00-.79-2.66A3.81 3.81.0 007.86 2.3a7.71 7.71.0 00-1.79.22 12.78 12.78.0 00-1.79.57 4.55 4.55.0 01-.58.22h-.26q-.35.0-.35-.52V2a1.09 1.09.0 01.12-.58 1.2 1.2.0 01.47-.35A10.88 10.88.0 015.77.32 10.19 10.19.0 018.36.0a6 6 0 014.35 1.35 5.49 5.49.0 011.38 4.09zM7.34 13.38a5.36 5.36.0 001.72-.31A3.63 3.63.0 0010.63 12 2.62 2.62.0 0011.19 11a5.63 5.63.0 00.16-1.44v-.7a14.35 14.35.0 00-1.53-.28 12.37 12.37.0 00-1.56-.1 3.84 3.84.0 00-2.47.67A2.34 2.34.0 005 11a2.35 2.35.0 00.61 1.76A2.4 2.4.0 007.34 13.38zm13.35 1.8a1 1 0 01-.64-.16 1.3 1.3.0 01-.35-.65L15.81 1.51a3 3 0 01-.15-.67.36.36.0 01.41-.41H17.7a1 1 0 01.65.16 1.4 1.4.0 01.33.65l2.79 11 2.59-11A1.17 1.17.0 0124.39.6a1.1 1.1.0 01.67-.16H26.4a1.1 1.1.0 01.67.16 1.17 1.17.0 01.32.65L30 12.39 32.88 1.25A1.39 1.39.0 0133.22.6a1 1 0 01.65-.16h1.54a.36.36.0 01.41.41 1.36 1.36.0 010 .26 3.64 3.64.0 01-.12.41l-4 12.86a1.3 1.3.0 01-.35.65 1 1 0 01-.64.16H29.25a1 1 0 01-.67-.17 1.26 1.26.0 01-.32-.67L25.67 3.64l-2.56 10.7a1.26 1.26.0 01-.32.67 1 1 0 01-.67.17zm21.36.44a11.28 11.28.0 01-2.56-.29 7.44 7.44.0 01-1.92-.67 1 1 0 01-.61-.93v-.84q0-.52.38-.52a.9.9.0 01.31.06l.42.17a8.77 8.77.0 001.83.58 9.78 9.78.0 002 .2 4.48 4.48.0 002.43-.55 1.76 1.76.0 00.86-1.57 1.61 1.61.0 00-.45-1.16A4.29 4.29.0 0043 9.22l-2.41-.76A5.15 5.15.0 0138 6.78a3.94 3.94.0 01-.83-2.41 3.7 3.7.0 01.45-1.85 4.47 4.47.0 011.19-1.37 5.27 5.27.0 011.7-.86A7.4 7.4.0 0142.6.0a8.87 8.87.0 011.12.07q.57.07 1.08.19t.95.26a4.27 4.27.0 01.7.29 1.59 1.59.0 01.49.41.94.94.0 01.15.55v.79q0 .52-.38.52a1.76 1.76.0 01-.64-.2 7.74 7.74.0 00-3.2-.64 4.37 4.37.0 00-2.21.47 1.6 1.6.0 00-.79 1.48 1.58 1.58.0 00.49 1.18 4.94 4.94.0 001.83.92L44.55 7a5.08 5.08.0 012.57 1.6A3.76 3.76.0 0147.9 11a4.21 4.21.0 01-.44 1.93 4.4 4.4.0 01-1.21 1.47 5.43 5.43.0 01-1.85.93A8.25 8.25.0 0142.05 15.62z"/><path class="cls-2" d="M45.19 23.81C39.72 27.85 31.78 30 25 30A36.64 36.64.0 01.22 20.57c-.51-.46-.06-1.09.56-.74A49.78 49.78.0 0025.53 26.4 49.23 49.23.0 0044.4 22.53C45.32 22.14 46.1 23.14 45.19 23.81z"/><path class="cls-2" d="M47.47 21.21c-.7-.9-4.63-.42-6.39-.21-.53.06-.62-.4-.14-.74 3.13-2.2 8.27-1.57 8.86-.83s-.16 5.89-3.09 8.35c-.45.38-.88.18-.68-.32C46.69 25.8 48.17 22.11 47.47 21.21z"/></svg></a></div><div class=searchbox><label for=search-by><i class="fas fa-search"></i></label>
<input data-search-input id=search-by type=search placeholder=Search...>
<span data-search-clear><i class="fas fa-times"></i></span></div><script type=text/javascript src=https://anquoc211.github.io/AWS_Internship/js/lunr.min.js?1765072081></script><script type=text/javascript src=https://anquoc211.github.io/AWS_Internship/js/auto-complete.js?1765072081></script><script type=text/javascript>var baseurl="https://anquoc211.github.io/AWS_Internship/"</script><script type=text/javascript src=https://anquoc211.github.io/AWS_Internship/js/search.js?1765072081></script></div><div class=highlightable><ul class=topics><li data-nav-id=/1-worklog/ title="Worklog - AWS Learning Journey" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/><b>1. </b>Worklog - AWS Learning Journey
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/1-worklog/1.1-week1/ title="Week 1 - Cloud Computing Fundamentals" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.1-week1/><b>1.1. </b>Week 1 - Cloud Computing Fundamentals
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/1-worklog/1.1-week1/1.1.1-day01-2025-09-08/ title="Day 01 - Introduction to Cloud Computing" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.1-week1/1.1.1-day01-2025-09-08/><b>1.1.1. </b>Day 01 - Introduction to Cloud Computing
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.1-week1/1.1.2-day02-2025-09-09/ title="Day 02 - AWS Global Infrastructure" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.1-week1/1.1.2-day02-2025-09-09/><b>1.1.2. </b>Day 02 - AWS Global Infrastructure
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.1-week1/1.1.3-day03-2025-09-10/ title="Day 03 - AWS Management Tools" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.1-week1/1.1.3-day03-2025-09-10/><b>1.1.3. </b>Day 03 - AWS Management Tools
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.1-week1/1.1.4-day04-2025-09-11/ title="Day 04 - Cost Optimization on AWS" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.1-week1/1.1.4-day04-2025-09-11/><b>1.1.4. </b>Day 04 - Cost Optimization on AWS
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.1-week1/1.1.5-day05-2025-09-12/ title="Day 05 - AWS Well-Architected Framework" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.1-week1/1.1.5-day05-2025-09-12/><b>1.1.5. </b>Day 05 - AWS Well-Architected Framework
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/1-worklog/1.2-week2/ title="Week 2 - AWS Networking Services" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.2-week2/><b>1.2. </b>Week 2 - AWS Networking Services
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/1-worklog/1.2-week2/1.2.1-day06-2025-09-15/ title="Day 06 - Amazon VPC Fundamentals" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.2-week2/1.2.1-day06-2025-09-15/><b>1.2.1. </b>Day 06 - Amazon VPC Fundamentals
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.2-week2/1.2.2-day07-2025-09-16/ title="Day 07 - VPC Routing & Network Interfaces" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.2-week2/1.2.2-day07-2025-09-16/><b>1.2.2. </b>Day 07 - VPC Routing & Network Interfaces
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.2-week2/1.2.3-day08-2025-09-17/ title="Day 08 - VPC Security & Flow Logs" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.2-week2/1.2.3-day08-2025-09-17/><b>1.2.3. </b>Day 08 - VPC Security & Flow Logs
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.2-week2/1.2.4-day09-2025-09-18/ title="Day 09 - VPC Connectivity & Load Balancing" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.2-week2/1.2.4-day09-2025-09-18/><b>1.2.4. </b>Day 09 - VPC Connectivity & Load Balancing
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.2-week2/1.2.5-day10-2025-09-19/ title="Day 10 - Elastic Load Balancing" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.2-week2/1.2.5-day10-2025-09-19/><b>1.2.5. </b>Day 10 - Elastic Load Balancing
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/1-worklog/1.3-week3/ title="Week 3 - AWS Compute Services" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.3-week3/><b>1.3. </b>Week 3 - AWS Compute Services
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/1-worklog/1.3-week3/1.3.1-day11-2025-09-22/ title="Day 11 - Amazon EC2 Fundamentals" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.3-week3/1.3.1-day11-2025-09-22/><b>1.3.1. </b>Day 11 - Amazon EC2 Fundamentals
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.3-week3/1.3.2-day12-2025-09-23/ title="Day 12 - EC2 Storage & Backup" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.3-week3/1.3.2-day12-2025-09-23/><b>1.3.2. </b>Day 12 - EC2 Storage & Backup
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.3-week3/1.3.3-day13-2025-09-24/ title="Day 13 - Instance Store & User Data" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.3-week3/1.3.3-day13-2025-09-24/><b>1.3.3. </b>Day 13 - Instance Store & User Data
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.3-week3/1.3.4-day14-2025-09-25/ title="Day 14 - EC2 Auto Scaling" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.3-week3/1.3.4-day14-2025-09-25/><b>1.3.4. </b>Day 14 - EC2 Auto Scaling
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.3-week3/1.3.5-day15-2025-09-26/ title="Day 15 - Lightsail, EFS & FSx" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.3-week3/1.3.5-day15-2025-09-26/><b>1.3.5. </b>Day 15 - Lightsail, EFS & FSx
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/1-worklog/1.4-week4/ title="Week 4 - AWS Storage Services" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.4-week4/><b>1.4. </b>Week 4 - AWS Storage Services
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/1-worklog/1.4-week4/1.4.1-day16-2025-09-29/ title="Day 16 - Amazon S3 Fundamentals" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.4-week4/1.4.1-day16-2025-09-29/><b>1.4.1. </b>Day 16 - Amazon S3 Fundamentals
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.4-week4/1.4.2-day17-2025-09-30/ title="Day 17 - S3 Advanced Features" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.4-week4/1.4.2-day17-2025-09-30/><b>1.4.2. </b>Day 17 - S3 Advanced Features
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.4-week4/1.4.3-day18-2025-10-01/ title="Day 18 - AWS Snow Family & Hybrid Storage" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.4-week4/1.4.3-day18-2025-10-01/><b>1.4.3. </b>Day 18 - AWS Snow Family & Hybrid Storage
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.4-week4/1.4.4-day19-2025-10-02/ title="Day 19 - Disaster Recovery on AWS" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.4-week4/1.4.4-day19-2025-10-02/><b>1.4.4. </b>Day 19 - Disaster Recovery on AWS
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.4-week4/1.4.5-day20-2025-10-03/ title="Day 20 - AWS Backup & FSx" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.4-week4/1.4.5-day20-2025-10-03/><b>1.4.5. </b>Day 20 - AWS Backup & FSx
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/1-worklog/1.5-week5/ title="Week 5 - AWS Security & Identity" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.5-week5/><b>1.5. </b>Week 5 - AWS Security & Identity
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/1-worklog/1.5-week5/1.5.1-day21-2025-10-06/ title="Day 21 - Shared Responsibility & IAM Basics" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.5-week5/1.5.1-day21-2025-10-06/><b>1.5.1. </b>Day 21 - Shared Responsibility & IAM Basics
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.5-week5/1.5.2-day22-2025-10-07/ title="Day 22 - IAM Policies & Roles" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.5-week5/1.5.2-day22-2025-10-07/><b>1.5.2. </b>Day 22 - IAM Policies & Roles
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.5-week5/1.5.3-day23-2025-10-08/ title="Day 23 - Amazon Cognito & Organizations" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.5-week5/1.5.3-day23-2025-10-08/><b>1.5.3. </b>Day 23 - Amazon Cognito & Organizations
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.5-week5/1.5.4-day24-2025-10-09/ title="Day 24 - SCPs, Identity Center & KMS" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.5-week5/1.5.4-day24-2025-10-09/><b>1.5.4. </b>Day 24 - SCPs, Identity Center & KMS
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.5-week5/1.5.5-day25-2025-10-10/ title="Day 25 - AWS Security Hub & Automation" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.5-week5/1.5.5-day25-2025-10-10/><b>1.5.5. </b>Day 25 - AWS Security Hub & Automation
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/1-worklog/1.6-week6/ title="Week 6 - AWS Database Services" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.6-week6/><b>1.6. </b>Week 6 - AWS Database Services
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/1-worklog/1.6-week6/1.6.1-day26-2025-10-13/ title="Day 26 - Database Fundamentals" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.6-week6/1.6.1-day26-2025-10-13/><b>1.6.1. </b>Day 26 - Database Fundamentals
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.6-week6/1.6.2-day27-2025-10-14/ title="Day 27 - Amazon RDS & Aurora" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.6-week6/1.6.2-day27-2025-10-14/><b>1.6.2. </b>Day 27 - Amazon RDS & Aurora
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.6-week6/1.6.3-day28-2025-10-15/ title="Day 28 - Amazon Redshift" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.6-week6/1.6.3-day28-2025-10-15/><b>1.6.3. </b>Day 28 - Amazon Redshift
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.6-week6/1.6.4-day29-2025-10-16/ title="Day 29 - Amazon ElastiCache" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.6-week6/1.6.4-day29-2025-10-16/><b>1.6.4. </b>Day 29 - Amazon ElastiCache
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.6-week6/1.6.5-day30-2025-10-17/ title="Day 30 - Database Migration & Best Practices" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.6-week6/1.6.5-day30-2025-10-17/><b>1.6.5. </b>Day 30 - Database Migration & Best Practices
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/1-worklog/1.7-week7/ title="Week 7 - Vertical Slice Delivery" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.7-week7/><b>1.7. </b>Week 7 - Vertical Slice Delivery
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/1-worklog/1.7-week7/1.7.1-day31-2025-10-20/ title="Day 31 - Vertical Slice Kickoff" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.7-week7/1.7.1-day31-2025-10-20/><b>1.7.1. </b>Day 31 - Vertical Slice Kickoff
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.7-week7/1.7.2-day32-2025-10-21/ title="Day 32 - Contract-First & Mocking" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.7-week7/1.7.2-day32-2025-10-21/><b>1.7.2. </b>Day 32 - Contract-First & Mocking
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.7-week7/1.7.3-day33-2025-10-22/ title="Day 33 - Next.js App Router" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.7-week7/1.7.3-day33-2025-10-22/><b>1.7.3. </b>Day 33 - Next.js App Router
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.7-week7/1.7.4-day34-2025-10-23/ title="Day 34 - FastAPI Clean Architecture" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.7-week7/1.7.4-day34-2025-10-23/><b>1.7.4. </b>Day 34 - FastAPI Clean Architecture
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.7-week7/1.7.5-day35-2025-10-24/ title="Day 35 - Contract Testing & Retrospective" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.7-week7/1.7.5-day35-2025-10-24/><b>1.7.5. </b>Day 35 - Contract Testing & Retrospective
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/1-worklog/1.8-week8/ title="Week 8 - Learning Natural Language Processing" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.8-week8/><b>1.8. </b>Week 8 - Learning Natural Language Processing
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/1-worklog/1.8-week8/1.8.1-day36-2025-10-27/ title="Day 36 - Introduction to NLP & Text Preprocessing" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.8-week8/1.8.1-day36-2025-10-27/><b>1.8.1. </b>Day 36 - Introduction to NLP & Text Preprocessing
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.8-week8/1.8.2-day37-2025-10-28/ title="Day 37 - Advanced Text Preprocessing" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.8-week8/1.8.2-day37-2025-10-28/><b>1.8.2. </b>Day 37 - Advanced Text Preprocessing
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.8-week8/1.8.3-day38-2025-10-29/ title="Day 38 - Text Analysis & Sentiment Analysis" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.8-week8/1.8.3-day38-2025-10-29/><b>1.8.3. </b>Day 38 - Text Analysis & Sentiment Analysis
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.8-week8/1.8.4-day39-2025-10-30/ title="Day 39 - Named Entity Recognition (NER)" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.8-week8/1.8.4-day39-2025-10-30/><b>1.8.4. </b>Day 39 - Named Entity Recognition (NER)
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.8-week8/1.8.5-day40-2025-10-31/ title="Day 40 - Building NLP Projects" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.8-week8/1.8.5-day40-2025-10-31/><b>1.8.5. </b>Day 40 - Building NLP Projects
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/1-worklog/1.9-week9/ title="Week 9 - NLP Revision & Advanced Concepts" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.9-week9/><b>1.9. </b>Week 9 - NLP Revision & Advanced Concepts
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/1-worklog/1.9-week9/1.9.1-day41-2025-11-03/ title="Day 41 - NLP Fundamentals Revision" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.9-week9/1.9.1-day41-2025-11-03/><b>1.9.1. </b>Day 41 - NLP Fundamentals Revision
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.9-week9/1.9.2-day42-2025-11-04/ title="Day 42 - Advanced Text Classification" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.9-week9/1.9.2-day42-2025-11-04/><b>1.9.2. </b>Day 42 - Advanced Text Classification
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.9-week9/1.9.3-day43-2025-11-05/ title="Day 43 - Production Sentiment Analysis Systems" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.9-week9/1.9.3-day43-2025-11-05/><b>1.9.3. </b>Day 43 - Production Sentiment Analysis Systems
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.9-week9/1.9.4-day44-2025-11-06/ title="Day 44 - Advanced NER & Custom Entity Training" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.9-week9/1.9.4-day44-2025-11-06/><b>1.9.4. </b>Day 44 - Advanced NER & Custom Entity Training
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.9-week9/1.9.5-day45-2025-11-07/ title="Day 45 - NLP Integration & Final Project" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.9-week9/1.9.5-day45-2025-11-07/><b>1.9.5. </b>Day 45 - NLP Integration & Final Project
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/1-worklog/1.10-week10/ title="Week 10 - Online Library Project Completion (Frontend)" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.10-week10/><b>1.10. </b>Week 10 - Online Library Project Completion (Frontend)
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/1-worklog/1.10-week10/1.10.1-day46-2025-11-10/ title="Day 46 - Authentication & Project Setup" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.10-week10/1.10.1-day46-2025-11-10/><b>1.10.1. </b>Day 46 - Authentication & Project Setup
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.10-week10/1.10.2-day47-2025-11-11/ title="Day 47 - Book Upload Flow & Presigned URLs" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.10-week10/1.10.2-day47-2025-11-11/><b>1.10.2. </b>Day 47 - Book Upload Flow & Presigned URLs
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.10-week10/1.10.3-day48-2025-11-12/ title="Day 48 - Admin Panel & Approval Workflow" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.10-week10/1.10.3-day48-2025-11-12/><b>1.10.3. </b>Day 48 - Admin Panel & Approval Workflow
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.10-week10/1.10.4-day49-2025-11-13/ title="Day 49 - Reader Interface & Search Implementation" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.10-week10/1.10.4-day49-2025-11-13/><b>1.10.4. </b>Day 49 - Reader Interface & Search Implementation
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.10-week10/1.10.5-day50-2025-11-14/ title="Day 50 - Testing, Deployment & Project Completion" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/1-worklog/1.10-week10/1.10.5-day50-2025-11-14/><b>1.10.5. </b>Day 50 - Testing, Deployment & Project Completion
<i class="fas fa-check read-icon"></i></a></li></ul></li></ul></li><li data-nav-id=/2-proposal/ title=Proposal class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/2-proposal/><b>2. </b>Proposal
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/3-blogstranslated/ title="Translated Blogs" class="dd-item
parent"><a href=https://anquoc211.github.io/AWS_Internship/3-blogstranslated/><b>3. </b>Translated Blogs
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/3-blogstranslated/3.1-blog1/ title="Blog 1" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/3-blogstranslated/3.1-blog1/><b>3.1. </b>Blog 1
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/3-blogstranslated/3.2-blog2/ title="Blog 2" class="dd-item
active"><a href=https://anquoc211.github.io/AWS_Internship/3-blogstranslated/3.2-blog2/><b>3.2. </b>Blog 2
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/3-blogstranslated/3.3-blog3/ title="Blog 3" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/3-blogstranslated/3.3-blog3/><b>3.3. </b>Blog 3
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/4-eventparticipated/ title="Events Participated" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/4-eventparticipated/><b>4. </b>Events Participated
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/4-eventparticipated/4.1-event1/ title="Event 1 - Vietnam Cloud Day 2025" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/4-eventparticipated/4.1-event1/><b>4.1. </b>Event 1 - Vietnam Cloud Day 2025
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/4-eventparticipated/4.2-event2/ title="Event 2 - AWS GenAI Builder Club" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/4-eventparticipated/4.2-event2/><b>4.2. </b>Event 2 - AWS GenAI Builder Club
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/5-workshop/ title=Workshop class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/5-workshop/><b>5. </b>Workshop
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/5-workshop/5.1-workshop-overview/ title="Workshop Overview" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/5-workshop/5.1-workshop-overview/><b>5.1. </b>Workshop Overview
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.2-prerequisite/ title=Prerequisites class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/5-workshop/5.2-prerequisite/><b>5.2. </b>Prerequisites
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.3-module3/ title="User Registration & Verification" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/5-workshop/5.3-module3/><b>5.3. </b>User Registration & Verification
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.4-module4/ title="Login & Session Management" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/5-workshop/5.4-module4/><b>5.4. </b>Login & Session Management
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.5-module5/ title="Password Management" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/5-workshop/5.5-module5/><b>5.5. </b>Password Management
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.6-module6/ title="Advanced Features & Cleanup" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/5-workshop/5.6-module6/><b>5.6. </b>Advanced Features & Cleanup
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/6-self-evaluation/ title=Self-Assessment class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/6-self-evaluation/><b>6. </b>Self-Assessment
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/7-feedback/ title="Sharing and Feedback" class=dd-item><a href=https://anquoc211.github.io/AWS_Internship/7-feedback/><b>7. </b>Sharing and Feedback
<i class="fas fa-check read-icon"></i></a></li></ul><section id=shortcuts><h3>More</h3><ul><li><a class=padding href=https://www.facebook.com/groups/awsstudygroupfcj/><i class='fab fa-facebook'></i> AWS Study Group</a></li></ul></section><section id=prefooter><hr><ul><li><a class=padding><i class="fas fa-language fa-fw"></i><div class=select-style><select id=select-language onchange="location=this.value"><option id=en value=https://anquoc211.github.io/AWS_Internship/3-blogstranslated/3.2-blog2/ selected>English</option><option id=vi value=https://anquoc211.github.io/AWS_Internship/vi/3-blogstranslated/3.2-blog2/>Tiếng Việt</option></select><svg id="Capa_1" xmlns:xlink="http://www.w3.org/1999/xlink" width="255" height="255" viewBox="0 0 255 255" style="enable-background:new 0 0 255 255"><g><g id="arrow-drop-down"><polygon points="0,63.75 127.5,191.25 255,63.75"/></g></g></svg></div></a></li><li><a class=padding href=# data-clear-history-toggle><i class="fas fa-history fa-fw"></i> Clear History</a></li></ul></section><section id=footer><left><b>Workshop</b><br><img src="https://hitwebcounter.com/counter/counter.php?page=7920860&style=0038&nbdigits=9&type=page&initCount=0" title=Migrate alt="web counter" border=0></a><br><b><a href=https://cloudjourney.awsstudygroup.com/>Cloud Journey</a></b><br><img src="https://hitwebcounter.com/counter/counter.php?page=7830807&style=0038&nbdigits=9&type=page&initCount=0" title="Total CLoud Journey" alt="web counter" border=0>
</left><left><br><br><b>Last Updated</b><br><i><span id=lastUpdated style=color:orange></span>
</i><script>const today=new Date,formattedDate=today.toLocaleDateString("en-GB");document.getElementById("lastUpdated").textContent=formattedDate</script></left><left><br><br><b>Team</b><br><i><a href=https://www.facebook.com/groups/660548818043427 style=color:orange>First Cloud Journey</a><br></i></left><script async defer src=https://buttons.github.io/buttons.js></script></section></div></nav><section id=body><div id=overlay></div><div class="padding highlightable"><div><div id=top-bar><div id=breadcrumbs itemscope itemtype=http://data-vocabulary.org/Breadcrumb><span id=sidebar-toggle-span><a href=# id=sidebar-toggle data-sidebar-toggle><i class="fas fa-bars"></i>
</a></span><span id=toc-menu><i class="fas fa-list-alt"></i></span>
<span class=links><a href=https://anquoc211.github.io/AWS_Internship/>Internship Report</a> > <a href=https://anquoc211.github.io/AWS_Internship/3-blogstranslated/>Translated Blogs</a> > Blog 2</span></div><div class=progress><div class=wrapper><nav id=TableOfContents><ul><li><a href=#solution-overview>Solution Overview</a></li><li><a href=#prerequisites>Prerequisites</a></li><li><a href=#deploying-gpt-oss-model-to-sagemaker-inference>Deploying GPT-OSS Model to SageMaker Inference</a></li><li><a href=#using-langgraph-to-build-stock-analysis-agent>Using LangGraph to Build Stock Analysis Agent</a></li><li><a href=#deploying-to-amazon-bedrock-agentcore>Deploying to Amazon Bedrock AgentCore</a></li><li><a href=#invoking-the-agent>Invoking the Agent</a></li><li><a href=#cleanup>Cleanup</a></li><li><a href=#conclusion>Conclusion</a></li><li><a href=#about-the-authors>About the Authors</a></li></ul></nav></div></div></div></div><div id=head-tags></div><div id=body-inner><h1>Blog 2</h1><h1 id=building-agentic-workflows-with-openai-gpt-oss-on-amazon-sagemaker-ai-and-amazon-bedrock-agentcore>Building Agentic Workflows with OpenAI GPT OSS on Amazon SageMaker AI and Amazon Bedrock AgentCore</h1><p><strong>by:</strong> Vivek Gangasani and Surya Kari | <strong>Published:</strong> Sep 17, 2025 | <strong>in:</strong> Amazon Bedrock, Amazon SageMaker AI, Amazon SageMaker Unified Studio, Artificial Intelligence, Customer Solutions</p><hr><p>OpenAI has released two open-weight models, <code>gpt-oss-120b</code> (117 billion parameters) and <code>gpt-oss-20b</code> (21 billion parameters), both built on Mixture of Experts (MoE) architecture and using a 128K context window. These models lead open-source models according to the Artificial Analysis benchmark, and excel in reasoning capabilities and agentic workflows.</p><p>With Amazon SageMaker AI, you can fine-tune or customize models and deploy using your chosen framework through a fully managed service. Amazon SageMaker Inference gives you flexibility in bringing your own inference code and framework without needing to build and maintain server clusters yourself.</p><p>While large language models (LLMs) excel at understanding language and generating content, building practical agentic applications requires managing complex workflows, tool calling capabilities, and context management. Multi-agent architecture addresses these challenges by breaking down complex systems into specialized components, but this also introduces new complexities in agent coordination, memory management, and workflow orchestration.</p><p>In this post, we&rsquo;ll demonstrate how to deploy the <code>gpt-oss-20b</code> model to SageMaker managed endpoints and illustrate a practical example of a stock analysis agent assistant using LangGraph — a powerful graph-based framework that handles state management, workflow coordination, and persistent memory systems. We&rsquo;ll then deploy the agents to Amazon Bedrock AgentCore, a unified orchestration layer that abstracts infrastructure, allowing you to deploy and operate AI agents at scale securely.</p><h2 id=solution-overview>Solution Overview</h2><p>In this solution, we build an agentic stock analyzer with the following main components:</p><ul><li>GPT OSS 20B model deployed to SageMaker endpoint using vLLM, an open-source serving framework for LLMs</li><li>LangGraph to build the multi-agent orchestration framework</li><li>Amazon Bedrock AgentCore to deploy the agents</li></ul><p>The diagram below illustrates the solution architecture:</p><p><img alt="Solution Architecture" src=https://i.imgur.com/placeholder-blog2-img1.png></p><p>This architecture illustrates a multi-agent workflow hosted on Amazon Bedrock AgentCore Runtime running on AWS. Users submit queries, processed by a pipeline of specialized agents — Data Gathering Agent, Stock Performance Analyzer Agent, and Stock Report Generation Agent — each responsible for a distinct part of the stock assessment process. These agents coordinate within Amazon Bedrock AgentCore Runtime, and when they need to understand or generate language, they call a GPT OSS model hosted on SageMaker AI. The model processes inputs and returns structured results that help determine agent behavior, enabling a fully serverless, modular, and scalable agentic system using open-source models.</p><h2 id=prerequisites>Prerequisites</h2><ul><li>Ensure you have the necessary quota for G6e instances to deploy the model.</li><li>Request quota here if you don&rsquo;t have it yet.</li><li>If this is your first time working with Amazon SageMaker Studio, you need to create a SageMaker domain first.</li><li>Ensure your IAM role has the necessary permissions to deploy SageMaker Models and Endpoints.</li><li>For more information, see How Amazon SageMaker AI works with IAM in the SageMaker Developer Guide.</li></ul><h2 id=deploying-gpt-oss-model-to-sagemaker-inference>Deploying GPT-OSS Model to SageMaker Inference</h2><p>Customers wanting to customize models and frameworks can deploy in a serverful manner, but this requires GPU access, serving frameworks, load balancers, and infrastructure configuration. SageMaker AI provides a fully managed hosting platform, handling infrastructure provisioning, necessary drivers, model loading, and deployment.</p><p>OpenAI&rsquo;s GPT-OSS models launch with 4-bit quantization scheme (MXFP4), enabling fast inference while keeping resources low. These models can run on <code>P5(H100)</code>, <code>P6(H200)</code>, <code>P4(A100)</code> and <code>G6e(L40)</code> instances. GPT-OSS models are sparse MoE architecture with 128 experts (120B) or 32 experts (20B), where each token is routed to 4 experts without sharing experts. Using MXFP4 for MoE weights shrinks model size to 63 GB (120B) and 14 GB (20B), making them runnable on a single H100 GPU.</p><p>For efficient deployment, you need a strong serving framework like vLLM. To deploy the model, we build a vLLM container with the latest version supporting GPT OSS models on SageMaker AI. You can use the Docker file and following script to build the container and push to Amazon Elastic Container Registry (Amazon ECR). The recommended approach is to execute directly from SageMaker Studio, a managed JupyterLab environment with AWS CLI access, where you can build and push the image to ECR as part of the SageMaker workflow. Alternatively, you can perform the same steps on an Amazon Elastic Compute Cloud (Amazon EC2) instance with Docker installed.</p><p>After you&rsquo;ve built and pushed the container to Amazon ECR, you can open SageMaker Studio via the SageMaker AI console, as illustrated in the screenshot below:</p><p><img alt="Open SageMaker Studio" src=https://i.imgur.com/placeholder-blog2-img2.png></p><p>You can then create a Jupyter space or use an existing space to open JupyterLab and run the notebook.</p><p><img alt="Create JupyterLab space" src=https://i.imgur.com/placeholder-blog2-img3.png></p><p>Clone the following notebook and run &ldquo;Option 3: Deploying from HF using BYOC.&rdquo; Update necessary parameters, such as inference image in the notebook with the container image. We also provide the necessary environment variables, as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># </span>
</span></span><span style=display:flex><span>inference_image <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>account_id<span style=color:#e6db74>}</span><span style=color:#e6db74>.dkr.ecr.</span><span style=color:#e6db74>{</span>region<span style=color:#e6db74>}</span><span style=color:#e6db74>.amazonaws.com/vllm:v0.10.0-gpt-oss&#34;</span>
</span></span><span style=display:flex><span>instance_type <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;ml.g6e.4xlarge&#34;</span>
</span></span><span style=display:flex><span>num_gpu <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>model_name <span style=color:#f92672>=</span> sagemaker<span style=color:#f92672>.</span>utils<span style=color:#f92672>.</span>name_from_base(<span style=color:#e6db74>&#34;model-byoc&#34;</span>)
</span></span><span style=display:flex><span>endpoint_name <span style=color:#f92672>=</span> model_name
</span></span><span style=display:flex><span>inference_component_name <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;ic-</span><span style=color:#e6db74>{</span>model_name<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>config <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;OPTION_MODEL&#34;</span>: <span style=color:#e6db74>&#34;openai/gpt-oss-20b&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;OPTION_SERVED_MODEL_NAME&#34;</span>: <span style=color:#e6db74>&#34;model&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;OPTION_TENSOR_PARALLEL_SIZE&#34;</span>: json<span style=color:#f92672>.</span>dumps(num_gpu),
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;OPTION_ASYNC_SCHEDULING&#34;</span>: <span style=color:#e6db74>&#34;true&#34;</span>,
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>After you set up the deployment configuration, you can deploy to SageMaker AI with the following code:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># </span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sagemaker.compute_resource_requirements.resource_requirements <span style=color:#f92672>import</span> ResourceRequirements
</span></span><span style=display:flex><span>lmi_model <span style=color:#f92672>=</span> sagemaker<span style=color:#f92672>.</span>Model(
</span></span><span style=display:flex><span>    image_uri<span style=color:#f92672>=</span>inference_image,
</span></span><span style=display:flex><span>    env<span style=color:#f92672>=</span>config,
</span></span><span style=display:flex><span>    role<span style=color:#f92672>=</span>role,
</span></span><span style=display:flex><span>    name<span style=color:#f92672>=</span>model_name,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>lmi_model<span style=color:#f92672>.</span>deploy(
</span></span><span style=display:flex><span>    initial_instance_count<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>    instance_type<span style=color:#f92672>=</span>instance_type,
</span></span><span style=display:flex><span>    container_startup_health_check_timeout<span style=color:#f92672>=</span><span style=color:#ae81ff>600</span>,
</span></span><span style=display:flex><span>    endpoint_name<span style=color:#f92672>=</span>endpoint_name,
</span></span><span style=display:flex><span>    endpoint_type<span style=color:#f92672>=</span>sagemaker<span style=color:#f92672>.</span>enums<span style=color:#f92672>.</span>EndpointType<span style=color:#f92672>.</span>INFERENCE_COMPONENT_BASED,
</span></span><span style=display:flex><span>    inference_component_name<span style=color:#f92672>=</span>inference_component_name,
</span></span><span style=display:flex><span>    resources<span style=color:#f92672>=</span>ResourceRequirements(requests<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#34;num_accelerators&#34;</span>: num_gpu, <span style=color:#e6db74>&#34;memory&#34;</span>: <span style=color:#ae81ff>1024</span><span style=color:#f92672>*</span><span style=color:#ae81ff>5</span>, <span style=color:#e6db74>&#34;copies&#34;</span>: <span style=color:#ae81ff>1</span>,}),
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p>You can run an inference example:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># </span>
</span></span><span style=display:flex><span>payload<span style=color:#f92672>=</span>{
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;messages&#34;</span>: [
</span></span><span style=display:flex><span>        {<span style=color:#e6db74>&#34;role&#34;</span>: <span style=color:#e6db74>&#34;user&#34;</span>, <span style=color:#e6db74>&#34;content&#34;</span>: <span style=color:#e6db74>&#34;Name popular places to visit in London?&#34;</span>}
</span></span><span style=display:flex><span>    ],
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>res <span style=color:#f92672>=</span> llm<span style=color:#f92672>.</span>predict(payload)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;-----</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span> <span style=color:#f92672>+</span> res[<span style=color:#e6db74>&#34;choices&#34;</span>][<span style=color:#ae81ff>0</span>][<span style=color:#e6db74>&#34;message&#34;</span>][<span style=color:#e6db74>&#34;content&#34;</span>] <span style=color:#f92672>+</span> <span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>-----</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>print(res[<span style=color:#e6db74>&#34;usage&#34;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Output:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># -----</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Here are some of the must-see spots in London -- a mix of iconic landmarks, world-class museums, and vibrant neighborhoods:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># | # | Place | Why It&#39;s Popular |</span>
</span></span><span style=display:flex><span><span style=color:#75715e># |---|-------|------------------|</span>
</span></span><span style=display:flex><span><span style=color:#75715e># | 1 | **Buckingham Palace** | The Queen&#39;s official London residence - watch the Changing of the Guard. |</span>
</span></span><span style=display:flex><span><span style=color:#75715e># | 2 | **The Tower of London &amp; Tower Bridge** | Historic castle, Crown Jewels, and the iconic bridge with glass floors. |</span>
</span></span><span style=display:flex><span><span style=color:#75715e># | 3 | **The British Museum** | World-famous collection from the Rosetta Stone to Egyptian mummies (free entry). |</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ... (Rest of table) ...</span>
</span></span><span style=display:flex><span><span style=color:#75715e># |15 | **Oxford Street &amp; Regent Street** | Prime shopping streets for fashion, flagship stores, and historic architecture. |</span>
</span></span><span style=display:flex><span><span style=color:#75715e># These spots cover history, culture, shopping, and leisure--perfect for a first visit or a weekend escape in London!</span>
</span></span><span style=display:flex><span><span style=color:#75715e># -----</span>
</span></span></code></pre></div><h2 id=using-langgraph-to-build-stock-analysis-agent>Using LangGraph to Build Stock Analysis Agent</h2><p>For our multi-agent stock analysis system, we use LangGraph to orchestrate the workflow. The Jupyter notebook for the code is in this Github repository. The system consists of three specialized tools working together for comprehensive stock analysis:</p><ul><li><strong>gather_stock_data tool</strong> collects comprehensive stock data for a given stock ticker, including current price, historical performance, financial metrics and market data. It returns formatted information including price history, company fundamentals, trading metrics, and recent news headlines.</li><li><strong>analyze_stock_performance tool</strong> performs detailed technical and fundamental analysis of stock data, calculating metrics like price trends, volatility, and overall investment score. It evaluates multiple factors including P/E ratio, profit margins, and dividend yield to provide comprehensive performance analysis.</li><li><strong>generate_stock_report tool</strong> creates professional PDF reports from collected and analyzed stock data, automatically uploading to Amazon S3 with date-organized folders.</li></ul><p>To test locally, you can use a simplified version of the system by importing necessary functions from your local script. For example:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># </span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langgraph_stock_local <span style=color:#f92672>import</span> langgraph_stock_sagemaker 
</span></span><span style=display:flex><span><span style=color:#75715e># Test the agent locally </span>
</span></span><span style=display:flex><span>result <span style=color:#f92672>=</span> langgraph_stock_sagemaker({
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;prompt&#34;</span>: <span style=color:#e6db74>&#34;Analyze SIM_STOCK Stock for Investment purposes.&#34;</span>
</span></span><span style=display:flex><span>})
</span></span><span style=display:flex><span>print(result)
</span></span></code></pre></div><p>This approach helps you iterate agent logic quickly before deploying to a scalable platform, ensuring each component works correctly and the overall workflow produces expected results for various stock types.</p><h2 id=deploying-to-amazon-bedrock-agentcore>Deploying to Amazon Bedrock AgentCore</h2><p>After you develop and test the LangGraph framework locally, you can deploy it to Amazon Bedrock AgentCore Runtime. Amazon Bedrock AgentCore handles most container orchestration, session management, scalability and infrastructure management abstraction. It provides a persistent execution environment that can maintain agent state across multiple invocations.</p><p>Before deploying the stock analysis agent to AgentCore Runtime, we need to create an AWS Identity and Access Management (IAM) role with appropriate permissions. This role allows AgentCore to call your SageMaker endpoint for GPT-OSS model inference, manage ECR container repository, write Amazon CloudWatch logs for monitoring and debugging, access AgentCore&rsquo;s workload service for runtime, and send telemetry data to AWS X-Ray and CloudWatch for observability.</p><p>The code is as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># </span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> create_agentcore_role <span style=color:#f92672>import</span> create_bedrock_agentcore_role
</span></span><span style=display:flex><span>role_arn <span style=color:#f92672>=</span> create_bedrock_agentcore_role(
</span></span><span style=display:flex><span>    role_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;MyStockAnalyzerRole&#34;</span>,
</span></span><span style=display:flex><span>    sagemaker_endpoint_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;your-endpoint-name&#34;</span>,
</span></span><span style=display:flex><span>    region<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;us-west-2&#34;</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p>After creating the role, you use the Amazon Bedrock AgentCore Starter Toolkit to deploy the agent. The toolkit simplifies the deployment process by packaging code, creating container images, and configuring the runtime environment:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># </span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> bedrock_agentcore_starter_toolkit <span style=color:#f92672>import</span> Runtime
</span></span><span style=display:flex><span>agentcore_runtime <span style=color:#f92672>=</span> Runtime() 
</span></span><span style=display:flex><span><span style=color:#75715e># Configure the agent </span>
</span></span><span style=display:flex><span>response <span style=color:#f92672>=</span> agentcore_runtime<span style=color:#f92672>.</span>configure(
</span></span><span style=display:flex><span>    entrypoint<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;langgraph_stock_sagemaker_gpt_oss.py&#34;</span>,
</span></span><span style=display:flex><span>    execution_role<span style=color:#f92672>=</span>role_arn,
</span></span><span style=display:flex><span>    auto_create_ecr<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    requirements_file<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;requirements.txt&#34;</span>,
</span></span><span style=display:flex><span>    region<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;us-west-2&#34;</span>,
</span></span><span style=display:flex><span>    agent_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;stock_analyzer_agent&#34;</span>
</span></span><span style=display:flex><span>) 
</span></span><span style=display:flex><span><span style=color:#75715e># Deploy to the cloud </span>
</span></span><span style=display:flex><span>launch_result <span style=color:#f92672>=</span> agentcore_runtime<span style=color:#f92672>.</span>launch(local<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, local_build<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span></code></pre></div><p>When you use <code>BedrockAgentCoreApp</code>, it automatically creates an HTTP server listening on port 8080, implements the <code>/invocations</code> endpoint to handle agent requests, the <code>/ping</code> endpoint for health checks (crucial for asynchronous agents), handles content types and response formatting correctly, and manages errors according to AWS standards.</p><p>After you deploy to AgentCore Runtime, the status will show <code>Ready</code> on the Amazon Bedrock AgentCore console.</p><h2 id=invoking-the-agent>Invoking the Agent</h2><p>After you create the agent, you must set up the entry point to invoke the agent. With Amazon AgentCore Runtime, we use the <code>@app.entrypoint</code> decorator for the agent invocation part and use that as the runtime entry point.</p><p>After deploying the agent to AgentCore Runtime, you invoke it using the AWS SDK:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># </span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> boto3
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> json
</span></span><span style=display:flex><span>agentcore_client <span style=color:#f92672>=</span> boto3<span style=color:#f92672>.</span>client(<span style=color:#e6db74>&#39;bedrock-agentcore&#39;</span>, region_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;us-west-2&#39;</span>)
</span></span><span style=display:flex><span>response <span style=color:#f92672>=</span> agentcore_client<span style=color:#f92672>.</span>invoke_agent_runtime(
</span></span><span style=display:flex><span>    agentRuntimeArn<span style=color:#f92672>=</span>launch_result<span style=color:#f92672>.</span>agent_arn,
</span></span><span style=display:flex><span>    qualifier<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;DEFAULT&#34;</span>,
</span></span><span style=display:flex><span>    payload<span style=color:#f92672>=</span>json<span style=color:#f92672>.</span>dumps({
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;prompt&#34;</span>: <span style=color:#e6db74>&#34;Analyze SIM_STOCK for investment purposes&#34;</span>
</span></span><span style=display:flex><span>    })
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p>After invoking the stock analysis agent via AgentCore Runtime, you must parse and format the response for clear display. Response handling includes these steps:</p><ul><li>Decode the byte stream from AgentCore into readable text.</li><li>Parse the JSON response containing complete stock analysis.</li><li>Extract three main sections using regex pattern matching:<ul><li><strong>Stock Data Gathering Section</strong>: Extracts core information like stock ticker, company info, current price, market metrics, financial ratios, trading data, and recent news headlines.</li><li><strong>Performance Analysis section</strong>: Analyzes technical indicators, fundamental indicators, and volatility to create comprehensive stock analysis.</li><li><strong>Stock Report Generation Section</strong>: Creates detailed PDF report with all stock technical analysis.</li></ul></li><li>The system also includes graceful error handling for JSON parsing errors, fallback to text display if structured parsing fails, and provides debugging information for handling stock analysis parsing errors.</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># </span>
</span></span><span style=display:flex><span>stock_analysis <span style=color:#f92672>=</span> parse_bedrock_agentcore_stock_response(invoke_response)
</span></span></code></pre></div><p>The formatted output makes it easy to view the agent&rsquo;s decision-making process and present professional stock analysis results to stakeholders, completing the workflow from model deployment to meaningful business outcomes:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span># 
</span></span><span style=display:flex><span>STOCK DATA GATHERING REPORT:
</span></span><span style=display:flex><span>================================
</span></span><span style=display:flex><span>Stock Symbol: SIM_STOCK
</span></span><span style=display:flex><span>Company Name: Simulated Stock Inc.
</span></span><span style=display:flex><span>Sector: SIM_SECTOR
</span></span><span style=display:flex><span>Industry: SIM INDUSTRY
</span></span><span style=display:flex><span>CURRENT MARKET DATA:
</span></span><span style=display:flex><span>- Current Price: $29.31
</span></span><span style=display:flex><span>- Market Cap: $3,958
</span></span><span style=display:flex><span>- 52-Week High: $29.18
</span></span><span style=display:flex><span>- 52-Week Low: $16.80
</span></span><span style=display:flex><span>- YTD Return: 1.30%
</span></span><span style=display:flex><span>- Volatility (Annualized): 32.22%
</span></span><span style=display:flex><span>FINANCIAL METRICS:
</span></span><span style=display:flex><span>- P/E Ratio: 44.80
</span></span><span style=display:flex><span>- Forward P/E: 47.59
</span></span><span style=display:flex><span>- Price-to-Book: 11.75
</span></span><span style=display:flex><span>- Dividend Yield: 0.46%
</span></span><span style=display:flex><span>- Revenue (TTM): $4,988
</span></span><span style=display:flex><span>- Profit Margin: 24.30% 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>STOCK PERFORMANCE ANALYSIS:
</span></span><span style=display:flex><span>===============================
</span></span><span style=display:flex><span>Stock: SIM_STOCK | Current Price: $29.31
</span></span><span style=display:flex><span>TECHNICAL ANALYSIS:
</span></span><span style=display:flex><span>- Price Trend: SLIGHT UPTREND
</span></span><span style=display:flex><span>- YTD Performance: 1.03%
</span></span><span style=display:flex><span>- Technical Score: 3/5
</span></span><span style=display:flex><span>FUNDAMENTAL ANALYSIS:
</span></span><span style=display:flex><span>- P/E Ratio: 34.80
</span></span><span style=display:flex><span>- Profit Margin: 24.30%
</span></span><span style=display:flex><span>- Dividend Yield: 0.46%
</span></span><span style=display:flex><span>- Beta: 1.165
</span></span><span style=display:flex><span>- Fundamental Score: 3/5
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>STOCK REPORT GENERATION:
</span></span><span style=display:flex><span>===============================
</span></span><span style=display:flex><span>Stock: SIM_STOCK Sector: SIM_INDUSTRY
</span></span><span style=display:flex><span>Current Price: $29.78
</span></span><span style=display:flex><span>REPORT SUMMARY:
</span></span><span style=display:flex><span>- Technical Analysis: 8.33% YTD performance
</span></span><span style=display:flex><span>- Report Type: Comprehensive stock analysis for informational purposes
</span></span><span style=display:flex><span>- Generated: 2025-09-04 23:11:55
</span></span><span style=display:flex><span>PDF report uploaded to S3: s3://amzn-s3-demo-bucket/2025/09/04/SIM_STOCK_Stock_Report_20250904_231155.pdf
</span></span><span style=display:flex><span>REPORT CONTENTS:
</span></span><span style=display:flex><span>• Executive Summary with key metrics
</span></span><span style=display:flex><span>• Detailed market data and financial metrics
</span></span><span style=display:flex><span>• Technical and fundamental analysis
</span></span><span style=display:flex><span>• Professional formatting for documentation
</span></span></code></pre></div><h2 id=cleanup>Cleanup</h2><p>You can delete the SageMaker endpoint to avoid incurring charges after testing by running the following cells in the same notebook:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># </span>
</span></span><span style=display:flex><span>sess<span style=color:#f92672>.</span>delete_inference_component(inference_component_name)
</span></span><span style=display:flex><span>sess<span style=color:#f92672>.</span>delete_endpoint(endpoint_name)
</span></span><span style=display:flex><span>sess<span style=color:#f92672>.</span>delete_endpoint_config(endpoint_name)
</span></span><span style=display:flex><span>sess<span style=color:#f92672>.</span>delete_model(model_name)
</span></span></code></pre></div><p>You can also delete Amazon Bedrock AgentCore resources with the following commands:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># </span>
</span></span><span style=display:flex><span>runtime_delete_response <span style=color:#f92672>=</span> agentcore_control_client<span style=color:#f92672>.</span>delete_agent_runtime(agentRuntimeId<span style=color:#f92672>=</span>launch_result<span style=color:#f92672>.</span>agent_id)
</span></span><span style=display:flex><span>response <span style=color:#f92672>=</span> ecr_client<span style=color:#f92672>.</span>delete_repository(repositoryName<span style=color:#f92672>=</span>launch_result<span style=color:#f92672>.</span>ecr_uri<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#39;/&#39;</span>)[<span style=color:#ae81ff>1</span>],force<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span></code></pre></div><h2 id=conclusion>Conclusion</h2><p>In this post, we built an end-to-end solution to deploy OpenAI open-weight models on a single G6e(L40s) GPU, created a multi-agent stock analysis system with LangGraph and deployed seamlessly with Amazon Bedrock AgentCore. This implementation shows organizations can now use powerful open-source LLMs cost-effectively through serving frameworks like vLLM.</p><p>Beyond technical implementation, upgrading this workflow can deliver significant business value, such as reducing stock analysis processing time, increasing analyst productivity by automating regular stock assessments. Furthermore, by freeing analysts from repetitive tasks, organizations can shift skilled experts toward handling complex cases and building relationships — activities that can drive business growth. We invite you to try our code samples and iterate on agentic workflows to meet your use cases.</p><hr><h2 id=about-the-authors>About the Authors</h2><p><strong>Vivek Gangasani</strong> is Worldwide Lead GenAI Specialist Solutions Architect for SageMaker Inference. He is responsible for Go-to-Market (GTM) strategy and Outbound Product strategy for SageMaker Inference. Vivek also supports enterprises and startups in deploying, managing and scaling their GenAI models using SageMaker and GPUs. Currently, he focuses on developing strategy and solutions for optimizing inference performance and GPU efficiency for hosting Large Language Models (LLMs). In his free time, Vivek enjoys rock climbing, watching movies, and trying different cuisines.</p><p><strong>Surya Kari</strong> is a Senior Generative AI Data Scientist at AWS, specializing in developing solutions leveraging advanced foundation models. He has extensive experience working with advanced language models like DeepSeek-R1, Llama family, and Qwen, focusing on fine-tuning and optimizing them for specialized scientific applications. His experience includes implementing efficient training pipelines and model deployment strategies using AWS SageMaker, helping scale foundation models from development to production. Surya collaborates with customers to design and implement Generative AI solutions, helping them navigate model selection, fine-tuning methods, and deployment strategies to achieve optimal performance for specific use cases.</p><footer class=footline></footer></div></div><div id=navigation><a class="nav nav-prev" href=https://anquoc211.github.io/AWS_Internship/3-blogstranslated/3.1-blog1/ title="Blog 1"><i class="fa fa-chevron-left"></i></a>
<a class="nav nav-next" href=https://anquoc211.github.io/AWS_Internship/3-blogstranslated/3.3-blog3/ title="Blog 3" style=margin-right:0><i class="fa fa-chevron-right"></i></a></div></section><div style=left:-1000px;overflow:scroll;position:absolute;top:-1000px;border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px><div style=border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px></div></div><script src=https://anquoc211.github.io/AWS_Internship/js/clipboard.min.js?1765072081></script><script src=https://anquoc211.github.io/AWS_Internship/js/perfect-scrollbar.min.js?1765072081></script><script src=https://anquoc211.github.io/AWS_Internship/js/perfect-scrollbar.jquery.min.js?1765072081></script><script src=https://anquoc211.github.io/AWS_Internship/js/jquery.sticky.js?1765072081></script><script src=https://anquoc211.github.io/AWS_Internship/js/featherlight.min.js?1765072081></script><script src=https://anquoc211.github.io/AWS_Internship/js/highlight.pack.js?1765072081></script><script>hljs.initHighlightingOnLoad()</script><script src=https://anquoc211.github.io/AWS_Internship/js/modernizr.custom-3.6.0.js?1765072081></script><script src=https://anquoc211.github.io/AWS_Internship/js/learn.js?1765072081></script><script src=https://anquoc211.github.io/AWS_Internship/js/hugo-learn.js?1765072081></script><link href=https://anquoc211.github.io/AWS_Internship/mermaid/mermaid.css?1765072081 rel=stylesheet><script src=https://anquoc211.github.io/AWS_Internship/mermaid/mermaid.js?1765072081></script><script>mermaid.initialize({startOnLoad:!0})</script><script>(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,(e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date),(i=t.createElement(n),a=t.getElementsByTagName(n)[0]),i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-158079754-2","auto"),ga("send","pageview")</script></body></html>