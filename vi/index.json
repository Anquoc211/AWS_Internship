[{"uri":"https://anquoc211.github.io/AWS_Internship/vi/4-eventparticipated/4.1-event1/","title":"Sự kiện 1 - Vietnam Cloud Day 2025","tags":[],"description":"","content":"Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders Ngày \u0026amp; Giờ: Thứ Năm, 18 tháng 9, 2025 | 9:00 – 17:00 VNT\nĐịa điểm: Văn phòng Amazon Web Services Vietnam, Tầng 36, Số 2 Hai Trưng, Quận 1, TP. Hồ Chí Minh\nTrạng thái: Đã đóng đăng ký\nTổng quan Vietnam Cloud Day 2025 quy tụ các nhà phát triển và lãnh đạo doanh nghiệp trong một trải nghiệm AWS toàn diện. Sự kiện có sự tham gia của đại diện chính phủ, điều hành AWS và các nhà tiên phong công nghiệp thảo luận về các đổi mới cloud mới nhất và chiến lược AI. Người tham dự được trải nghiệm hai track song song: phát trực tiếp với các bài phát biểu chính và các phiên thảo luận chuyên sâu trực tiếp.\nChương trình sự kiện Sân khấu chính (Phát trực tiếp) Thời gian (VNT) Phiên Diễn giả 7:35 - 9:00 Đăng ký \u0026amp; Giao lưu - 9:00 - 9:20 Phát biểu khai mạc Đại diện Chính phủ 9:20 - 9:40 Phát biểu chào mừng Eric Yeo, Tổng Giám đốc Quốc gia, AWS Việt Nam, Campuchia, Lào \u0026amp; Myanmar 9:40 - 10:00 Câu chuyện thành công khách hàng Tiến sĩ Jens Lottner, CEO, Techcombank 10:00 - 10:20 Giới thiệu đổi mới Bà Trang Phùng, CEO \u0026amp; Đồng sáng lập, U2U Network 10:20 - 10:50 Cập nhật chiến lược khu vực Jaime Valles, Phó Chủ tịch \u0026amp; Tổng Giám đốc Châu Á Thái Bình Dương và Nhật Bản, AWS 11:00 - 11:40 Thảo luận điều hành: Định hướng cách mạng GenAI Điều phối: Jeff Johnson, Giám đốc điều hành ASEAN, AWS Điểm nổi bật thảo luận điều hành Các lãnh đạo ngành chia sẻ cách tiếp cận chiến lược trong việc áp dụng AI tạo sinh:\nChủ đề thảo luận:\nXây dựng văn hóa tổ chức hướng đến đổi mới Liên kết các sáng kiến AI với kết quả kinh doanh Quản lý chuyển đổi được thúc đẩy bởi AI Thành viên thảo luận:\nVu Van – Đồng sáng lập \u0026amp; CEO, ELSA Corp Nguyễn Hòa Bình – Chủ tịch, Tập đoàn Nexttech Dieter Botha – CEO, TymeX Phiên chuyên sâu kỹ thuật (Trực tiếp) Track 1: Đổi mới AI \u0026amp; Dữ liệu Thời gian (VNT) Phiên Diễn giả 13:15 - 13:30 Tổng quan Track Jun Kai Loke, Chuyên gia AI/ML SA, AWS 13:30 - 14:00 Xây dựng nền tảng dữ liệu thống nhất cho AI Kiên Nguyễn, Kiến trúc sư giải pháp, AWS 14:00 - 14:30 Chiến lược \u0026amp; Lộ trình áp dụng GenAI Jun Kai Loke \u0026amp; Tamelly Lim, Chuyên gia SA, AWS 14:30 - 15:00 Vòng đời phát triển được thúc đẩy bởi AI Bình Trần, Kiến trúc sư giải pháp cấp cao, AWS 15:00 - 15:30 Giải lao giao lưu - 15:30 - 16:00 Thực hành tốt nhất về bảo mật cho ứng dụng GenAI Taiki Đặng, Kiến trúc sư giải pháp, AWS 16:00 - 16:30 AI Agents cho năng suất Michael Armentano, Chuyên gia GTM chính, AWS Những hiểu biết quan trọng từ các phiên:\nNền tảng dữ liệu thống nhất\nKhám phá các mẫu kiến trúc cho cơ sở hạ tầng dữ liệu có khả năng mở rộng hỗ trợ khối lượng công việc AI và phân tích, bao gồm các thực hành tốt nhất về thu thập, lưu trữ, xử lý và quản trị dữ liệu.\nLộ trình áp dụng GenAI\nAWS phác thảo tầm nhìn chiến lược cho việc áp dụng AI tạo sinh, nêu bật các dịch vụ chính và xu hướng mới nổi cho phép các tổ chức đổi mới với công nghệ GenAI.\nVòng đời phát triển được thúc đẩy bởi AI\nGiới thiệu cách tiếp cận chuyển đổi trong đó AI trở thành cộng tác viên trung tâm trong toàn bộ quy trình phát triển phần mềm, cải thiện đáng kể tốc độ, chất lượng và đổi mới.\nNguyên tắc cơ bản về bảo mật GenAI\nGiải quyết các thách thức bảo mật trên toàn bộ ngăn xếp GenAI với các biện pháp bảo vệ tích hợp của AWS bao gồm mã hóa, kiến trúc zero-trust, giám sát liên tục và kiểm soát truy cập chi tiết.\nAI Agents như công cụ nhân năng suất\nTrình diễn cách các AI agent thông minh tự động học hỏi, thích nghi và thực hiện các tác vụ phức tạp, chuyển đổi hoạt động và nhân năng suất theo cấp số nhân.\nTrack 2: Di chuyển \u0026amp; Hiện đại hóa Cloud Thời gian (VNT) Phiên Diễn giả 13:15 - 13:30 Giới thiệu Track Hưng Nguyễn Gia, Trưởng nhóm SA, AWS 13:30 - 14:00 Di chuyển doanh nghiệp quy mô lớn Sơn Đỗ, TAM, AWS \u0026amp; Nguyễn Văn Hải, Techcombank 14:00 - 14:30 Hiện đại hóa ứng dụng với GenAI Phúc Nguyễn, SA, AWS \u0026amp; Alex Trần, OCB 14:30 - 15:00 Thảo luận: Thúc đẩy chuyển đổi kinh doanh Điều phối: Hưng Nguyễn Gia, AWS 15:00 - 15:30 Giải lao - 15:30 - 16:00 Hành trình hiện đại hóa VMware Cloud Hùng Hoàng, Quản lý giải pháp khách hàng, AWS 16:00 - 16:30 Bảo mật AWS quy mô lớn Taiki Đặng, Kiến trúc sư giải pháp, AWS Những hiểu biết quan trọng từ các phiên:\nThành công di chuyển doanh nghiệp\nChia sẻ các chiến lược đã được chứng minh từ hàng nghìn lần di chuyển doanh nghiệp, bao gồm các mô hình tư duy, thực hành kỹ thuật tốt nhất và con đường hiện đại hóa với các công cụ tăng tốc AWS.\nPhát triển được hỗ trợ bởi GenAI\nTrình diễn cách Amazon Q Developer chuyển đổi SDLC thông qua khả năng agentic, tăng tốc tạo mã, cải thiện chất lượng và tự động hóa tài liệu và kiểm thử.\nThảo luận về hiện đại hóa\nCác chuyên gia ngành thảo luận về trải nghiệm hiện đại hóa ứng dụng thực tế và chiến lược chuyển đổi kinh doanh.\nThành viên thảo luận:\nNguyễn Minh Ngân, Chuyên gia AI, OCB Nguyễn Mạnh Tuyến, Trưởng phòng Ứng dụng Dữ liệu, Chứng khoán LPBank Vinh Nguyễn, Đồng sáng lập \u0026amp; CTO, Ninety Eight Chuyển đổi VMware\nGiới thiệu cách các tổ chức Việt Nam tăng tốc áp dụng cloud từ các tài sản VMware bằng AWS Transform để di chuyển nhanh, an toàn, tiết kiệm chi phí với các playbook từng bước.\nBảo mật quy mô lớn\nKhám phá các cách tiếp cận bảo mật toàn diện trong suốt vòng đời phát triển và sản xuất, bao gồm phòng ngừa, phát hiện, phản ứng và cách GenAI nâng cao hoạt động bảo mật.\nKết quả thu được Tầm nhìn chiến lược: Hiểu rõ định hướng AI và hiện đại hóa cloud của AWS Kiến thức thực tiễn: Thông tin chi tiết có thể hành động cho triển khai AI cấp doanh nghiệp Thực hành tốt nhất: Các cách tiếp cận đã được chứng minh cho kiến trúc dữ liệu, bảo mật và hiện đại hóa Ví dụ thực tế: Câu chuyện thành công của khách hàng từ các doanh nghiệp Việt Nam hàng đầu Kỹ năng kỹ thuật: Chuyên môn thực hành với các dịch vụ GenAI, di chuyển và hiện đại hóa của AWS "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nong Quốc An\nSố điện thoại: 0896413154\nEmail: nongan786@gmail.com\nTrường: Đại học FPT\nNgành: Trí tuệ nhân tạo\nLớp: AWS092025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/09/2025 đến ngày 25/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Tăng cường năng suất của tổ chức bạn với tiện ích mở rộng Amazon Q Business browser Tác giả: Abhinand Sukumar và Firaz Akmal | NXB: 17 TH9 2025 | Trong: Amazon Q Business, Technical How-to\nCác giải pháp Generative AI (AI tạo sinh) như Amazon Q Business đang chuyển đổi cách nhân viên làm việc. Các tổ chức trong mọi ngành công nghiệp đang đón nhận những công cụ này để giúp lực lượng lao động của họ trích xuất những hiểu biết giá trị từ dữ liệu ngày càng phân mảnh để đẩy nhanh quá trình ra quyết định.\nTuy nhiên, việc áp dụng các công cụ Generative AI không phải là không có những thách thức. Hai trở ngại đã nổi lên trong việc triển khai các giải pháp Generative AI. Thứ nhất, người dùng thường thấy mình buộc phải từ bỏ quy trình làm việc quen thuộc, tự chuyển dữ liệu sang một trợ lý AI để phân tích. Điều này tạo ra những khó khăn không cần thiết và làm tăng thời gian tạo ra giá trị. Thứ hai, việc thiếu công cụ Generative AI trong các phần mềm thường được sử dụng sẽ gây nên những khó khăn cho nhân viên trong việc xác định những cơ hội mà AI có thể tăng năng suất của họ một cách đáng kể.\nBước vào Amazon Q Business, một trợ lý được hỗ trợ bởi Generative AI được thiết kế riêng cho nơi làm việc hiện đại, để bạn có thể tham gia vào các cuộc trò chuyện, giải quyết các vấn đề phức tạp và hành động bằng cách kết nối liền mạch với dữ liệu công ty và các hệ thống doanh nghiệp. Amazon Q Business cung cấp cho nhân viên quyền truy cập tức thì vào thông tin và lời khuyên liên quan, hợp lý hóa các tác vụ, đẩy nhanh quá trình ra quyết định, đồng thời thúc đẩy sự sáng tạo và đổi mới tại nơi làm việc.\nGần đây, chúng tôi đã ra mắt tiện ích mở rộng Amazon Q Business browser trong Amazon Q Business và hiện nó đã có sẵn cho người đăng ký Amazon Q Business (Lite và Pro). Tiện ích mở rộng Amazon Q Business browser mang sức mạnh của Amazon Q Business trực tiếp vào trình duyệt của bạn, để bạn có thể nhận được hỗ trợ Generative AI nhận biết theo ngữ cảnh và nhận trợ giúp trực tiếp cho các tác vụ hàng ngày.\nTrong bài đăng này, chúng tôi sẽ chỉ ra cách triển khai giải pháp này cho doanh nghiệp của riêng bạn, cung cấp cho nhóm của bạn quyền truy cập liền mạch vào các thông tin chi tiết dựa trên AI.\nCác use case cho Amazon Q Business browser extension Tiện ích mở rộng Amazon Q Business browser được triển khai cho tất cả Amazonians, giúp hàng chục nghìn người dùng làm việc hiệu quả hơn mỗi ngày. Trong phần này, chúng tôi nêu bật một số use case có tác động lớn nhất mà các Amazonians sử dụng tiện ích mở rộng Amazon Q Business browser để tăng năng suất.\nPhân tích nội dung web Các đội ngũ kinh doanh và kỹ thuật cần phân tích và tổng hợp thông tin trên nhiều báo cáo, phân tích cạnh tranh và tài liệu ngành được tìm thấy bên ngoài dữ liệu của công ty để phát triển insight và chiến lược. Họ phải đảm bảo các khuyến nghị chiến lược của mình dựa trên các nguồn dữ liệu đã được xác minh và thông tin ngành đáng tin cậy. Ngoài ra, việc xác định pattern trên nhiều nguồn là tốn thời gian và phức tạp.\nVới tiện ích mở rộng Amazon Q Business browser, các strategist có thể nhanh chóng tạo ra insight ngành và xác định các trend trên các nguồn dữ liệu nội bộ và bên ngoài đáng tin cậy chỉ trong vài giây, đồng thời vẫn duy trì yếu tố con người trong tư duy chiến lược.\nHãy xem video demo sau đây:\nCải thiện chất lượng nội dung Tiện ích mở rộng Amazon Q Business browser mang đến khả năng độc đáo để kết hợp ngữ cảnh mà có thể không dễ dàng có được đối với trợ lý AI tạo sinh của bạn. Bạn có thể sử dụng tiện ích mở rộng Amazon Q Business browser để tạo nội dung và cải thiện chất lượng nội dung bằng cách bao gồm nhiều nguồn rời rạc trong các truy vấn của bạn mà thông thường không có sẵn cho các trợ lý AI tạo sinh.\nBạn có thể sử dụng nó để thực hiện xác thực nội dung theo thời gian thực từ nhiều nguồn khác nhau và kết hợp các style guide và best practice dựa trên web để đẩy nhanh quá trình tạo nội dung.\nXem video demo sau:\nTổng quan giải pháp Trong các phần sau, chúng tôi sẽ hướng dẫn cách bắt đầu với tiện ích mở rộng Amazon Q Business browser nếu bạn đã kích hoạt Amazon Q Business cho tổ chức của mình. Để tìm hiểu thêm, hãy xem phần Cấu hình tiện ích mở rộng Amazon Q Business browser để sử dụng.\nCác điều kiện tiên quyết Hoàn thành các bước điều kiện tiên quyết trong phần này trước khi triển khai tiện ích mở rộng trình duyệt.\nTạo một ứng dụng Amazon Q Business và subscribe user của bạn Tiện ích mở rộng Amazon Q Business browser là một tính năng của Amazon Q Business và yêu cầu khách hàng trước tiên phải tạo một ứng dụng Amazon Q Business và đăng ký người dùng của họ trước khi tiện ích mở rộng trình duyệt có thể được kích hoạt. Để tìm hiểu thêm về cách bạn có thể bắt đầu với Amazon Q Business, hãy xem Getting started with Amazon Q Business.\nThiết lập Amazon Q Business web experience Tiện ích mở rộng sử dụng client Amazon Q Business web experience như một cơ chế để xác thực người dùng và cung cấp các tính năng của Amazon Q Business. Bước đầu tiên để bật tiện ích mở rộng là tạo một Amazon Q Business web experience. Nếu bạn đã tạo một web experience cho người dùng của mình, bạn có thể bỏ qua bước này.\nTuy nhiên, nếu bạn đã phát triển một custom web experience bằng cách sử dụng Amazon Q Business APIs, hãy hoàn thành các bước sau để tạo một Amazon Q Business web experience:\nTrên Amazon Q Business console, đi tới Amazon Q Business application của bạn.\nPhần Web experience settings hiển thị liệu bạn đã có một web experience được triển khai hay chưa.\nNếu bạn chưa triển khai web experience, phần này sẽ trống, với thông báo “A web experience needs to be created before deploying.”\nỞ đầu trang application của bạn, chọn Edit.\nĐối với Outcome, chọn Web experience.\nChọn Update.\nBước này có thể mất vài phút để hoàn tất. Sau khi web experience của bạn được triển khai, bạn sẽ tìm thấy một URL nơi web experience của bạn được lưu trữ trên trang chi tiết ứng dụng Amazon Q Business của bạn. Lưu lại URL này để sử dụng sau.\n!https://www.reddit.com/r/privacy/comments/1ccv1yg/what_is_the_windows_web_experience_pack_is_it/?tl=vi(https://i.imgur.com/R3x3W0c.png)\nCấp quyền cho người dùng gửi truy vấn trực tiếp đến large language model Tiện ích mở rộng Amazon Q Business browser có thể đưa ngữ cảnh trang web của người dùng vào truy vấn bằng cách gửi nội dung trang web dưới dạng tệp đính kèm cùng với prompt của người dùng. Vì tính năng tệp đính kèm chỉ khả dụng cho General knowledge mode, tiện ích mở rộng yêu cầu admin Amazon Q Business cấp quyền cho người dùng gửi truy vấn trực tiếp đến large language model (LLM) để tận dụng đầy đủ bộ tính năng của tiện ích mở rộng.\nNếu không có điều kiện tiên quyết này, người dùng chỉ có thể truy cập knowledge của công ty thông qua tiện ích mở rộng và không thể hỏi Amazon Q Business về nội dung trang web của họ.\nAmazon Q Business không lưu trữ dữ liệu hội thoại của người dùng và không sử dụng truy vấn hay hội thoại để huấn luyện các LLM của mình. Các hội thoại chỉ được lưu trong ứng dụng trong 30 ngày. Bạn có thể xóa các hội thoại này bằng cách truy cập Amazon Q Business web experience và chọn Chat trong bảng điều hướng, như minh họa trong ảnh chụp màn hình sau.\nĐể cấp quyền cho người dùng gửi truy vấn trực tiếp đến Amazon Q LLM, hãy hoàn thành các bước sau:\nTrên Amazon Q Business console, đi tới ứng dụng của bạn.\nChọn Admin controls and guardrails trong bảng điều hướng.\nTrong phần Global controls, chọn Edit.\nSelect Allow end users to send queries directly to the LLM.\nChoose Save.\nBây giờ bạn đã sẵn sàng để bật tiện ích mở rộng trình duyệt cho người dùng của mình.\nCấu hình tiện ích mở rộng Amazon Q Business browser Bây giờ bạn đã hoàn thành các điều kiện tiên quyết cho tiện ích mở rộng trình duyệt, hãy hoàn thành các bước sau để kích hoạt tiện ích mở rộng trình duyệt cho người dùng của bạn:\nTrên bảng điều khiển Amazon Q Business, đi đến ứng dụng của bạn.\nTrong phần Enhancements trong bảng điều hướng, chọn Integrations.\nTrong phần Browser extensions, chọn Edit.\nChọn các hộp kiểm cho tiện ích mở rộng trình duyệt bạn muốn kích hoạt:\nHộp kiểm Chromium kích hoạt tiện ích mở rộng của Chrome store, hỗ trợ các trình duyệt Google Chrome và Microsoft Edge. Hộp kiểm Firefox kích hoạt tiện ích bổ sung Firefox Browser cho các trình duyệt Firefox. Bạn cũng có thể xem các trang cửa hàng Chrome hoặc Firefox cho tiện ích mở rộng bằng cách sử dụng các liên kết trong các phần Learn more tương ứng.\nChọn Save.\nNgười dùng của bạn bây giờ sẽ thấy hướng dẫn cài đặt tiện ích mở rộng Amazon Q Business browser vào lần tiếp theo họ đăng nhập vào Amazon Q Business web experience. Nếu bạn chưa thực hiện, hãy chia sẻ URL web experience mà bạn đã nhận được ở các bước trước với người dùng của mình để họ có thể làm theo các bước để cài đặt tiện ích mở rộng trình duyệt.\nKích hoạt tiện ích mở rộng nếu bạn dùng xác thực liên kết IAM (IAM federation) cho Amazon Q Business Nếu bạn đang sử dụng nhà cung cấp danh tính bên ngoài (IdP) cho ứng dụng Amazon Q Business, bạn phải đưa tiện ích mở rộng vào danh sách cho phép (allow-list) với nhà cung cấp đó trước khi người dùng có thể bắt đầu sử dụng tiện ích.\nHãy allow-list các URL sau với IdP để kích hoạt tiện ích mở rộng:\nĐối với tiện ích mở rộng cho trình duyệt Chromium (phù hợp với Google Chrome và Microsoft Edge): https://feihpdljijcgnokhfoibicengfiellbp.chromiumapp.org/ Đối với tiện ích mở rộng cho Mozilla Firefox: https://ba6e8e6e4fa44c1057cf5f26fba9b2e788dfc34f.extensions.allizom.org/ Bạn không cần thực hiện các bước trên nếu đang dùng AWS IAM Identity Center làm giải pháp xác thực cho ứng dụng Amazon Q Business.\nBắt đầu với tiện ích mở rộng trình duyệt Sau khi bạn chia sẻ URL web experience với người dùng, họ có thể dùng URL này để tìm trang cửa hàng của tiện ích và cài đặt. Người dùng thực hiện các bước sau:\nĐăng nhập vào Amazon Q Business web experience do quản trị viên cung cấp.\nBạn sẽ thấy một banner thông báo quản trị viên đã bật tiện ích mở rộng cho bạn.\nChọn Install extension.\nLiên kết sẽ đưa bạn tới trang cửa hàng phù hợp của tiện ích mở rộng Amazon Q Business dựa trên trình duyệt bạn đang dùng.\nChọn Add to Chrome hoặc tùy chọn cài đặt tương ứng với trình duyệt của bạn.\nSau khi cài đặt, bạn sẽ thấy tiện ích trong thanh công cụ của trình duyệt, mục Extensions.\nBạn có thể chọn biểu tượng ghim để ghim tiện ích.\nKhi mở tiện ích, bạn sẽ thấy một khung bên như trong ảnh minh họa.\nTiện ích sẽ tự động phát hiện URL web experience đúng từ các tab đang mở để hỗ trợ bạn đăng nhập.\nNếu không, hãy nhập URL web experience do quản trị viên cung cấp vào phần Amazon Q URL và chọn Sign in.\nSau khi đăng nhập, bạn đã sẵn sàng! Tham khảo phần trước về các use case của Amazon để lấy cảm hứng sử dụng tiện ích nhằm tăng năng suất.\nTriển khai Tiện ích mở rộng Amazon Q Business thay mặt người dùng Một số quản trị viên có thể chọn triển khai trực tiếp tiện ích mở rộng Amazon Q Business trên trình duyệt của người dùng để hợp lý hóa và đẩy nhanh quá trình áp dụng. Các doanh nghiệp sử dụng phần mềm quản lý thiết bị di động (MDM) khác nhau và có các yêu cầu khác nhau đối với chính sách trình duyệt của họ.\nĐể triển khai tiện ích mở rộng Amazon Q Business, hãy tham khảo các tài nguyên sau:\nMozilla Firefox: policy settings Google Chrome: policy settings Microsoft Edge: Policy settings Reference guide Tùy chỉnh Tiện ích mở rộng Amazon Q Business cho doanh nghiệp của bạn Một số quản trị viên có thể chọn tùy chỉnh giao diện của tiện ích mở rộng Amazon Q Business để phù hợp với nhu cầu của doanh nghiệp. Phần này phác thảo chức năng tùy chỉnh được hỗ trợ của tiện ích mở rộng và các giá trị chính sách tiện ích mở rộng trình duyệt tương ứng để cấu hình trên trình duyệt của người dùng.\nXóa trường nhập Amazon Q Business URL khỏi trang đăng nhập tiện ích mở rộng trình duyệt Nếu bạn không muốn yêu cầu người dùng nhập URL Amazon Q Business web experience khi đăng nhập, bạn có thể đặt URL mặc định thay mặt họ bằng cách đặt chính sách Q_BIZ_BROWSER_EXTENSION_URL thành URL Amazon Q Business web experience phù hợp cho người dùng của bạn.\nThay thế biểu tượng thanh công cụ của tiện ích mở rộng trình duyệt Bạn có thể sửa đổi biểu tượng thanh công cụ của tiện ích mở rộng trình duyệt bằng cách đặt giá trị của một hoặc nhiều khóa chính sách trình duyệt sau thành URL hình ảnh PNG hoặc SVG của bạn hoặc một datauri hợp lệ cho người dùng của bạn:\n`Q_BIZ_BROWSER_EXTENSION_ICON_128 "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Xây dựng Agentic Workflows với OpenAI GPT OSS trên Amazon SageMaker AI và Amazon Bedrock AgentCore bởi: Vivek Gangasani and Surya Kari | NXB: 17 TH9 2025 | trong: Amazon Bedrock, Amazon SageMaker AI, Amazon SageMaker Unified Studio, Artificial Intelligence, Customer Solutions\nOpenAI đã phát hành hai mô hình open-weight, gpt-oss-120b (117 tỷ tham số) và gpt-oss-20b (21 tỷ tham số), cả hai được xây dựng theo kiến trúc Mixture of Experts (MoE) và sử dụng cửa sổ ngữ cảnh 128K. [cite: 169] Những mô hình này dẫn đầu các mô hình mã nguồn mở, theo Artificial Analysis benchmark, và excel trong khả năng suy luận và workflow agentic. [cite: 170]\nVới Amazon SageMaker AI, bạn có thể fine-tune hoặc tùy chỉnh mô hình và triển khai bằng framework bạn chọn thông qua dịch vụ được quản lý toàn diện. [cite: 171] Amazon SageMaker Inference cho bạn linh hoạt trong việc mang mã và framework inference riêng mà không cần tự xây dựng và duy trì cụm máy chủ. [cite: 172]\nMặc dù các large language model (LLMs) xuất sắc trong việc hiểu ngôn ngữ và sinh nội dung, việc xây dựng các ứng dụng agentic thực tế đòi hỏi quản lý workflow phức tạp, khả năng gọi công cụ (tool calling), và quản lý ngữ cảnh. [cite: 173] Kiến trúc đa agent (multi-agent) giải quyết những thách thức này bằng cách phân chia hệ thống phức tạp thành các thành phần chuyên biệt, nhưng điều này cũng mang lại các phức tạp mới trong phối hợp agent, quản lý bộ nhớ, và điều phối workflow. [cite: 174]\nTrong bài viết này, chúng tôi sẽ chỉ ra cách triển khai mô hình gpt-oss-20b lên các endpoint được quản lý của SageMaker và minh họa ví dụ thực tế về trợ lý agent phân tích cổ phiếu dùng LangGraph — một framework dựa trên đồ thị mạnh mẽ xử lý quản lý trạng thái, workflow phối hợp, và hệ thống bộ nhớ bền vững. [cite: 175] Sau đó, chúng tôi sẽ triển khai các agent lên Amazon Bedrock AgentCore, một lớp điều phối hợp nhất trừu tượng hóa hạ tầng, cho phép bạn triển khai và vận hành các agent AI ở quy mô một cách an toàn. [cite: 176]\nTổng quan giải pháp Trong giải pháp này, chúng tôi xây dựng một agent phân tích cổ phiếu (agentic stock analyzer) với các thành phần chính sau: [cite: 178]\nMô hình GPT OSS 20B được triển khai lên endpoint SageMaker sử dụng vLLM, một framework serving mã nguồn mở cho LLMs [cite: 179] LangGraph để xây dựng framework điều phối đa agent [cite: 180] Amazon Bedrock AgentCore để triển khai các agent [cite: 181] Sơ đồ dưới đây minh họa kiến trúc giải pháp: [cite: 182]\nKiến trúc này minh họa một workflow đa agent được host trên Amazon Bedrock AgentCore Runtime chạy trên AWS. [cite: 183] Người dùng gửi truy vấn, được xử lý bởi pipeline của các agent chuyên biệt — Data Gathering Agent, Stock Performance Analyzer Agent, và Stock Report Generation Agent — mỗi agent chịu trách nhiệm một phần riêng trong quá trình đánh giá cổ phiếu. [cite: 184] Các agent này phối hợp trong Amazon Bedrock AgentCore Runtime, và khi cần hiểu hoặc sinh ngôn ngữ, chúng gọi tới một mô hình GPT OSS được host trên SageMaker AI. [cite: 185] Mô hình xử lý đầu vào và trả về kết quả cấu trúc giúp quyết định hành vi agent, cho phép hệ thống agentic hoàn toàn không máy chủ (serverless), mô-đun và có thể mở rộng sử dụng các mô hình mã nguồn mở. [cite: 186]\nYêu cầu trước khi thực hiện Đảm bảo bạn có quota cần thiết cho các instance G6e để triển khai mô hình. [cite: 188] Yêu cầu quota tại đây nếu bạn chưa có. [cite: 189] Nếu đây là lần đầu bạn làm việc với Amazon SageMaker Studio, bạn cần tạo một domain SageMaker trước. [cite: 190] Đảm bảo role IAM của bạn có các quyền cần thiết để triển khai SageMaker Models và Endpoints. [cite: 191] Để biết thêm, xem How Amazon SageMaker AI works with IAM trong SageMaker Developer Guide. [cite: 192] Triển khai mô hình GPT-OSS lên SageMaker Inference Khách hàng muốn tùy chỉnh mô hình và framework có thể triển khai theo cách serverful, nhưng điều này đòi hỏi truy cập GPU, các framework phục vụ, load balancer, và cấu hình hạ tầng. [cite: 194] SageMaker AI cung cấp nền tảng hosting được quản lý hoàn toàn, lo phần cấp phát hạ tầng, driver cần thiết, tải mô hình, và triển khai. [cite: 195]\nMô hình GPT-OSS của OpenAI được khởi chạy với scheme quantization 4-bit (MXFP4), cho phép inference nhanh trong khi giữ tài nguyên thấp. [cite: 196] Những mô hình này có thể chạy trên các instance P5(H100), P6(H200), P4(A100) và G6e(L40). [cite: 197] Các mô hình GPT-OSS là kiến trúc MoE thưa với 128 expert (120B) hoặc 32 expert (20B), trong đó mỗi token được định tuyến tới 4 experts mà không chia sẻ expert. [cite: 198] Sử dụng MXFP4 cho trọng số MoE giúp thu nhỏ kích thước mô hình xuống còn 63 GB (120B) và 14 GB (20B), khiến chúng có thể chạy trên một GPU H100 đơn. [cite: 199]\nĐể triển khai hiệu quả, bạn cần một framework serving mạnh như vLLM. [cite: 200] Để triển khai mô hình, chúng tôi xây dựng một container vLLM với phiên bản mới nhất hỗ trợ các mô hình GPT OSS trên SageMaker AI. [cite: 201] Bạn có thể dùng Docker file và script sau để build container và push lên Amazon Elastic Container Registry (Amazon ECR). [cite: 202] Cách được khuyến nghị là thực hiện trực tiếp từ SageMaker Studio, môi trường JupyterLab được quản lý có truy cập AWS CLI, nơi bạn có thể build và push image lên ECR như một phần của workflow SageMaker. [cite: 203] Ngoài ra, bạn cũng có thể thực hiện các bước tương tự trên một instance Amazon Elastic Compute Cloud (Amazon EC2) có cài Docker. [cite: 204]\nSau khi bạn đã build và push container lên Amazon ECR, bạn có thể mở SageMaker Studio qua console SageMaker AI, như minh họa trong screenshot dưới đây: [cite: 205]\nSau đó bạn có thể tạo không gian Jupyter hoặc dùng không gian có sẵn để mở JupyterLab và chạy notebook. [cite: 206]\nClone notebook sau và chạy “Option 3: Deploying from HF using BYOC.” [cite: 207] Cập nhật các tham số cần thiết, như image inference trong notebook với image container. [cite: 208] Chúng tôi cũng cung cấp các biến môi trường cần thiết, như sau: [cite: 209]\n# inference_image = f\u0026#34;{account_id}.dkr.ecr.{region}[.amazonaws.com/vllm:v0.10.0-gpt-oss](https://.amazonaws.com/vllm:v0.10.0-gpt-oss)\u0026#34; instance_type = \u0026#34;ml.g6e.4xlarge\u0026#34; num_gpu = 1 model_name = sagemaker.utils.name_from_base(\u0026#34;model-byoc\u0026#34;) endpoint_name = model_name inference_component_name = f\u0026#34;ic-{model_name}\u0026#34; config = { \u0026#34;OPTION_MODEL\u0026#34;: \u0026#34;openai/gpt-oss-20b\u0026#34;, \u0026#34;OPTION_SERVED_MODEL_NAME\u0026#34;: \u0026#34;model\u0026#34;, \u0026#34;OPTION_TENSOR_PARALLEL_SIZE\u0026#34;: json.dumps(num_gpu), \u0026#34;OPTION_ASYNC_SCHEDULING\u0026#34;: \u0026#34;true\u0026#34;, } [cite_start]Sau khi bạn thiết lập cấu hình triển khai, bạn có thể deploy lên SageMaker AI bằng mã sau: [cite: 211]\n# from sagemaker.compute_resource_requirements.resource_requirements import ResourceRequirements lmi_model = sagemaker.Model( image_uri=inference_image, env=config, role=role, name=model_name, ) lmi_model.deploy( initial_instance_count=1, instance_type=instance_type, container_startup_health_check_timeout=600, endpoint_name=endpoint_name, endpoint_type=sagemaker.enums.EndpointType.INFERENCE_COMPONENT_BASED, inference_component_name=inference_component_name, resources=ResourceRequirements(requests={\u0026#34;num_accelerators\u0026#34;: num_gpu, \u0026#34;memory\u0026#34;: 1024*5, \u0026#34;copies\u0026#34;: 1,}), ) [cite_start]Bạn có thể chạy một ví dụ inference: [cite: 213]\n# payload={ \u0026#34;messages\u0026#34;: [ {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Name popular places to visit in London?\u0026#34;\u0026#34;} ], } res = llm.predict(payload) print(\u0026#34;-----\\n\u0026#34; + res[\u0026#34;choices\u0026#34;][0][\u0026#34;message\u0026#34;][\u0026#34;content\u0026#34;] + \u0026#34;\\n-----\\n\u0026#34;) print(res[\u0026#34;usage\u0026#34;]) # Output: # ----- # Here are some of the must-see spots in London -- a mix of iconic landmarks, world-class museums, and vibrant neighborhoods: # | # | Place | Why It\u0026#39;s Popular ||---|-------|------------------| # | 1 | **Buckingham Palace** | The Queen\u0026#39;s official London residence - watch the Changing of the Guard. | # | 2 | **The Tower of London \u0026amp; Tower Bridge** | Historic castle, Crown Jewels, and the iconic bridge with glass floors. | # | 3 | **The British Museum** | World-famous collection from the Rosetta Stone to Egyptian mummies (free entry). | # ... (Phần còn lại của bảng) ... # |15 | **Oxford Street \u0026amp; Regent Street** | Prime shopping streets for fashion, flagship stores, and historic architecture. | # These spots cover history, culture, shopping, and leisure--perfect for a first visit or a weekend escape in London! # ----- Dùng LangGraph để xây dựng agent phân tích cổ phiếu [cite_start]Đối với hệ thống đa agent phân tích cổ phiếu của chúng tôi, chúng tôi sử dụng LangGraph để điều phối workflow. [cite: 218] Jupyter notebook cho mã nằm trong Github repository này. [cite_start]Hệ thống bao gồm ba công cụ chuyên biệt làm việc cùng nhau để phân tích cổ phiếu toàn diện: [cite: 219]\n[cite_start]gather_stock_data tool thu thập dữ liệu cổ phiếu toàn diện cho mã cổ phiếu cho trước, bao gồm giá hiện tại, hiệu suất lịch sử, các chỉ số tài chính và dữ liệu thị trường. [cite: 220] [cite_start]Nó trả về thông tin định dạng bao gồm lịch sử giá, cơ bản công ty, các chỉ số giao dịch, và tiêu đề tin tức gần đây. [cite: 221] [cite_start]analyze_stock_performance tool thực hiện phân tích kỹ thuật và cơ bản chi tiết của dữ liệu cổ phiếu, tính các chỉ số như xu hướng giá, độ biến động, và điểm đầu tư tổng thể. [cite: 222] [cite_start]Nó đánh giá nhiều yếu tố bao gồm tỉ lệ P/E, biên lợi nhuận, và lợi suất cổ tức để cung cấp phân tích hiệu suất toàn diện. [cite: 223] [cite_start]generate_stock_report tool tạo báo cáo PDF chuyên nghiệp từ dữ liệu cổ phiếu thu thập và phân tích, tự động upload lên Amazon S3 với thư mục theo ngày. [cite: 224] [cite_start]Để test cục bộ, bạn có thể dùng phiên bản đơn giản của hệ thống bằng cách import các hàm cần thiết từ script cục bộ của bạn. [cite: 225] [cite_start]Ví dụ: [cite: 226]\n# from langgraph_stock_local import langgraph_stock_sagemaker # Test the agent locally result = langgraph_stock_sagemaker({ \u0026#34;prompt\u0026#34;: \u0026#34;Analyze SIM_STOCK Stock for Investment purposes.\u0026#34; }) print(result) [cite_start]Cách này giúp bạn lặp logic của agent nhanh chóng trước khi deploy lên nền tảng có thể mở rộng, đảm bảo mỗi thành phần hoạt động đúng và workflow tổng thể cho kết quả mong đợi cho nhiều loại cổ phiếu khác nhau. [cite: 228]\nTriển khai lên Amazon Bedrock AgentCore [cite_start]Sau khi bạn phát triển và test LangGraph framework cục bộ, bạn có thể triển khai nó lên Amazon Bedrock AgentCore Runtime. [cite: 230] [cite_start]Amazon Bedrock AgentCore xử lý phần lớn việc điều phối container, quản lý phiên (session), khả năng mở rộng và trừu tượng hóa quản lý hạ tầng. [cite: 231] [cite_start]Nó cung cấp môi trường thực thi bền vững có thể giữ trạng thái agent qua nhiều lần gọi. [cite: 232]\n[cite_start]Trước khi triển khai agent phân tích cổ phiếu lên AgentCore Runtime, chúng ta cần tạo AWS Identity and Access Management role IAM với quyền phù hợp. [cite: 233] [cite_start]Role này cho phép AgentCore gọi endpoint SageMaker của bạn để inference mô hình GPT-OSS, quản lý kho container ECR, ghi log Amazon CloudWatch để giám sát và debugging, truy cập dịch vụ workload của AgentCore cho runtime, và gửi telemetry data tới AWS X-Ray và CloudWatch để quan sát. [cite: 234]\n[cite_start]Mã như sau: [cite: 235]\n# from create_agentcore_role import create_bedrock_agentcore_role role_arn = create_bedrock_agentcore_role( role_name=\u0026#34;MyStockAnalyzerRole\u0026#34;, sagemaker_endpoint_name=\u0026#34;your-endpoint-name\u0026#34;, region=\u0026#34;us-west-2\u0026#34; ) [cite_start]Sau khi tạo role, bạn dùng Amazon Bedrock AgentCore Starter Toolkit để triển khai agent. [cite: 237] [cite_start]Toolkit đơn giản hóa quy trình triển khai bằng cách đóng gói mã, tạo image container, và cấu hình môi trường runtime: [cite: 238]\n# from bedrock_agentcore_starter_toolkit import Runtime agentcore_runtime = Runtime() # Configure the agent response = agentcore_runtime.configure( entrypoint=\u0026#34;langgraph_stock_sagemaker_gpt_oss.py\u0026#34;, execution_role=role_arn, auto_create_ecr=True, requirements_file=\u0026#34;requirements.txt\u0026#34;, region=\u0026#34;us-west-2\u0026#34;, agent_name=\u0026#34;stock_analyzer_agent\u0026#34; ) # Deploy to the cloud launch_result = agentcore_runtime.launch(local=False, local_build=False) [cite_start]Khi bạn dùng BedrockAgentCoreApp, nó tự động tạo HTTP server lắng nghe tại cổng 8080, triển khai endpoint /invocations để xử lý yêu cầu agent, endpoint /ping để kiểm tra sức khỏe (rất quan trọng cho agent bất đồng bộ), xử lý đúng content types và định dạng phản hồi, và quản lý error theo tiêu chuẩn AWS. [cite: 240]\n[cite_start]Sau khi bạn deploy lên AgentCore Runtime, trạng thái sẽ hiển thị Ready trên console Amazon Bedrock AgentCore. [cite: 241]\nGọi agent [cite_start]Sau khi bạn tạo agent, bạn phải thiết lập điểm entry để gọi agent. [cite: 243] [cite_start]Với Amazon AgentCore Runtime, chúng ta dùng decorator @app.entrypoint cho phần gọi agent và sử dụng đó làm điểm entry runtime. [cite: 244]\n[cite_start]Sau khi deploy agent lên AgentCore Runtime, bạn gọi nó bằng AWS SDK: [cite: 245]\n# import boto3 import json agentcore_client = boto3.client(\u0026#39;bedrock-agentcore\u0026#39;, region_name=\u0026#39;us-west-2\u0026#39;) response = agentcore_client.invoke_agent_runtime( agentRuntimeArn=launch_result.agent_arn, qualifier=\u0026#34;DEFAULT\u0026#34;, payload=json.dumps({ \u0026#34;prompt\u0026#34;: \u0026#34;Analyze SIM_STOCK for investment purposes\u0026#34; }) ) [cite_start]Sau khi gọi agent phân tích cổ phiếu qua AgentCore Runtime, bạn phải parse và format phản hồi để hiển thị rõ ràng. [cite: 247] [cite_start]Xử lý phản hồi gồm các bước: [cite: 248]\n[cite_start]Giải mã byte stream từ AgentCore thành văn bản đọc được. [cite: 249] [cite_start]Parse JSON phản hồi chứa phân tích cổ phiếu hoàn chỉnh. [cite: 250] [cite_start]Trích ba phần chính bằng regex pattern matching: [cite: 251] [cite_start]Stock Data Gathering Section: Trích các thông tin cốt lõi như mã cổ phiếu, thông tin công ty, giá hiện tại, các chỉ số thị trường, các tỉ số tài chính, dữ liệu giao dịch, và tiêu đề tin tức gần đây. [cite: 252] [cite_start]Performance Analysis section: Phân tích chỉ số kỹ thuật, chỉ số cơ bản, và độ biến động để tạo ra phân tích toàn diện về cổ phiếu. [cite: 253] [cite_start]Stock Report Generation Section: Tạo báo cáo PDF chi tiết với tất cả các phân tích kỹ thuật cổ phiếu. [cite: 254] [cite_start]Hệ thống cũng bao gồm xử lý lỗi graceful nếu có lỗi parse JSON, fallback sang hiển thị văn bản nếu parse cấu trúc thất bại, và cung cấp thông tin debugging để xử lý lỗi parsing phân tích cổ phiếu. [cite: 255] # stock_analysis = parse_bedrock_agentcore_stock_response(invoke_response) [cite_start]Đầu ra đã format giúp dễ dàng xem quy trình ra quyết định của agent và trình bày kết quả phân tích cổ phiếu chuyên nghiệp cho các bên liên quan, hoàn thiện workflow từ triển khai mô hình đến kết quả kinh doanh có ý nghĩa: [cite: 257]\n# STOCK DATA GATHERING REPORT: ================================ Stock Symbol: SIM_STOCK Company Name: Simulated Stock Inc. Sector: SIM_SECTOR Industry: SIM INDUSTRY CURRENT MARKET DATA: - Current Price: $29.31 - Market Cap: $3,958 - 52-Week High: $29.18 - 52-Week Low: $16.80 - YTD Return: 1.30% - Volatility (Annualized): 32.22% FINANCIAL METRICS: - P/E Ratio: 44.80 - Forward P/E: 47.59 - Price-to-Book: 11.75 - Dividend Yield: 0.46% - Revenue (TTM): $4,988 - Profit Margin: 24.30% STOCK PERFORMANCE ANALYSIS: =============================== Stock: SIM_STOCK | Current Price: $29.31 TECHNICAL ANALYSIS: - Price Trend: SLIGHT UPTREND - YTD Performance: 1.03% - Technical Score: 3/5 FUNDAMENTAL ANALYSIS: - P/E Ratio: 34.80 - Profit Margin: 24.30% - Dividend Yield: 0.46% - Beta: 1.165 - Fundamental Score: 3/5 STOCK REPORT GENERATION: =============================== Stock: SIM_STOCK Sector: SIM_INDUSTRY Current Price: $29.78 REPORT SUMMARY: - Technical Analysis: 8.33% YTD performance - Report Type: Comprehensive stock analysis for informational purposes - Generated: 2025-09-04 23:11:55 PDF report uploaded to S3: s3://amzn-s3-demo-bucket/2025/09/04/SIM_STOCK_Stock_Report_20250904_231155.pdf REPORT CONTENTS: • Executive Summary with key metrics • Detailed market data and financial metrics • Technical and fundamental analysis • Professional formatting for documentation Dọn dẹp [cite_start]Bạn có thể xóa endpoint SageMaker để tránh phát sinh chi phí sau khi test bằng cách chạy các ô sau trong cùng notebook: [cite: 262]\n# sess.delete_inference_component(inference_component_name) sess.delete_endpoint(endpoint_name) sess.delete_endpoint_config(endpoint_name) sess.delete_model(model_name) [cite_start]Bạn cũng có thể xóa các tài nguyên của Amazon Bedrock AgentCore bằng các lệnh sau: [cite: 264]\n# runtime_delete_response = agentcore_control_client.delete_agent_runtime(agentRuntimeId=launch_result.agent_id) response = ecr_client.delete_repository(repositoryName=launch_result.ecr_uri.split(\u0026#39;/\u0026#39;)[1],force=True) Kết luận [cite_start]Trong bài viết này, chúng tôi đã xây dựng giải pháp end-to-end để triển khai các mô hình OpenAI open-weight trên một GPU G6e(L40s) duy nhất, tạo hệ thống phân tích cổ phiếu đa agent với LangGraph và triển khai liền mạch với Amazon Bedrock AgentCore. [cite: 267] [cite_start]Triển khai này cho thấy tổ chức giờ đây có thể sử dụng các LLM mã nguồn mở mạnh mẽ với hiệu quả chi phí thông qua các framework serving như vLLM. [cite: 268]\n[cite_start]Bên cạnh phần triển khai kỹ thuật, việc nâng cấp workflow này có thể đem lại giá trị kinh doanh đáng kể, chẳng hạn giảm thời gian xử lý phân tích cổ phiếu, tăng năng suất của nhà phân tích bằng cách tự động hóa các đánh giá cổ phiếu định kỳ. [cite: 269] [cite_start]Hơn nữa, bằng cách giải phóng nhà phân tích khỏi các tác vụ lặp đi lặp lại, tổ chức có thể chuyển các chuyên gia có kỹ năng sang xử lý các trường hợp phức tạp và xây dựng mối quan hệ — những hoạt động có thể thúc đẩy tăng trưởng kinh doanh. [cite: 270] [cite_start]Chúng tôi mời bạn thử các code sample của chúng tôi và lặp lại các workflow agentic để đáp ứng các trường hợp sử dụng của bạn. [cite: 271]\nVề các tác giả [cite_start]Vivek Gangasani là Worldwide Lead GenAI Specialist Solutions Architect cho SageMaker Inference. [cite: 273] [cite_start]Anh phụ trách chiến lược Go-to-Market (GTM) và Outbound Product strategy cho SageMaker Inference. [cite: 274] [cite_start]Vivek cũng hỗ trợ các doanh nghiệp và startup trong việc triển khai, quản lý và mở rộng mô hình GenAI của họ bằng SageMaker và GPU. [cite: 275] [cite_start]Hiện tại, anh tập trung vào việc phát triển chiến lược và giải pháp tối ưu hiệu năng inference cũng như hiệu suất GPU cho việc lưu trữ các Large Language Models (LLMs). [cite: 276] [cite_start]Trong thời gian rảnh, Vivek thích leo núi, xem phim, và thử các món ăn khác nhau. [cite: 277]\n[cite_start]Surya Kari là Senior Generative AI Data Scientist tại AWS, chuyên phát triển các giải pháp tận dụng foundation models tiên tiến. [cite: 278] [cite_start]Anh có nhiều kinh nghiệm làm việc với các advanced language models như DeepSeek-R1, Llama family, và Qwen, tập trung vào fine-tuning và tối ưu hóa chúng cho các ứng dụng khoa học chuyên biệt. [cite: 279] [cite_start]Kinh nghiệm của anh bao gồm việc triển khai pipeline huấn luyện hiệu quả và chiến lược triển khai mô hình bằng AWS SageMaker, giúp mở rộng foundation models từ giai đoạn phát triển đến sản xuất. [cite: 280] [cite_start]Surya hợp tác với khách hàng để thiết kế và triển khai giải pháp Generative AI, giúp họ định hướng trong việc lựa chọn mô hình, phương pháp fine-tuning, và chiến lược triển khai nhằm đạt được hiệu năng tối ưu cho từng trường hợp cụ thể. [cite: 281]\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.6-week6/1.6.1-day26-2025-10-13/","title":"Day 26 - Database Fundamentals","tags":[],"description":"","content":" ⚠️ Bản dịch tiếng Việt đang được cập nhật. Vui lòng xem nội dung chi tiết trong file _index.md (tiếng Anh).\nNội dung tiếng Việt sẽ được bổ sung sớm để phản ánh đầy đủ các ghi chú và bài lab.\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.7-week7/1.7.1-day31-2025-10-20/","title":"Day 31 - Vertical Slice Kickoff","tags":[],"description":"","content":" ⚠️ Bản dịch tiếng Việt đang được cập nhật. Vui lòng xem nội dung chi tiết trong file _index.md (tiếng Anh).\nNội dung tiếng Việt sẽ được bổ sung sớm để phản ánh đầy đủ các ghi chú và bài lab.\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.1-week1/1.1.1-day01-2025-09-08/","title":"Ngày 01 - Giới thiệu về Điện toán Đám mây","tags":[],"description":"","content":"Ngày: 2025-09-08\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Điện toán Đám mây là gì? Hình thức cung cấp tài nguyên CNTT theo nhu cầu thông qua Internet với mô hình trả phí theo mức sử dụng. Lợi ích của Điện toán Đám mây Chỉ trả tiền cho phần tài nguyên thực tế sử dụng, tối ưu chi phí. Tăng tốc phát triển nhờ dịch vụ quản lý và tự động hóa. Mở rộng/thu hẹp tài nguyên linh hoạt theo nhu cầu. Triển khai ứng dụng toàn cầu chỉ trong vài phút. Vì sao chọn AWS? AWS giữ vị trí dẫn đầu thị trường cloud toàn cầu 13 năm liên tiếp (tính đến 2023). Văn hóa, tầm nhìn và sự ám ảnh khách hàng rất khác biệt. Triết lý giá: khách hàng nên trả ít hơn theo thời gian cho cùng một lượng tài nguyên. Mọi Nguyên tắc Lãnh đạo của AWS đều hướng đến giá trị thực cho khách hàng. Bắt đầu với AWS như thế nào? Có nhiều lộ trình học – tự học hoàn toàn khả thi. Đăng ký tài khoản AWS Free Tier để khám phá dịch vụ. Gợi ý nền tảng khóa học: Udemy A Cloud Guru Tham khảo thêm các lộ trình chính thức của AWS: AWS Learning Paths "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.2-week2/1.2.1-day06-2025-09-15/","title":"Ngày 06 - Kiến thức Cơ bản về Amazon VPC","tags":[],"description":"","content":"Ngày: 2025-09-15\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Dịch vụ mạng trên AWS Amazon Virtual Private Cloud (VPC) Amazon VPC cho phép triển khai tài nguyên AWS vào một mạng ảo do chính bạn định nghĩa. Mỗi VPC tồn tại trong phạm vi một Region. Khi tạo VPC, cần định nghĩa dải IPv4 CIDR (bắt buộc) và có thể thêm IPv6. Giới hạn mặc định: 5 VPC mỗi Region cho mỗi tài khoản. Thường dùng để tách biệt môi trường Production, Development, Staging. Muốn cô lập hoàn toàn tài nguyên, nên dùng các AWS Account khác nhau thay vì nhiều VPC cùng tài khoản. Subnet Mỗi subnet nằm trong một Availability Zone. CIDR của subnet phải là tập con của CIDR VPC cha. AWS dành sẵn 5 địa chỉ IP trong mỗi subnet: network, broadcast, router, DNS và một địa chỉ dự phòng. Ví dụ các IP được dành trước (10.0.0.0/24):\n10.0.0.0 – Địa chỉ mạng 10.0.0.1 – Router của VPC 10.0.0.2 – Máy chủ DNS 10.0.0.3 – Dành cho sử dụng trong tương lai 10.0.0.255 – Địa chỉ broadcast Hands-On Labs Lab 03 – Amazon VPC \u0026amp; Networking Basics Tạo VPC → 03-03.1 Tạo Subnet → 03-03.2 "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.3-week3/1.3.1-day11-2025-09-22/","title":"Ngày 11 - Kiến thức cơ bản về Amazon EC2","tags":[],"description":"","content":"Ngày: 2025-09-22\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Compute trên AWS Amazon Elastic Compute Cloud (EC2) Amazon EC2 cung cấp năng lực tính toán có thể co giãn trên cloud, tương tự máy chủ ảo hoặc vật lý. Phù hợp cho các workload như web hosting, ứng dụng, cơ sở dữ liệu, dịch vụ xác thực và nhiều tác vụ máy chủ tổng quát khác. Instance Type\nCấu hình EC2 được xác định bởi instance type, không phải phần cứng tự chọn. Mỗi loại quy định: CPU (Intel, AMD, ARM – Graviton 1/2/3) / GPU Bộ nhớ Kết nối mạng Lưu trữ Nhóm instance tiêu biểu:\nGeneral Purpose: T3, T4g, M5, M6i (cân bằng giữa compute, memory, network). Compute Optimized: C5, C6i, C7g (hiệu năng xử lý cao). Memory Optimized: R5, R6i, X2 (tối ưu cho workload dùng nhiều RAM). Storage Optimized: I3, D2, H1 (tốc độ đọc/ghi tuần tự cao trên storage cục bộ). Accelerated Computing: P4, G5, Inf1 (GPU/FPGA cho ML, đồ họa). Amazon Machine Image (AMI) AMI (Amazon Machine Image) là mẫu chứa cấu hình phần mềm của instance, gồm hệ điều hành, ứng dụng và thiết lập. Các loại AMI: AMI do AWS cung cấp (Amazon Linux, Windows, Ubuntu, v.v.). AMI trên AWS Marketplace. AMI tùy chỉnh do người dùng tạo. Lợi ích của AMI tùy chỉnh\nLaunch và cấu hình instance nhanh hơn. Đơn giản hóa sao lưu và khôi phục. Đảm bảo môi trường nhất quán trên nhiều instance. Thành phần AMI:\nMẫu ổ đĩa gốc (OS và ứng dụng). Quyền launch. Ánh xạ thiết bị khối (block device mapping). Hands-On Labs Lab 01 – AWS Account \u0026amp; IAM Setup Tạo tài khoản AWS → 01-01 Cấu hình thiết bị MFA ảo → 01-02 Tạo nhóm Admin và người dùng Admin → 01-03 Cập nhật hỗ trợ xác thực tài khoản → 01-04 "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.4-week4/1.4.1-day16-2025-09-29/","title":"Ngày 16 - Kiến thức cơ bản về Amazon S3","tags":[],"description":"","content":"Ngày: 2025-09-29\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Dịch vụ lưu trữ trên AWS Amazon Simple Storage Service (S3) Amazon S3 là dịch vụ lưu trữ đối tượng, cho phép lưu và truy xuất dữ liệu với quy mô gần như không giới hạn, độ sẵn sàng cao, bảo mật mạnh và hiệu năng tốt.\nTính năng cốt lõi của S3 Bucket và Object: Dữ liệu được lưu dưới dạng object trong bucket. Mỗi object tối đa 5 TB. Availability \u0026amp; Durability: Thiết kế đạt 99,99% availability và 99,999999999% (11 số 9) durability. Bảo mật: Nhiều lớp bảo vệ như IAM, bucket policy, ACL, mã hóa. Khả năng mở rộng: Tự động scale dung lượng và throughput mà không giảm hiệu năng. Cấu trúc object S3:\nKey: Tên/đường dẫn object. Value: Dữ liệu object. Version ID: Dùng khi bật versioning. Metadata: Metadata hệ thống và người dùng. Access Control: Quyền truy cập. S3 Access Points Access Point giúp đơn giản hóa việc quản lý truy cập cho dataset dùng chung.\nKiểm soát theo ứng dụng: Mỗi access point có policy riêng. Đơn giản vận hành: Dễ quản lý quyền cho dataset dùng chung nhiều ứng dụng. Kiểm soát mạng: Có thể cấu hình chỉ cho phép truy cập từ các VPC cụ thể. Các lớp lưu trữ S3 Chọn storage class phù hợp với mô hình truy cập và chi phí:\nS3 Standard: Dữ liệu truy cập thường xuyên; availability và hiệu năng cao nhất. S3 Intelligent-Tiering: Tự động di chuyển object giữa các tier để tối ưu chi phí. S3 Standard-IA: Dữ liệu ít truy cập, vẫn truy xuất mili-giây. S3 One Zone-IA: Tương tự Standard-IA nhưng lưu ở một AZ. S3 Glacier Flexible Retrieval: Lưu trữ chi phí thấp, truy xuất phút–giờ. S3 Glacier Deep Archive: Chi phí thấp nhất, truy xuất ~12 giờ. So sánh storage class:\nClass Độ bền Availability Lưu tối thiểu Thời gian truy xuất Standard 11 số 9 99,99% Không Tức thời Intelligent-Tiering 11 số 9 99,9% Không Tức thời Standard-IA 11 số 9 99,9% 30 ngày Tức thời One Zone-IA 11 số 9 99,5% 30 ngày Tức thời Glacier Flexible 11 số 9 99,99% 90 ngày Phút-giờ Glacier Deep Archive 11 số 9 99,99% 180 ngày 12 giờ Hands-On Labs Lab 57 – Amazon S3 \u0026amp; CloudFront (Phần 1) Tạo S3 Bucket → 57-2.1 Tải dữ liệu lên → 57-2.2 Bật Static Website → 57-3 Cấu hình Public Access Block → 57-4 "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.5-week5/1.5.1-day21-2025-10-06/","title":"Ngày 21 - Shared Responsibility &amp; Kiến thức IAM cơ bản","tags":[],"description":"","content":"Ngày: 2025-10-06\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Bảo mật Mô hình Trách nhiệm chia sẻ (Shared Responsibility Model) Trên môi trường cloud, bảo mật là trách nhiệm được chia sẻ giữa nhà cung cấp và khách hàng. Khách hàng cần cấu hình dịch vụ an toàn, áp dụng best practice và triển khai các kiểm soát bảo mật từ lớp hypervisor trở lên (ứng dụng/dữ liệu). Phạm vi trách nhiệm thay đổi tùy mô hình dịch vụ: Dịch vụ cấp hạ tầng Dịch vụ được quản lý một phần Dịch vụ fully-managed Trách nhiệm của AWS (Security OF the Cloud):\nBảo mật vật lý trung tâm dữ liệu. Hạ tầng phần cứng và mạng. Lớp ảo hóa. Vận hành các dịch vụ managed. Trách nhiệm của khách hàng (Security IN the Cloud):\nMã hóa dữ liệu. Cấu hình mạng. Quản lý truy cập. Bảo mật ứng dụng. Vá OS (đối với EC2). AWS Identity and Access Management (IAM) Root Account Có quyền không giới hạn với mọi dịch vụ/tài nguyên AWS và có thể gỡ mọi quyền đã cấp. Best practice: Tạo và dùng IAM Administrator cho tác vụ hằng ngày. Lưu trữ thông tin root an toàn (dual control). Duy trì email và domain của root hợp lệ, được gia hạn. Bật MFA cho tài khoản root. Tổng quan IAM IAM kiểm soát quyền truy cập dịch vụ/tài nguyên trong tài khoản. Principal bao gồm: root user, IAM user, federated user, IAM role, phiên assumed-role, dịch vụ AWS và người dùng ẩn danh. Ghi nhớ: IAM user không phải là tài khoản AWS riêng. Người dùng mới tạo không có quyền mặc định. Cấp quyền bằng cách gắn policy vào user, group hoặc role. Dùng IAM group để quản lý nhiều user (group không lồng nhau được). Hands-On Labs Lab 48 – IAM Access Keys \u0026amp; Roles (Phần 1) Tạo EC2 Instance → 48-1.1 Tạo S3 Bucket → 48-1.2 Tạo IAM User và Access Key → 48-2.1 "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.8-week8/1.8.1-day36-2025-10-27/","title":"Ngày 36 - Giới thiệu NLP &amp; Tiền xử lý văn bản","tags":[],"description":"","content":"Ngày: 2025-10-27 Trạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú bài giảng Giới thiệu về Xử lý Ngôn ngữ Tự nhiên NLP là gì? NLP cho phép máy tính hiểu, diễn giải và tạo ra ngôn ngữ con người. Ứng dụng: chatbots, phân tích cảm xúc, dịch thuật, trợ lý giọng nói, công cụ tìm kiếm. Thách thức chính: tính mơ hồ, ngữ cảnh, thành ngữ, nhiều ngôn ngữ. Tổng quan quy trình NLP Văn bản thô → Tiền xử lý → Trích xuất đặc trưng → Mô hình → Đầu ra Mỗi giai đoạn chuyển đổi văn bản thành dữ liệu có cấu trúc cho machine learning. Tiền xử lý rất quan trọng - nguyên tắc \u0026ldquo;rác vào, rác ra\u0026rdquo; được áp dụng. Kiến thức cơ bản về tiền xử lý văn bản Tokenization Chia văn bản thành các từ hoặc câu riêng lẻ. Word tokenization: \u0026ldquo;Hello world!\u0026rdquo; → [\u0026ldquo;Hello\u0026rdquo;, \u0026ldquo;world\u0026rdquo;, \u0026ldquo;!\u0026rdquo;] Sentence tokenization: Chia đoạn văn thành các câu. Tầm quan trọng: nền tảng cho tất cả các tác vụ NLP. Chuyển sang chữ thường Chuyển đổi tất cả văn bản sang chữ thường để đảm bảo tính nhất quán. \u0026ldquo;Hello\u0026rdquo; và \u0026ldquo;hello\u0026rdquo; được coi là cùng một từ. Đánh đổi: có thể mất thông tin (ví dụ: tên riêng). Loại bỏ dấu câu \u0026amp; ký tự đặc biệt Làm sạch văn bản bằng cách loại bỏ các ký tự không phải chữ và số. Chỉ giữ lại các từ có ý nghĩa để phân tích. Phụ thuộc vào ngữ cảnh: một số dấu câu có thể mang ý nghĩa. Những hiểu biết quan trọng NLP là cầu nối giữa giao tiếp của con người và sự hiểu biết của máy. Chất lượng tiền xử lý ảnh hưởng trực tiếp đến hiệu suất mô hình. Các tác vụ khác nhau yêu cầu các chiến lược tiền xử lý khác nhau. Luôn kiểm tra dữ liệu của bạn trước và sau khi tiền xử lý. Thực hành Lab Lab 1: Tokenization cơ bản import nltk from nltk.tokenize import word_tokenize, sent_tokenize # Tải dữ liệu cần thiết nltk.download(\u0026#39;punkt\u0026#39;) text = \u0026#34;Natural Language Processing is fascinating! It enables many applications.\u0026#34; # Word tokenization words = word_tokenize(text) print(\u0026#34;Words:\u0026#34;, words) # Sentence tokenization sentences = sent_tokenize(text) print(\u0026#34;Sentences:\u0026#34;, sentences) Lab 2: Làm sạch văn bản import re import string def clean_text(text): # Chữ thường text = text.lower() # Loại bỏ dấu câu text = text.translate(str.maketrans(\u0026#39;\u0026#39;, \u0026#39;\u0026#39;, string.punctuation)) # Loại bỏ số text = re.sub(r\u0026#39;\\d+\u0026#39;, \u0026#39;\u0026#39;, text) # Loại bỏ khoảng trắng thừa text = \u0026#39; \u0026#39;.join(text.split()) return text sample = \u0026#34;Hello World! This is NLP 101.\u0026#34; cleaned = clean_text(sample) print(\u0026#34;Gốc:\u0026#34;, sample) print(\u0026#34;Đã làm sạch:\u0026#34;, cleaned) Lab 3: Khám phá NLTK import nltk # Khám phá khả năng NLTK print(\u0026#34;Phiên bản NLTK:\u0026#34;, nltk.__version__) # Tải tài nguyên bổ sung nltk.download(\u0026#39;stopwords\u0026#39;) nltk.download(\u0026#39;wordnet\u0026#39;) from nltk.corpus import stopwords # Xem stop words tiếng Anh stop_words = set(stopwords.words(\u0026#39;english\u0026#39;)) print(f\u0026#34;Số lượng stop words: {len(stop_words)}\u0026#34;) print(\u0026#34;Mẫu stop words:\u0026#34;, list(stop_words)[:10]) Bài tập thực hành Tokenize một đoạn văn từ cuốn sách yêu thích của bạn Tạo một hàm loại bỏ URLs khỏi văn bản So sánh số lượng từ trước và sau khi tiền xử lý Thử nghiệm với các phương pháp tokenization khác nhau "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.9-week9/1.9.1-day41-2025-11-03/","title":"Ngày 41 - Ôn tập kiến thức cơ bản NLP","tags":[],"description":"","content":"Ngày: 2025-11-03 Trạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú bài giảng Tóm tắt Tuần 8 Các khái niệm NLP cốt lõi được xem lại Quy trình tiền xử lý văn bản\nTokenization: cấp độ từ và câu Chuẩn hóa: chữ thường, loại bỏ ký tự đặc biệt Loại bỏ stop word: quyết định phụ thuộc ngữ cảnh Stemming vs Lemmatization: sự đánh đổi và trường hợp sử dụng Những điểm chính từ Tuần 8\nChất lượng tiền xử lý ảnh hưởng trực tiếp đến hiệu suất mô hình Các tác vụ khác nhau yêu cầu chiến lược tiền xử lý khác nhau Lemmatization thường được ưu tiên cho hệ thống production Luôn xác thực lựa chọn tiền xử lý với trường hợp sử dụng cụ thể Đi sâu: Kỹ thuật Tokenization Tokenization nâng cao Subword Tokenization\nByte Pair Encoding (BPE): xử lý các từ ngoài từ vựng WordPiece: được BERT và các transformer khác sử dụng SentencePiece: tokenization không phụ thuộc ngôn ngữ Trường hợp sử dụng: mô hình đa ngôn ngữ và xử lý từ hiếm So sánh các cách tiếp cận\nPhương pháp Ưu điểm Nhược điểm Tốt nhất cho Word Đơn giản, nhanh Từ vựng lớn Tác vụ đơn giản Character Không có vấn đề OOV Chuỗi dài Tác vụ chính tả Subword Cách tiếp cận cân bằng Phức tạp hơn NLP hiện đại Tokenization biểu thức chính quy Mẫu tùy chỉnh cho văn bản đặc thù lĩnh vực Xử lý URLs, emails, hashtags Bảo toàn dấu câu quan trọng Tokenization văn bản y tế/kỹ thuật Thực hành tốt nhất về chuẩn hóa văn bản Khi nào nên chuẩn hóa Nên chuẩn hóa:\nĐộ nhạy chữ hoa/thường không quan trọng Cần định dạng nhất quán Ràng buộc về bộ nhớ/tính toán Tránh chuẩn hóa quá mức:\nThực thể có tên quan trọng Phân tích cảm xúc (biểu tượng cảm xúc quan trọng) Code hoặc tài liệu kỹ thuật Xử lý Unicode Mã hóa/giải mã đúng cách Các dạng chuẩn hóa (NFC, NFD, NFKC, NFKD) Xử lý văn bản đa ngôn ngữ Bảo toàn emoji và ký tự đặc biệt Những hiểu biết quan trọng Xem lại kiến thức cơ bản tiết lộ sự hiểu biết sâu sắc hơn Các trường hợp biên thường xác định chiến lược tiền xử lý NLP hiện đại ngày càng sử dụng subword tokenization Sự cân bằng giữa đơn giản và hiệu quả là rất quan trọng Thực hành Lab Lab 1: So sánh tiền xử lý toàn diện import nltk from nltk.tokenize import word_tokenize, sent_tokenize from nltk.stem import PorterStemmer, WordNetLemmatizer from nltk.corpus import stopwords import string text = \u0026#34;\u0026#34;\u0026#34; The AI-powered system\u0026#39;s performance improved significantly! Running multiple tests @ 99.9% accuracy. #MachineLearning \u0026#34;\u0026#34;\u0026#34; def compare_preprocessing(text): \u0026#34;\u0026#34;\u0026#34;So sánh các cách tiếp cận tiền xử lý khác nhau\u0026#34;\u0026#34;\u0026#34; # Gốc print(\u0026#34;VĂN BẢN GỐC:\u0026#34;) print(text) print(\u0026#34;\\n\u0026#34; + \u0026#34;=\u0026#34;*60 + \u0026#34;\\n\u0026#34;) # Tokenization cơ bản words_basic = word_tokenize(text) print(\u0026#34;TOKENIZATION CƠ BẢN:\u0026#34;) print(words_basic) print(f\u0026#34;Số lượng token: {len(words_basic)}\\n\u0026#34;) # Chữ thường + loại bỏ dấu câu words_clean = [w.lower() for w in words_basic if w not in string.punctuation] print(\u0026#34;CHỮ THƯỜNG + KHÔNG DẤU CÂU:\u0026#34;) print(words_clean) print(f\u0026#34;Số lượng token: {len(words_clean)}\\n\u0026#34;) # Loại bỏ stop word stop_words = set(stopwords.words(\u0026#39;english\u0026#39;)) words_no_stop = [w for w in words_clean if w not in stop_words] print(\u0026#34;KHÔNG STOP WORDS:\u0026#34;) print(words_no_stop) print(f\u0026#34;Số lượng token: {len(words_no_stop)}\\n\u0026#34;) # Stemming stemmer = PorterStemmer() words_stemmed = [stemmer.stem(w) for w in words_no_stop] print(\u0026#34;STEMMED:\u0026#34;) print(words_stemmed) print(f\u0026#34;Số lượng token: {len(words_stemmed)}\\n\u0026#34;) # Lemmatization lemmatizer = WordNetLemmatizer() words_lemmatized = [lemmatizer.lemmatize(w, pos=\u0026#39;v\u0026#39;) for w in words_no_stop] print(\u0026#34;LEMMATIZED:\u0026#34;) print(words_lemmatized) print(f\u0026#34;Số lượng token: {len(words_lemmatized)}\\n\u0026#34;) compare_preprocessing(text) Lab 2: Tokenization tùy chỉnh với Regex import re def custom_tokenize(text): \u0026#34;\u0026#34;\u0026#34;Tokenization tùy chỉnh bảo toàn các mẫu đặc biệt\u0026#34;\u0026#34;\u0026#34; # Mẫu cho các phần tử văn bản khác nhau patterns = [ r\u0026#39;http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.\u0026amp;+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\u0026#39;, # URLs r\u0026#39;[\\w.+-]+@[\\w-]+\\.[\\w.-]+\u0026#39;, # Emails r\u0026#39;#\\w+\u0026#39;, # Hashtags r\u0026#39;@\\w+\u0026#39;, # Mentions r\u0026#39;\\d+\\.?\\d*%\u0026#39;, # Phần trăm r\u0026#39;\\$\\d+\\.?\\d*\u0026#39;, # Tiền r\u0026#39;\\d{4}-\\d{2}-\\d{2}\u0026#39;, # Ngày tháng r\u0026#39;\\w+\u0026#39;, # Từ r\u0026#39;[^\\w\\s]\u0026#39;, # Dấu câu ] pattern = \u0026#39;|\u0026#39;.join(patterns) tokens = re.findall(pattern, text) return tokens # Kiểm tra tokenization tùy chỉnh sample = \u0026#34;\u0026#34;\u0026#34; Xem https://example.com để biết cập nhật AI! Liên hệ: info@ai-company.com Sự kiện: 2025-11-03 @10:00AM Ngân sách: $50,000 (99.5% tài trợ) #TechEvent \u0026#34;\u0026#34;\u0026#34; tokens = custom_tokenize(sample) print(\u0026#34;Tokenization tùy chỉnh:\u0026#34;) for i, token in enumerate(tokens, 1): print(f\u0026#34;{i}. {token}\u0026#34;) Lab 3: Xử lý văn bản đa ngôn ngữ def process_multilingual_text(text): \u0026#34;\u0026#34;\u0026#34;Xử lý văn bản với nhiều ngôn ngữ và ký tự đặc biệt\u0026#34;\u0026#34;\u0026#34; # Chuẩn hóa Unicode import unicodedata # NFC (Canonical Decomposition, followed by Canonical Composition) normalized = unicodedata.normalize(\u0026#39;NFC\u0026#39;, text) # Xác định các mẫu đặc thù ngôn ngữ has_emoji = bool(re.search(r\u0026#39;[\\U0001F600-\\U0001F64F]\u0026#39;, text)) has_cjk = bool(re.search(r\u0026#39;[\\u4e00-\\u9fff]\u0026#39;, text)) # Trung/Nhật/Hàn has_arabic = bool(re.search(r\u0026#39;[\\u0600-\\u06ff]\u0026#39;, text)) info = { \u0026#39;gốc\u0026#39;: text, \u0026#39;đã_chuẩn_hóa\u0026#39;: normalized, \u0026#39;có_emoji\u0026#39;: has_emoji, \u0026#39;có_cjk\u0026#39;: has_cjk, \u0026#39;có_arabic\u0026#39;: has_arabic, \u0026#39;độ_dài\u0026#39;: len(text), \u0026#39;độ_dài_chuẩn_hóa\u0026#39;: len(normalized) } return info # Kiểm tra xử lý đa ngôn ngữ multilingual_samples = [ \u0026#34;Hello 世界! 🌍\u0026#34;, \u0026#34;Natural Language Processing\u0026#34;, \u0026#34;café résumé naïve\u0026#34;, \u0026#34;مرحبا العالم\u0026#34; ] for sample in multilingual_samples: result = process_multilingual_text(sample) print(f\u0026#34;\\nVăn bản: {result[\u0026#39;gốc\u0026#39;]}\u0026#34;) print(f\u0026#34;Đã chuẩn hóa: {result[\u0026#39;đã_chuẩn_hóa\u0026#39;]}\u0026#34;) print(f\u0026#34;Có Emoji: {result[\u0026#39;có_emoji\u0026#39;]}\u0026#34;) print(f\u0026#34;Có CJK: {result[\u0026#39;có_cjk\u0026#39;]}\u0026#34;) print(f\u0026#34;Có Arabic: {result[\u0026#39;có_arabic\u0026#39;]}\u0026#34;) Lab 4: Xây dựng quy trình tiền xử lý class PreprocessingPipeline: \u0026#34;\u0026#34;\u0026#34;Quy trình tiền xử lý linh hoạt\u0026#34;\u0026#34;\u0026#34; def __init__(self): self.steps = [] self.stemmer = PorterStemmer() self.lemmatizer = WordNetLemmatizer() self.stop_words = set(stopwords.words(\u0026#39;english\u0026#39;)) def add_lowercase(self): self.steps.append((\u0026#39;chữ_thường\u0026#39;, lambda x: x.lower())) return self def add_tokenization(self): self.steps.append((\u0026#39;tokenize\u0026#39;, word_tokenize)) return self def add_remove_punctuation(self): def remove_punct(tokens): return [t for t in tokens if t not in string.punctuation] self.steps.append((\u0026#39;loại_dấu_câu\u0026#39;, remove_punct)) return self def add_remove_stopwords(self): def remove_stop(tokens): return [t for t in tokens if t not in self.stop_words] self.steps.append((\u0026#39;loại_stop_word\u0026#39;, remove_stop)) return self def add_stemming(self): def stem(tokens): return [self.stemmer.stem(t) for t in tokens] self.steps.append((\u0026#39;stem\u0026#39;, stem)) return self def add_lemmatization(self, pos=\u0026#39;v\u0026#39;): def lemmatize(tokens): return [self.lemmatizer.lemmatize(t, pos=pos) for t in tokens] self.steps.append((\u0026#39;lemmatize\u0026#39;, lemmatize)) return self def process(self, text): result = text for step_name, step_func in self.steps: result = step_func(result) print(f\u0026#34;Sau {step_name}: {result[:100]}...\u0026#34;) # Hiển thị 100 ký tự đầu return result # Xây dựng quy trình tùy chỉnh pipeline = (PreprocessingPipeline() .add_lowercase() .add_tokenization() .add_remove_punctuation() .add_remove_stopwords() .add_lemmatization()) text = \u0026#34;The students are studying NLP concepts and building amazing applications!\u0026#34; result = pipeline.process(text) print(f\u0026#34;\\nKết quả cuối cùng: {result}\u0026#34;) Bài tập thực hành So sánh các cách tiếp cận tiền xử lý trên các loại văn bản khác nhau (tweets, bài báo, code) Xây dựng quy trình tiền xử lý cho một lĩnh vực cụ thể (y tế, pháp lý, mạng xã hội) Triển khai tokenization tùy chỉnh để xử lý các định dạng đặc biệt (mã sản phẩm, IDs) Phân tích tác động của các lựa chọn tiền xử lý khác nhau đến tác vụ phân loại Tạo benchmark tiền xử lý so sánh sự đánh đổi giữa tốc độ và chất lượng "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.10-week10/1.10.1-day46-2025-11-10/","title":"Ngày 46 - Xác thực &amp; Thiết lập dự án","tags":[],"description":"","content":"Ngày: 2025-11-10\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú bài giảng Xem lại ngữ cảnh dự án Kiến trúc Thư viện Online Frontend Stack:\nNext.js 14 (App Router) AWS Amplify (Hosting + CI/CD) Amplify UI Components TailwindCSS cho styling React Query cho quản lý state Tích hợp dịch vụ AWS:\nAmazon Cognito (Xác thực) API Gateway (HTTP API endpoints) S3 (Lưu trữ file qua presigned URLs) CloudFront (Phân phối nội dung) DynamoDB (Lưu trữ metadata) Thiết lập môi trường phát triển Yêu cầu:\nNode.js 18+ và npm/yarn AWS CLI đã cấu hình Git và tài khoản GitHub Tài khoản AWS với quyền phù hợp Cấu trúc dự án:\nonline-library/ ├── src/ │ ├── app/ # Trang Next.js App Router │ ├── components/ # UI components tái sử dụng │ ├── lib/ # Hàm tiện ích \u0026amp; AWS SDK │ ├── hooks/ # Custom React hooks │ └── types/ # Định nghĩa TypeScript ├── public/ # Tài nguyên tĩnh ├── amplify/ # Cấu hình Amplify └── .env.local # Biến môi trường Luồng xác thực Chiến lược tích hợp Cognito Hành trình người dùng:\nĐăng ký → Xác thực email → Đăng nhập Lưu trữ JWT token trong localStorage/cookies Tự động refresh token trước khi hết hạn Truy cập dựa trên vai trò (User vs Admin) Các thành phần chính:\nTrang đăng nhập với email/password Form đăng ký với validation Luồng xác thực email Chức năng đặt lại mật khẩu HOC bảo vệ route Xác thực Amplify UI Lợi ích:\nComponents đã xây dựng sẵn, có thể tùy chỉnh Validation form tích hợp sẵn Quản lý token tự động Thiết kế responsive ngay từ đầu Cấu hình:\n// amplify-config.js const amplifyConfig = { Auth: { region: \u0026#39;ap-southeast-1\u0026#39;, userPoolId: process.env.NEXT_PUBLIC_USER_POOL_ID, userPoolWebClientId: process.env.NEXT_PUBLIC_USER_POOL_CLIENT_ID, }, API: { endpoints: [ { name: \u0026#39;OnlineLibraryAPI\u0026#39;, endpoint: process.env.NEXT_PUBLIC_API_ENDPOINT, } ] } } Những hiểu biết quan trọng Amplify UI components giảm đáng kể thời gian triển khai auth Token refresh nên tự động diễn ra ở background Lưu role/groups của user trong JWT claims cho authorization frontend Biến môi trường quan trọng cho bảo mật - không bao giờ commit dữ liệu nhạy cảm Thiết lập CI/CD trong Amplify yêu cầu cài đặt build phù hợp Công việc đã hoàn thành Khởi tạo dự án\nTạo dự án Next.js 14 với TypeScript và TailwindCSS Cài đặt AWS Amplify và các dependencies cần thiết Thiết lập cấu trúc thư mục dự án Cấu hình Amplify\nCấu hình Amplify với thông tin đăng nhập Cognito User Pool Thiết lập cấu hình endpoint API Gateway Tạo cấu trúc biến môi trường Trang xác thực\nXây dựng trang đăng nhập với Amplify Authenticator Tạo trang đăng ký với xác thực email Triển khai HOC bảo vệ route cho các trang yêu cầu xác thực Quản lý người dùng\nTạo custom hook useUser cho ngữ cảnh người dùng Triển khai xử lý JWT token Thiết lập phát hiện vai trò admin từ Cognito groups Thiết lập CI/CD\nKết nối repository GitHub với Amplify Hosting Cấu hình cài đặt build cho triển khai Next.js Thiết lập biến môi trường trong Amplify Console Thách thức \u0026amp; Giải pháp Thách thức: Thay đổi API Amplify v6 so với phiên bản trước\nGiải pháp: Cập nhật sử dụng cú pháp Amplify.configure() mới và Authenticator.Provider\nThách thức: Thời gian refresh token gây lỗi 401\nGiải pháp: Triển khai tự động refresh token 5 phút trước khi hết hạn\nThách thức: Vai trò admin không phản ánh ngay sau khi đăng nhập\nGiải pháp: Thêm cơ chế re-fetch token sau khi xác thực thành công\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/","title":"Nhật ký học tập - Hành trình AWS","tags":[],"description":"","content":"Nhật ký học tập Tổng quan Đây là nhật ký ghi chép hành trình học AWS và phát triển phần mềm từ ngày 8 tháng 9, 2025 đến ngày 14 tháng 11, 2025 (50 ngày làm việc trong 10 tuần).\nCấu trúc Nhật ký được tổ chức theo tuần, mỗi tuần gồm 5 ngày làm việc (Thứ Hai đến Thứ Sáu).\nTiến độ Tuần 1 (8-12/9): Các khái niệm cơ bản về Cloud Computing Tuần 2 (15-19/9): Dịch vụ Mạng AWS Tuần 3 (22-26/9): Dịch vụ Tính toán AWS Tuần 4 (29/9-3/10): Dịch vụ Lưu trữ AWS Tuần 5 (6-10/10): Bảo mật \u0026amp; Quản lý Danh tính AWS Tuần 6 (13-17/10): Dịch vụ Cơ sở dữ liệu AWS Tuần 7 (20-24/10): Chủ đề AWS Nâng cao Tuần 8 (27-31/10): Học Xử lý Ngôn ngữ Tự nhiên Tuần 9 (3-7/11): Ôn tập NLP \u0026amp; Các khái niệm Nâng cao Tuần 10 (10-14/11): Hoàn thiện Dự án Thư viện Trực tuyến (Frontend) Thống kê Tổng thời gian: 10 tuần (50 ngày làm việc) Các tuần tập trung AWS: 7 tuần (Tuần 1-7) Các tuần phát triển Front-End: 3 tuần (Tuần 8-10) Tổng số labs: Hơn 25 bài lab thực hành AWS Lĩnh vực chính: Dịch vụ AWS Cốt lõi, NLP, Phát triển Full-Stack Nội dung chính Dịch vụ AWS Cốt lõi (Tuần 1-7) Các khái niệm cơ bản về Cloud Computing\nKiến thức cơ bản về AWS, hạ tầng toàn cầu, công cụ quản lý Tối ưu hóa chi phí, gói hỗ trợ Well-Architected Framework Mạng\nVPC, subnets, security groups, NACLs Cân bằng tải (ALB, NLB, GWLB) VPC Peering, Transit Gateway Hybrid DNS với Route 53 Resolver Tính toán\nEC2, AMI, EBS, Instance Store Auto Scaling, các mô hình định giá Lightsail, EFS, FSx Lưu trữ\nS3, các lớp lưu trữ, Glacier Snow Family, Storage Gateway Khôi phục thảm họa, AWS Backup Bảo mật \u0026amp; Quản lý Danh tính\nIAM, Cognito, Organizations KMS, Security Hub Identity Center (SSO) Mô hình Trách nhiệm Chia sẻ Cơ sở dữ liệu\nRDS, Aurora, Redshift ElastiCache, DMS Các thực hành tốt nhất về cơ sở dữ liệu Chủ đề Nâng cao\nServerless (Lambda) Containers (ECS, EKS, ECR) Giám sát (CloudWatch, X-Ray, CloudTrail) Tự động hóa Lambda với tích hợp Slack Xử lý Ngôn ngữ Tự nhiên (Tuần 8-9) Kiến thức Cơ bản \u0026amp; Ứng dụng NLP Tiền xử lý văn bản (tokenization, stemming, lemmatization) Phân tích cảm xúc và phân loại văn bản Nhận dạng thực thể có tên (NER) Thư viện NLP (NLTK, spaCy) Xây dựng pipeline NLP và các dự án thực tế Phát triển Front-End (Tuần 10) Dự án Thư viện Trực tuyến Xác thực với AWS Cognito và Amplify UI Tải file lên với S3 presigned URLs Bảng quản trị và hệ thống quản lý sách Giao diện đọc sách với CloudFront signed URLs Chức năng tìm kiếm sử dụng DynamoDB GSI Triển khai CI/CD với AWS Amplify "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/5-workshop/5.1-workshop-overview/","title":"Tổng quan Workshop","tags":[],"description":"","content":"Mục tiêu Giới thiệu workshop xác thực: cài đặt AWS Amplify CLI, tạo ứng dụng React với luồng xác thực hoàn chỉnh sử dụng Amazon Cognito, triển khai đăng ký người dùng, đăng nhập, quản lý mật khẩu, MFA và đăng nhập qua mạng xã hội. Nhấn mạnh việc triển khai xác thực an toàn nhanh chóng mà không cần quản lý hạ tầng.\nKiến trúc tổng quan Amazon Cognito User Pool quản lý thư mục người dùng và xác thực. AWS Amplify cung cấp công cụ CLI và thư viện frontend để tích hợp liền mạch. Ứng dụng React sử dụng Amplify UI components cho giao diện xác thực. JWT tokens xử lý quản lý phiên và phân quyền API. Kết quả mong đợi Ứng dụng React với đăng ký người dùng và xác minh email. Chức năng đăng nhập/đăng xuất với session persistence. Tính năng đặt lại và thay đổi mật khẩu. Xác thực đa yếu tố (MFA) với TOTP. Tích hợp đăng nhập mạng xã hội (Google/Facebook). Protected routes với role-based access control. Cấu trúc \u0026amp; thời gian Module 1: Cài đặt Amplify và cấu hình ban đầu. Module 2: Luồng đăng ký người dùng và xác minh email. Module 3: Đăng nhập, quản lý phiên và đăng xuất. Module 4: Quản lý mật khẩu (quên/đặt lại/thay đổi). Module 5: Tính năng nâng cao (MFA và social login). Module 6: Triển khai production và dọn dẹp. "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.1-week1/","title":"Tuần 1 - Kiến thức Nền tảng Cloud Computing","tags":[],"description":"","content":"Tuần: 2025-09-08 đến 2025-09-12\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 1 Tuần này tập trung củng cố những khái niệm cơ bản về Cloud Computing, hạ tầng AWS và các công cụ quản trị.\nNội dung chính Giới thiệu Cloud Computing và lợi ích. AWS Global Infrastructure (Region, AZ, Edge Location). Bộ công cụ quản lý AWS (Console, CLI, SDK). Chiến lược tối ưu chi phí. AWS Well-Architected Framework. Labs thực hành Lab 01: Thiết lập tài khoản AWS \u0026amp; IAM. Lab 07: AWS Budgets \u0026amp; Cost Management. Lab 09: AWS Support Plans. "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Thư Viện Online - Nền Tảng Nội Dung Serverless Cho Nhóm Nhỏ 1. Tổng quan điều hành Dự án Thư Viện Online nhằm xây dựng một nền tảng serverless, chi phí thấp để lưu trữ và phân phối nội dung (PDF/ePub) cho một nhóm người dùng nhỏ (ban đầu ~100 người, nhóm người dùng gồm sinh viên/lab cần chia sẻ tài liệu nghiên cứu nội bộ có kiểm duyệt). Giải pháp này ưu tiên tính bảo mật, quy trình duyệt nội dung (Admin Approval), và chi phí vận hành minh bạch, tuyến tính khi mở rộng. Kiến trúc sử dụng AWS Serverless hoàn toàn (Amplify, Cognito, API Gateway, Lambda, S3, CloudFront, DynamoDB). Chi phí dự kiến cho MVP (không tính Free Tier) ≈ $9.80/tháng, đảm bảo khả năng mở rộng lên 5.000 đến 50.000 người dùng với chi phí dễ dự đoán.\n2. Vấn đề Vấn đề là gì? Tài liệu và sách bị phân tán; thiếu một hệ thống truyền tải nội dung an toàn và có kiểm soát truy cập; quy trình thêm hoặc kiểm duyệt nội dung tốn thời gian và nhiều vấn đề liên quan đến pháp lý.\nGiải pháp Xây dựng một pipeline serverless trên AWS: Người dùng tải lên qua Presigned PUT URL (tới S3 tạm); Admin phê duyệt → Lambda di chuyển file đến thư mục công khai (nhưng được bảo vệ); Người đọc truy cập qua Signed GET URL (từ CloudFront/CDN) để đảm bảo tốc độ và kiểm soát truy cập.\nLợi ích và Tỷ suất hoàn vốn Giá trị kinh doanh: Tập trung hóa nội dung; kiểm soát chất lượng qua quy trình duyệt; triển khai nhanh chóng với CI/CD. Lợi ích kỹ thuật: Chi phí vận hành thấp (≈ $9.80/tháng ở MVP, không tính Free Tier); kiến trúc Serverless có thể mở rộng quy mô lớn (scale) dễ dàng; bảo mật truy cập nội dung. 3. Kiến trúc giải pháp A. High-level B. Luồng xử lý yêu cầu Dịch vụ AWS Sử Dụng Dịch vụ Vai trò chính Hoạt động cụ thể Amplify Hosting CI/CD + FE Hosting Build \u0026amp; Deploy Next.js, quản lý domain Cognito Authentication Đăng ký/Đăng nhập, cấp JWT, refresh token API Gateway Entry point API Nhận request, xác thực JWT, route đến Lambda Lambda Business Logic Xử lý upload, duyệt, tạo signed URL, ghi metadata S3 Object Storage Lưu file gốc, file đã duyệt, được download qua Cloudfront Signed URL CloudFront CDN Phân phối nhanh nội dung, chặn direct access qua OAC DynamoDB Database Lưu metadata (tên sách, uploader, trạng thái duyệt) Route 53 DNS Trỏ domain đến Amplify Hosting, API Gateway, CloudFront CloudWatch Monitoring Lưu log Lambda, cảnh báo lỗi hoặc chi phí bất thường Tìm kiếm (Search):\nTìm kiếm đơn giản theo trường (VD: tên sách, tác giả), sử dụng DynamoDB GSIs cho các thuộc tính này và query theo GSI. Luồng xử lý yêu cầu User Upload: Presigned PUT tới S3 thư mục uploads/. Admin Approval: Lambda copy file từ uploads/ sang public/books/ khi được duyệt. Reader Security: CloudFront sử dụng Origin Access Control (OAC) để chặn truy cập trực tiếp S3 và chỉ cho phép đọc qua Signed URL (ngắn hạn) do Lambda tạo ra. Kiến trúc tìm kiếm Tìm kiếm đơn giản: Thiết kế GSI cho title và author (ví dụ: GSI1: PK=TITLE#{normalizedTitle}, SK=BOOK#{bookId}; GSI2: PK=AUTHOR#{normalizedAuthor}, SK=BOOK#{bookId}). Thêm endpoint GET /search?title=...\u0026amp;author=... để query theo GSI thay vì Scan. Phân quyền Admin Sử dụng Cognito User Groups với một nhóm Admins trong User Pool. Khi Admin đăng nhập, JWT sẽ chứa cognito:groups: [\u0026quot;Admins\u0026quot;]. Các Lambda thuộc nghiệp vụ Admin (ví dụ approveBook, takedownBook) phải kiểm tra claim này; nếu thiếu group, trả 403 Forbidden. Có thể dùng JWT Authorizer (API Gateway HTTP API) để xác thực, phần phân quyền chi tiết xử lý trong Lambda dựa trên claim. 4. Triển khai Kỹ Thuật Triển khai Thiết kế \u0026amp; IaC (Infra-as-Code): Xây dựng các stack CDK (Cognito, DDB, S3, Amplify, Lambda, API). Flow Upload \u0026amp; Duyệt: Triển khai Presigned PUT, lưu metadata (trạng thái pending), và logic Admin duyệt (copy file). Flow Đọc Sách: Triển khai endpoint Signed GET, và giao diện đọc (FE stream qua CloudFront). Vận hành (Ops): Thiết lập logs CloudWatch (retention ngắn), cảnh báo ngân sách (Budget Alerts), hardening IAM. Search: MVP: thêm GSI cho title, author và endpoint GET /search query theo GSI. Yêu cầu Kỹ Thuật Sử dụng CDK để định nghĩa toàn bộ hạ tầng. API Gateway phải là HTTP API để tối ưu chi phí. Lambda (Python) xử lý logic nghiệp vụ và tương tác DynamoDB/S3. S3 Bucket Policy phải chặn truy cập công khai và chỉ cho phép CloudFront OAC. 5. Lộ trình và các mốc tiến độ Lộ trình Dự án Nền tảng \u0026amp; Xác thực (Tuần 1-2) Mục tiêu là thiết lập hạ tầng và cho phép người dùng đăng nhập.\nTác vụ Backend (CDK/DevOps): Viết stack CDK/IaC cho Cognito (User Pool, App Client). Viết stack CDK cho DynamoDB (bảng chính, chưa cần GSI). Viết stack CDK cho S3 (Bucket uploads, public, logs) và cấu hình OAC (Origin Access Control). Triển khai API Gateway (HTTP API) và một Lambda \u0026ldquo;hello world\u0026rdquo; để kiểm thử. Tác vụ Frontend (Amplify): Cấu hình Amplify Hosting và kết nối với repo GitHub (CI/CD). Tích hợp Amplify UI / Cognito SDK cho các trang: Đăng ký, Xác thực email, Đăng nhập, Quên mật khẩu. Kết quả (Milestone): Developer có thể git push và FE tự động deploy. Người dùng có thể đăng ký/đăng nhập và nhận được JWT token. Luồng Upload \u0026amp; Duyệt (Tuần 2-3) Mục tiêu là cho phép người dùng (đã đăng nhập) tải file lên và Admin duyệt file đó.\nTác vụ Backend (CDK/Lambda): Viết Lambda createUploadUrl: Xác thực JWT (phải đăng nhập). Tạo Presigned PUT URL trỏ đến thư mục uploads/ trên S3. Ghi metadata vào DynamoDB (status: PENDING). Viết Lambda approveBook: Xác thực JWT (phải là Admin). Copy file từ uploads/ sang public/books/. Cập nhật status trong DynamoDB (status: APPROVED). Tác vụ Frontend: Xây dựng Form Upload (kéo thả, chọn file). Gọi API createUploadUrl để lấy URL. Thực hiện upload file (HTTP PUT) trực tiếp lên S3 Presigned URL. Xây dựng Giao diện Admin: Lấy danh sách sách có status PENDING. Có nút \u0026ldquo;Duyệt\u0026rdquo; (gọi API approveBook). Luồng Đọc \u0026amp; Tìm kiếm (Tuần 3-4) Mục tiêu là cho phép người dùng đọc và tìm kiếm sách đã được duyệt.\nTác vụ Backend (CDK/Lambda): Viết Lambda getReadUrl: Xác thực JWT (phải đăng nhập). Kiểm tra xem sách có status APPROVED không. Tạo Signed GET URL (ngắn hạn) qua CloudFront trỏ đến file trong public/books/. Cập nhật CDK: Thêm GSI (Global Secondary Index) cho title và author vào bảng DynamoDB. Viết Lambda searchBooks: Query DynamoDB dựa trên GSI (không dùng Scan). Tác vụ Frontend: Xây dựng Trang chủ: Hiển thị danh sách sách (từ API, không có URL). Xây dựng Thanh tìm kiếm (gọi API searchBooks). Xây dựng Giao diện Đọc sách (Reader): Khi bấm \u0026ldquo;Đọc\u0026rdquo;, gọi API getReadUrl. Dùng URL nhận được để render file (ví dụ: dùng react-pdf). Vận hành \u0026amp; Bảo mật (Tuần 5-6) Mục tiêu là \u0026ldquo;hóa cứng\u0026rdquo; hệ thống, làm cho nó an toàn và dễ giám sát.\nTác vụ Backend (CDK/Lambda): Thiết lập S3 Event Notification (cho uploads/). Viết Lambda validateMimeType: Trigger khi có file mới, đọc \u0026ldquo;magic bytes\u0026rdquo; để xác thực đúng là PDF/ePub. Nếu sai, cập nhật status: REJECTED_INVALID_TYPE. Viết Lambda takedownBook (API cho Admin) và deleteUpload (xóa file PENDING sau 72h). Tác vụ DevOps (AWS Console/CDK): Thiết lập AWS Budget Alerts (cảnh báo khi chi phí vượt $X). Thiết lập CloudWatch Alarms (ví dụ: Lambda error rate \u0026gt; 5%). Rà soát lại IAM (đảm bảo \u0026ldquo;least-privilege\u0026rdquo;), CORS (chỉ cho phép domain của Amplify). 6. Budget Estimation You can find the budget estimation on the: AWS Pricing Calculator\nDưới đây là ước tính chi phí hàng tháng nghiêm ngặt (giả định không áp dụng AWS Free Tier) tại quy mô MVP (100 người dùng).\n# AWS Service Region Monthly (USD) Notes 0 Amazon CloudFront Asia Pacific (Singapore) 0.86 10 GB data egress + 10 000 HTTPS requests 1 AWS Amplify Asia Pacific (Singapore) 1.31 100 build min + 0.5 GB storage + 2 GB served 2 Amazon API Gateway Asia Pacific (Singapore) 0.01 ~10 000 HTTP API calls/tháng 3 AWS Lambda Asia Pacific (Singapore) 0.00 128 MB RAM × 100 ms × 10 000 invokes 4 Amazon S3 (Standard) Asia Pacific (Singapore) 0.05 2 GB object storage for books/images 5 Data Transfer Asia Pacific (Singapore) 0.00 Included in CloudFront cost 6 DynamoDB (On-Demand) Asia Pacific (Singapore) 0.03 Light metadata table (0.1 GB, few reads/writes) 7 Amazon Cognito Asia Pacific (Singapore) 5.00 100 MAU, Advanced Security enabled 8 Amazon CloudWatch Asia Pacific (Singapore) 1.64 5 metrics + 0.1 GB logs/tháng 9 Amazon Route 53 Asia Pacific (Singapore) 0.90 1 Hosted Zone + DNS queries ≈ 9.80 USD / month No Free Tier applied Chi phí hạ tầng Mô hình chi phí này cho thấy sự hiệu quả của kiến trúc serverless: chi phí tập trung chủ yếu vào giá trị mang lại cho người dùng (Cognito MAU) thay vì trả tiền cho \u0026ldquo;máy chủ chờ\u0026rdquo; (idle servers).\n7. Đánh giá rủi ro Ma trận rủi ro Rủi ro Tác động Chiến lược giảm thiểu Chi phí tăng khi user đột biến Cao Giới hạn MAU, cache metadata qua CloudFront Upload lạm dụng Trung bình Giới hạn ≤ 50MB/file, xóa auto sau 72h File loại giả mạo/độc hại Trung bình S3 Event → Lambda xác thực MIME (magic bytes) Giám sát quá tải Thấp CloudWatch alert, log 14 ngày Chiến lược giảm thiểu Chi phí: Đặt AWS Budget Alerts cho CloudFront và Cognito. Nhận thức rằng Signed URL có TTL ngắn nên không cache công khai dài hạn; thay vào đó, cache metadata/API response (danh sách sách, chi tiết) trên CloudFront 3–5 phút để giảm tải API. Chỉ tạo Signed URL khi người dùng thực sự bấm đọc (on‑demand), không tạo sẵn cho cả danh sách. Tải lên: Giới hạn kích thước file ≤ 50MB cho MVP. (Có thể nâng lên 200MB khi cần, dùng multipart upload ở FE để tránh timeout.) Áp dụng Rate Limit/Throttling trên API Gateway cho các endpoint tạo Presigned URL. Thiết lập S3 Lifecycle Policy để tự động xóa file chưa duyệt ở uploads/ sau 72h. Thêm Server‑side Validation: S3 Event Notifications → Lambda đọc magic bytes (vd. thư viện file-type) để xác thực đúng PDF/ePub; nếu sai, tự động xóa và ghi trạng thái REJECTED_INVALID_TYPE vào DynamoDB. Bản quyền (DMCA): Lưu Audit Log trong DynamoDB: uploaderID, uploadTimestamp, adminApproverID, approvalTimestamp để phục vụ truy vết. Xây dựng Takedown API (chỉ Admin): cập nhật status TAKEDOWN; tùy chọn di chuyển object từ public/books/ sang quarantine/books/ (không xóa hẳn) để lưu vết. Kế hoạch ứng phó Nếu chi phí tăng vượt ngân sách, có thể tạm thời giới hạn người dùng mới thông qua hệ thống mời để kiểm soát MAU Cognito và tối ưu hóa file.\n8. Kết quả mong đợi Cải tiến kỹ thuật: Đảm bảo tốc độ truyền tải nhanh và bảo mật nội dung (CDN + Signed URL). Tạo ra một kiến trúc Serverless tiêu chuẩn trên AWS, dễ dàng mở rộng lên đến 50.000 người dùng mà không cần thay đổi kiến trúc cốt lõi. Hệ thống CI/CD hoàn toàn tự động cho cả Frontend và Backend (CDK/Amplify). Giá trị lâu dài Thiết lập một nền tảng dữ liệu tập trung và có cấu trúc cho nội dung sách. Cung cấp một tài liệu tham khảo sống về việc triển khai Serverless E2E. Khả năng tích hợp các dịch vụ phân tích (như Amazon QuickSight) hoặc AI/ML trong tương lai. Hệ thống này chứng minh khả năng xây dựng nền tảng nội dung bảo mật, tiết kiệm chi phí và mở rộng dễ dàng bằng AWS Serverless — phù hợp triển khai thực tế cho nhóm nhỏ. Rẻ\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/4-eventparticipated/4.2-event2/","title":"Sự kiện 2 - AWS GenAI Builder Club","tags":[],"description":"","content":"AWS GenAI Builder Club: Vòng đời phát triển được thúc đẩy bởi AI Ngày \u0026amp; Giờ: Thứ Sáu, 3 tháng 10, 2025 | 14:00 VNT\nĐịa điểm: AWS Event Hall, L26 Tòa nhà Bitexco, TP. Hồ Chí Minh\nDiễn giả: Toàn Huỳnh \u0026amp; My Nguyễn\nTổng quan Phiên AWS GenAI Builder Club này giới thiệu Vòng đời Phát triển được thúc đẩy bởi AI (AI-DLC), trình diễn cách AI có thể chuyển đổi kỹ thuật phần mềm bằng cách đóng vai trò là cộng tác viên thông minh trong suốt quá trình phát triển. Buổi học bao gồm các bản demo thực hành về Amazon Q Developer và Kiro IDE, giới thiệu tích hợp AI thực tế trong quy trình phát triển hiện đại.\nChương trình buổi học Thời gian Chủ đề Diễn giả 14:00 - 14:15 Chào mừng \u0026amp; Giới thiệu - 14:15 - 15:30 Tổng quan AI-DLC \u0026amp; Demo Amazon Q Developer Toàn Huỳnh 15:30 - 15:45 Giải lao giao lưu - 15:45 - 16:30 Trình diễn Kiro IDE My Nguyễn Vòng đời Phát triển được thúc đẩy bởi AI (AI-DLC) Nguyên tắc cốt lõi Bạn vẫn nắm quyền kiểm soát\nAI đóng vai trò trợ lý, không phải thay thế bạn. Duy trì quyền quyết định về hướng đi dự án và các lựa chọn kỹ thuật.\nHợp tác hai chiều\nAI nên đặt câu hỏi quan trọng về yêu cầu, kiến trúc và mục tiêu. Mối quan hệ là hợp tác, với bạn hướng dẫn các đề xuất của AI.\nLập kế hoạch trước khi code\nTạo kế hoạch toàn diện trước khi triển khai. AI có thể giúp tạo kế hoạch, nhưng bạn phải xem xét và xác thực chúng.\nQuy trình phát triển 1. Lập kế hoạch dự án\nXác định yêu cầu và phạm vi rõ ràng Tạo kế hoạch ban đầu với sự hỗ trợ của AI Xem xét và tinh chỉnh cho đến khi chi tiết và rõ ràng 2. Tạo User Story\nChia nhỏ kế hoạch thành user stories với tiêu chí chấp nhận Chia phạm vi thành các đơn vị quản lý được Phân công stories cho các thành viên nhóm 3. Xác định Technology Stack\nChỉ định frameworks, công cụ và công nghệ Đưa ra hướng dẫn tích cực thay vì ràng buộc Đặc tả rõ ràng mang lại kết quả tốt hơn 4. Yêu cầu \u0026amp; Thiết kế\nViết yêu cầu chính xác, chi tiết Tạo đặc tả một cách hợp tác với AI Xác định data models, APIs và kiến trúc hệ thống 5. Triển khai\nXây dựng theo kế hoạch Sử dụng phương pháp phát triển hợp tác Xác minh tất cả code do AI tạo ra theo nhóm 6. Kiểm thử \u0026amp; Triển khai\nTiến triển qua các môi trường: Dev → QA → UAT → Production Xác thực tại mỗi cổng chất lượng Đảm bảo chức năng trước khi phát hành Yếu tố thành công Lập kế hoạch trước - Đừng mong đợi AI quản lý mọi thứ Xem xét thường xuyên - Xác thực đầu ra AI liên tục Quản lý tích cực - Giá trị của bạn là xác thực và giám sát Đặt câu hỏi - Đảm bảo AI hiểu ngữ cảnh của bạn Sử dụng Templates - Cấu trúc prompts với ngữ cảnh và yêu cầu Tài liệu hóa kế hoạch - Xuất kế hoạch dưới dạng files để tham khảo Giữ sự tôn trọng - Duy trì giao tiếp chuyên nghiệp với AI Amazon Q Developer Tổng quan Amazon Q Developer là trợ lý AI nâng cao vòng đời phát triển phần mềm trên nhiều nền tảng: AWS Console, IDEs, CLI và công cụ DevSecOps.\nKhả năng chính Cải thiện Code\nTăng tốc tạo code Cải thiện chất lượng code thông qua đề xuất thông minh Tối ưu hóa codebase phức tạp Tích hợp liền mạch với quy trình hiện có Tự động hóa\nTự động tạo tài liệu toàn diện Tạo unit tests với nỗ lực tối thiểu Giảm boilerplate code Tự động hóa các tác vụ lặp đi lặp lại Hỗ trợ thông minh\nTận dụng kiến thức sâu về dịch vụ AWS Kết hợp chuyên môn trên nhiều lĩnh vực Tăng cường tư thế bảo mật Nâng cao năng suất của developer Thực hành tốt nhất Cung cấp ngữ cảnh dự án chi tiết Sử dụng prompts cụ thể, giàu ví dụ Xem xét tất cả đề xuất trước khi triển khai Lặp lại và tinh chỉnh prompts khi cần Tận dụng chuyên môn về dịch vụ AWS Kiro IDE Tổng quan Kiro là IDE agentic từ AWS kết nối giữa tạo mẫu AI nhanh và phát triển sẵn sàng production. Hiện đang ở giai đoạn public preview, nó duy trì tiêu chuẩn chuyên nghiệp trong khi nâng cao năng suất.\nTính năng cốt lõi Phát triển dựa trên Spec\nChuyển đổi yêu cầu thành đặc tả có cấu trúc Tạo user stories với tiêu chí chấp nhận Tạo tài liệu thiết kế trước khi code Lập kế hoạch triển khai có hệ thống Tự động hóa Agent\nTự động kích hoạt tasks trên các sự kiện Cập nhật tài liệu khi lưu file Tạo tests khi commit Tối ưu hóa hiệu suất dựa trên hành động Ngữ cảnh Dự án\nSử dụng steering files (markdown) cho hướng dẫn Hiểu cấu trúc dự án sâu sắc Áp dụng tiêu chuẩn coding nhất quán Tuân theo best practices của nhóm Thông minh đa File\nPhân tích nhiều files đồng thời Hiểu mục tiêu chức năng trên toàn codebase Căn chỉnh thay đổi với mục tiêu dự án Vượt xa việc hoàn thiện đơn giản Nền tảng VS Code\nXây dựng trên VS Code open source Import settings và extensions Giao diện quen thuộc cho developers Chuyển đổi liền mạch Models linh hoạt\nSử dụng Claude Sonnet 4 mặc định Chế độ Auto kết hợp nhiều models Cân bằng chất lượng và chi phí Thích ứng với các tasks khác nhau Ưu điểm Minh bạch \u0026amp; Kiểm soát\nBắt đầu với đặc tả Xem xét trước khi triển khai Giảm code không phù hợp Duy trì khả năng truy vết rõ ràng Tự động hóa\nTự động tạo tài liệu Tạo unit tests tự động Cập nhật thông tin có hệ thống Tập trung vào công việc có giá trị cao Bảo mật\nHầu hết hoạt động chạy locally Dữ liệu chỉ gửi khi có quyền Kiểm soát thông tin nhạy cảm Khả năng mở rộng\nTích hợp công cụ ngoài qua MCP Hỗ trợ nhiều AI models Không bị khóa vào một môi trường Thích ứng với quy trình nhóm Cân nhắc Hiện đang ở public preview Có thể gặp khó khăn với dự án rất phức tạp Yêu cầu giám sát của developer Dự kiến các mức giá tương lai (Free/Pro/Pro+) Khi nào sử dụng Cần phát triển dựa trên spec Muốn quy trình AI chuyên nghiệp, có cấu trúc Xây dựng prototypes nhanh cho production Yêu cầu tài liệu và kiểm thử tự động Những lỗi thường gặp \u0026amp; Giải pháp Phụ thuộc quá mức vào AI\nGiải pháp: Lập kế hoạch trước, xem xét thường xuyên. AI tăng cường, không thay thế phán đoán của developer.\nTỷ lệ lỗi cao\nGiải pháp: Triển khai chu kỳ xem xét. Xác thực tất cả code do AI tạo ra.\nYêu cầu mơ hồ\nGiải pháp: Viết yêu cầu chính xác. Tạo đặc tả chi tiết một cách hợp tác.\nHướng dẫn tiêu cực\nGiải pháp: Sử dụng hướng dẫn tích cực, cụ thể. Nói cho AI biết phải làm gì, không phải tránh gì.\nThiếu ngữ cảnh\nGiải pháp: Tạo steering files. Cung cấp ngữ cảnh chi tiết. Đặt câu hỏi quan trọng.\nAI làm Manager\nGiải pháp: Bạn quản lý dự án. Giá trị của bạn là xác thực và giám sát.\nNhững điểm chính Duy trì kiểm soát: Bạn là manager; AI là trợ lý Lập kế hoạch chiến lược: Tạo kế hoạch toàn diện trước khi code Hợp tác hiệu quả: AI nên đặt câu hỏi và hợp tác, không chỉ thực thi Chỉ định rõ ràng: Yêu cầu chính xác mang lại đầu ra AI tốt hơn Xem xét liên tục: Xác thực đề xuất AI thường xuyên Tập trung vào giá trị: Chuyên môn của bạn quan trọng trong xác thực và kiến trúc Cấu trúc Prompts: Sử dụng templates với ngữ cảnh và yêu cầu Tài liệu hóa kỹ lưỡng: Xuất kế hoạch dưới dạng tài liệu tham khảo sống Hướng dẫn tích cực: Hướng dẫn tích cực hiệu quả hơn ràng buộc Thực hành tích cực: Trải nghiệm thực tế tiết lộ khả năng và giới hạn Công cụ được giới thiệu Amazon Q Developer - Trợ lý phát triển được hỗ trợ bởi AI Kiro IDE - Môi trường phát triển dựa trên spec MCP (Model Context Protocol) - Framework tích hợp công cụ Kết luận Vòng đời Phát triển được thúc đẩy bởi AI đại diện cho sự thay đổi mô hình trong đó AI và developers hợp tác như đối tác. Thành công đòi hỏi lập kế hoạch rõ ràng, xem xét liên tục, yêu cầu chính xác và duy trì kiểm soát của developer. Amazon Q Developer và Kiro IDE cho phép quy trình này, hoạt động tốt nhất khi developers hiểu vai trò của họ là quản lý dự án và xác thực code trong khi tận dụng AI để tăng năng suất.\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.6-week6/1.6.2-day27-2025-10-14/","title":"Day 27 - Amazon RDS &amp; Aurora","tags":[],"description":"","content":" ⚠️ Bản dịch tiếng Việt đang được cập nhật. Vui lòng xem nội dung chi tiết trong file _index.md (tiếng Anh).\nNội dung tiếng Việt sẽ được bổ sung sớm để phản ánh đầy đủ các ghi chú và bài lab.\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.7-week7/1.7.2-day32-2025-10-21/","title":"Day 32 - Contract-First &amp; Mocking","tags":[],"description":"","content":" ⚠️ Bản dịch tiếng Việt đang được cập nhật. Vui lòng xem nội dung chi tiết trong file _index.md (tiếng Anh).\nNội dung tiếng Việt sẽ được bổ sung sớm để phản ánh đầy đủ các ghi chú và bài lab.\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.1-week1/1.1.2-day02-2025-09-09/","title":"Ngày 02 - Hạ tầng Toàn cầu của AWS","tags":[],"description":"","content":"Ngày: 2025-09-09\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Hạ tầng AWS Trung tâm dữ liệu (Data Center) Mỗi trung tâm dữ liệu có thể chứa hàng chục nghìn máy chủ. AWS tự thiết kế và vận hành phần cứng riêng để tối ưu hiệu năng và độ tin cậy. Vùng khả dụng (Availability Zone - AZ) Một hoặc nhiều trung tâm dữ liệu tách biệt vật lý trong cùng một Region. Mỗi AZ được thiết kế cách ly lỗi. Kết nối với nhau bằng mạng riêng độ trễ thấp, băng thông cao. AWS khuyến nghị triển khai workload tối thiểu trên hai AZ. Region Mỗi Region chứa ít nhất ba AZ. Hiện có hơn 25 Region trên toàn thế giới. Các Region kết nối với nhau qua mạng backbone của AWS. Phần lớn dịch vụ mặc định ở phạm vi Region. Edge Location Mạng lưới edge toàn cầu giúp phân phối nội dung với độ trễ tối thiểu. Được sử dụng bởi các dịch vụ như: Amazon CloudFront (CDN) AWS WAF (Tường lửa ứng dụng web) Amazon Route 53 (Dịch vụ DNS) Hands-On Labs Lab 01 – Thiết lập Tài khoản AWS \u0026amp; IAM Tạo tài khoản AWS → 01-01 Cấu hình thiết bị MFA ảo → 01-02 Tạo nhóm Admin và người dùng Admin → 01-03 Cập nhật thông tin hỗ trợ xác thực tài khoản → 01-04 "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.2-week2/1.2.2-day07-2025-09-16/","title":"Ngày 07 - Định tuyến VPC &amp; Network Interface","tags":[],"description":"","content":"Ngày: 2025-09-16\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Định tuyến VPC \u0026amp; ENI Route Table Route table xác định cách điều hướng lưu lượng mạng. Mỗi VPC có một route table mặc định chỉ chứa tuyến local để các subnet giao tiếp nội bộ. Có thể tạo thêm route table tùy chỉnh, nhưng tuyến local không thể xóa. Elastic Network Interface (ENI) ENI là card mạng ảo có thể gắn sang các EC2 instance khác nhau. Khi chuyển ENI, địa chỉ IP riêng, EIP và MAC được giữ nguyên. Elastic IP (EIP) là địa chỉ IPv4 công cộng tĩnh có thể gắn vào ENI. Bị tính phí nếu EIP không gắn cho tài nguyên nào. Tình huống sử dụng ENI:\nTách mạng quản trị khỏi mạng dữ liệu. Xây dựng thiết bị mạng/bảo mật (appliance). Instance hai cổng mạng chạy workload ở các subnet khác nhau. Giải pháp high availability chi phí thấp. VPC Endpoint VPC Endpoint cho phép kết nối riêng tư tới dịch vụ AWS qua AWS PrivateLink mà không đi Internet công cộng. Hai loại endpoint: Interface Endpoint: Tạo một ENI với IP riêng. Gateway Endpoint: Sử dụng route table (chỉ dành cho S3 và DynamoDB). Hands-On Labs Lab 03 – Amazon VPC \u0026amp; Networking (tiếp tục) Tạo Internet Gateway (IGW) → 03-03.3 Tạo Route Table (Outbound qua IGW) → 03-03.4 Tạo Security Group → 03-03.5 "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.3-week3/1.3.2-day12-2025-09-23/","title":"Ngày 12 - Lưu trữ &amp; Sao lưu cho EC2","tags":[],"description":"","content":"Ngày: 2025-09-23\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Lưu trữ \u0026amp; Bảo mật cho EC2 Sao lưu trong EC2 AWS Backup cung cấp giải pháp sao lưu tập trung cho nhiều dịch vụ, bao gồm EC2. EBS Snapshot sao lưu các volume EBS: Sao lưu theo thời điểm (point-in-time). Dạng incremental (chỉ lưu block thay đổi). Lưu trữ trong S3 (không truy cập trực tiếp). AMI Backup chụp toàn bộ cấu hình EC2 dưới dạng image. Best practices cho Snapshot:\nLên lịch snapshot định kỳ. Sao chép snapshot sang Region khác cho DR. Gắn thẻ (tag) để quản lý vòng đời. Sử dụng Amazon Data Lifecycle Manager (DLM). Key Pair Key Pair dùng để xác thực an toàn khi kết nối EC2: Public Key – lưu trên instance. Private Key – người dùng giữ để SSH (Linux) hoặc RDP (Windows). Thay thế mật khẩu, tăng cường bảo mật. Lưu ý: Nếu mất private key, AWS không thể khôi phục. Quản lý Key Pair:\nTạo key pair trên AWS hoặc import key sẵn có. Lưu trữ private key an toàn. Dùng key pair khác nhau cho từng môi trường. Luân phiên (rotate) định kỳ. Elastic Block Store (EBS) Amazon EBS cung cấp lưu trữ dạng block bền vững cho EC2. Các loại volume: General Purpose SSD (gp2/gp3) – cân bằng hiệu năng và chi phí. Provisioned IOPS SSD (io1/io2) – cho workload cần IOPS cao. Throughput Optimized HDD (st1) – dữ liệu lớn, truy cập tuần tự. Cold HDD (sc1) – dữ liệu ít truy cập, chi phí thấp. Tính năng chính:\nGắn/Tháo volume với instance. Dữ liệu vẫn giữ khi instance tắt. Tạo snapshot để sao lưu hoặc copy sang Region khác. Tự động nhân bản trong phạm vi AZ. So sánh volume EBS:\nLoại Tình huống Max IOPS Max Throughput gp3 Mục đích tổng quát 16.000 1.000 MB/s io2 Hiệu năng cao 64.000 1.000 MB/s st1 Big data 500 500 MB/s sc1 Lưu trữ lạnh 250 250 MB/s "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.4-week4/1.4.2-day17-2025-09-30/","title":"Ngày 17 - Tính năng nâng cao của S3","tags":[],"description":"","content":"Ngày: 2025-09-30\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Hosting website tĩnh trên Amazon S3 Hosting trực tiếp website tĩnh (HTML, CSS, JS, hình ảnh) từ S3.\nKhả năng chính Thiết lập đơn giản: Chỉ vài bước để bật chế độ static website cho bucket. Chi phí thấp: Trả phí lưu trữ và băng thông tiêu chuẩn, không cần máy chủ web riêng. Scale linh hoạt: Tự động xử lý spike traffic. Tích hợp CDN: Dễ dàng kết hợp Amazon CloudFront để tăng hiệu năng toàn cầu. Cấu hình website tĩnh:\n{ \u0026#34;IndexDocument\u0026#34;: { \u0026#34;Suffix\u0026#34;: \u0026#34;index.html\u0026#34; }, \u0026#34;ErrorDocument\u0026#34;: { \u0026#34;Key\u0026#34;: \u0026#34;error.html\u0026#34; } } Cross-Origin Resource Sharing (CORS) CORS cho phép tài nguyên web (font, JavaScript, \u0026hellip;) trên một domain truy cập tài nguyên ở domain khác.\nCấu hình CORS trên S3 Định nghĩa policy: Chỉ rõ những origin nào được phép truy cập nội dung bucket. Kiểm soát method: Cho phép các HTTP method cụ thể (GET, PUT, POST, \u0026hellip;). Tăng cường bảo mật: Ngăn truy cập cross-origin trái phép. Ví dụ cấu hình CORS:\n[ { \u0026#34;AllowedHeaders\u0026#34;: [\u0026#34;*\u0026#34;], \u0026#34;AllowedMethods\u0026#34;: [\u0026#34;GET\u0026#34;, \u0026#34;HEAD\u0026#34;], \u0026#34;AllowedOrigins\u0026#34;: [\u0026#34;https://example.com\u0026#34;], \u0026#34;ExposeHeaders\u0026#34;: [\u0026#34;ETag\u0026#34;], \u0026#34;MaxAgeSeconds\u0026#34;: 3000 } ] Hiệu năng \u0026amp; thiết kế khóa object Cách đặt tên object ảnh hưởng đáng kể tới hiệu năng S3:\nPrefix ngẫu nhiên: Phân tán key qua nhiều partition để tăng song song. Tránh prefix tuần tự: Không dùng tiền tố tăng dần (ví dụ timestamp) cho workload throughput cao. Truy cập song song: Thiết kế key hỗ trợ đọc/ghi đồng thời. Best practice đặt key:\n❌ Tệ: 2025-09-30-file1.jpg, 2025-09-30-file2.jpg Tốt: a1b2/2025-09-30-file1.jpg, c3d4/2025-09-30-file2.jpg S3 Glacier – Lưu trữ dài hạn Các lớp Glacier được tối ưu cho lưu trữ dài hạn chi phí thấp.\nTùy chọn truy xuất Expedited / Fast: Vài phút; chi phí cao. Standard: 3–5 giờ; cân bằng chi phí. Bulk: 5–12 giờ; rẻ nhất cho khôi phục khối lượng lớn. Glacier Deep Archive Lớp chi phí thấp nhất cho lưu trữ nhiều năm, thời gian truy xuất khoảng 12 giờ.\nHands-On Labs Lab 57 – Amazon S3 \u0026amp; CloudFront (Phần 2) Cấu hình object public → 57-5 Kiểm tra website → 57-6 Chặn toàn bộ public access → 57-7.1 Cấu hình CloudFront → 57-7.2 Kiểm tra CloudFront → 57-7.3 Bật Versioning cho bucket → 57-8 "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.5-week5/1.5.2-day22-2025-10-07/","title":"Ngày 22 - IAM Policies &amp; Roles","tags":[],"description":"","content":"Ngày: 2025-10-07\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học IAM Policies Policy IAM là tài liệu JSON mô tả quyền. Các loại: Identity-based policy (gắn vào principal). Resource-based policy (gắn vào resource). Quy tắc đánh giá: mọi explicit Deny sẽ ghi đè Allow trên tất cả policy. Ví dụ ràng buộc admin S3:\nCho phép toàn bộ s3:* trên một bucket cụ thể. Explicit Deny mọi hành động không phải S3. Cấu trúc policy:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [{ \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::my-bucket/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;IpAddress\u0026#34;: { \u0026#34;aws:SourceIp\u0026#34;: \u0026#34;203.0.113.0/24\u0026#34; } } }] } Logic đánh giá policy:\nMặc định mọi request bị từ chối. Allow rõ ràng sẽ ghi đè deny mặc định. Deny rõ ràng ghi đè mọi Allow. Permissions boundary giới hạn quyền tối đa. IAM Roles Role cung cấp quyền tạm thời cho user, dịch vụ hoặc danh tính bên ngoài. Các tình huống phổ biến: Cho phép dịch vụ AWS hành động thay bạn (ví dụ EC2 ghi vào S3). Truy cập chéo tài khoản. Liên kết danh tính từ IdP ngoài (federation). Cấp credential cho ứng dụng trên EC2 mà không cần lưu access key. Lợi ích\nKhông có credential dài hạn, phiên ngắn, hỗ trợ nguyên tắc least privilege và quản lý truy cập quy mô lớn. Các loại role:\nService Role: Cho dịch vụ AWS (EC2, Lambda, \u0026hellip;). Cross-Account Role: Truy cập tài nguyên ở tài khoản khác. Identity Provider Role: Cho người dùng liên kết (federated). Instance Profile: Vỏ chứa role dành cho EC2 instance. Hands-On Labs Lab 48 – IAM Access Keys \u0026amp; Roles (Phần 2) Sử dụng Access Key → 48-2.2 Tạo IAM Role → 48-3.1 Gán IAM Role → 48-3.2 Dọn dẹp tài nguyên → 48-4 Lab 28 – IAM Cross-Region Role \u0026amp; Policy (Phần 1) Tạo IAM User → 28-2.1 Tạo IAM Policy → 28-3 Tạo IAM Role → 28-4 "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.8-week8/1.8.2-day37-2025-10-28/","title":"Ngày 37 - Tiền xử lý văn bản nâng cao","tags":[],"description":"","content":"Ngày: 2025-10-28 Trạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú bài giảng Loại bỏ Stop Word Hiểu về Stop Words Các từ phổ biến có ít giá trị ngữ nghĩa: \u0026ldquo;the\u0026rdquo;, \u0026ldquo;is\u0026rdquo;, \u0026ldquo;at\u0026rdquo;, \u0026ldquo;and\u0026rdquo;, v.v. Loại bỏ chúng giúp giảm nhiễu và chi phí tính toán. Ngữ cảnh quan trọng: đối với một số tác vụ, stop words lại quan trọng. Khi nào nên loại bỏ Stop Words Phân loại văn bản: thường có lợi Phân tích cảm xúc: cẩn thận (\u0026ldquo;not\u0026rdquo; rất quan trọng) Truy xuất thông tin: giúp tập trung vào các từ nội dung Nhận dạng thực thể: có thể cần ngữ cảnh từ stop words Stemming Stemming là gì? Giảm từ về dạng gốc bằng cách loại bỏ hậu tố. \u0026ldquo;running\u0026rdquo;, \u0026ldquo;runs\u0026rdquo;, \u0026ldquo;ran\u0026rdquo; → \u0026ldquo;run\u0026rdquo; Nhanh nhưng có thể tạo ra các từ không có nghĩa (ví dụ: \u0026ldquo;studies\u0026rdquo; → \u0026ldquo;studi\u0026rdquo;) Các thuật toán Stemming phổ biến Porter Stemmer: được sử dụng rộng rãi nhất, độ chính xác trung bình Snowball Stemmer: phiên bản cải tiến của Porter Lancaster Stemmer: mạnh mẽ nhất, có thể stem quá mức Lemmatization Lemmatization là gì? Giảm từ về dạng từ điển (lemma). \u0026ldquo;running\u0026rdquo; → \u0026ldquo;run\u0026rdquo;, \u0026ldquo;better\u0026rdquo; → \u0026ldquo;good\u0026rdquo; Chính xác hơn stemming nhưng chậm hơn. Yêu cầu thông tin từ loại để có kết quả tốt nhất. Stemming vs Lemmatization Khía cạnh Stemming Lemmatization Tốc độ Nhanh Chậm hơn Độ chính xác Thấp hơn Cao hơn Đầu ra Có thể không phải từ thật Luôn là từ thật Trường hợp sử dụng Phân tích nhanh Phân tích chính xác Những hiểu biết quan trọng Lựa chọn tiền xử lý phụ thuộc vào tác vụ cụ thể của bạn. Lemmatization thường tốt hơn cho hệ thống production. Luôn xác thực tác động của tiền xử lý đến hiệu suất mô hình. Ghi chép quy trình tiền xử lý của bạn để có thể tái tạo. Thực hành Lab Lab 1: Loại bỏ Stop Word from nltk.corpus import stopwords from nltk.tokenize import word_tokenize stop_words = set(stopwords.words(\u0026#39;english\u0026#39;)) text = \u0026#34;This is an example sentence demonstrating stop word removal.\u0026#34; words = word_tokenize(text.lower()) filtered_words = [word for word in words if word not in stop_words] print(\u0026#34;Gốc:\u0026#34;, words) print(\u0026#34;Đã lọc:\u0026#34;, filtered_words) Lab 2: So sánh Stemming from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer words = [\u0026#34;running\u0026#34;, \u0026#34;runs\u0026#34;, \u0026#34;ran\u0026#34;, \u0026#34;easily\u0026#34;, \u0026#34;fairly\u0026#34;, \u0026#34;studies\u0026#34;] porter = PorterStemmer() snowball = SnowballStemmer(\u0026#39;english\u0026#39;) lancaster = LancasterStemmer() print(\u0026#34;Từ\\t\\tPorter\\t\\tSnowball\\tLancaster\u0026#34;) print(\u0026#34;-\u0026#34; * 60) for word in words: print(f\u0026#34;{word}\\t\\t{porter.stem(word)}\\t\\t{snowball.stem(word)}\\t\\t{lancaster.stem(word)}\u0026#34;) Lab 3: Lemmatization from nltk.stem import WordNetLemmatizer from nltk.corpus import wordnet lemmatizer = WordNetLemmatizer() words = [\u0026#34;running\u0026#34;, \u0026#34;runs\u0026#34;, \u0026#34;ran\u0026#34;, \u0026#34;better\u0026#34;, \u0026#34;studying\u0026#34;, \u0026#34;studies\u0026#34;] print(\u0026#34;Từ\\t\\tLemma (động từ)\\tLemma (danh từ)\u0026#34;) print(\u0026#34;-\u0026#34; * 50) for word in words: verb_lemma = lemmatizer.lemmatize(word, pos=wordnet.VERB) noun_lemma = lemmatizer.lemmatize(word, pos=wordnet.NOUN) print(f\u0026#34;{word}\\t\\t{verb_lemma}\\t\\t{noun_lemma}\u0026#34;) Lab 4: Quy trình tiền xử lý hoàn chỉnh import nltk from nltk.tokenize import word_tokenize from nltk.corpus import stopwords from nltk.stem import WordNetLemmatizer import string def preprocess_text(text): # Chữ thường text = text.lower() # Tokenize tokens = word_tokenize(text) # Loại bỏ dấu câu và stop words stop_words = set(stopwords.words(\u0026#39;english\u0026#39;)) tokens = [word for word in tokens if word not in string.punctuation and word not in stop_words] # Lemmatize lemmatizer = WordNetLemmatizer() tokens = [lemmatizer.lemmatize(word) for word in tokens] return tokens sample = \u0026#34;The students are studying NLP concepts. They\u0026#39;re learning quickly!\u0026#34; processed = preprocess_text(sample) print(\u0026#34;Tokens đã xử lý:\u0026#34;, processed) Bài tập thực hành So sánh kết quả tiền xử lý có và không có loại bỏ stop word Xây dựng danh sách stop words tùy chỉnh cho một lĩnh vực cụ thể Phân tích stemmer nào hoạt động tốt nhất cho trường hợp sử dụng của bạn Tạo hàm quy trình tiền xử lý cho tweets "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.9-week9/1.9.2-day42-2025-11-04/","title":"Ngày 42 - Phân loại văn bản nâng cao","tags":[],"description":"","content":"Ngày: 2025-11-04\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú bài giảng Ôn tập phân loại văn bản Các khái niệm chính từ Tuần 8 Phân loại văn bản gán các danh mục được xác định trước cho tài liệu Trích xuất đặc trưng: TF-IDF, word embeddings, biểu diễn ngữ cảnh Thuật toán phổ biến: Naive Bayes, SVM, Logistic Regression, Neural Networks Số liệu đánh giá: accuracy, precision, recall, F1-score Kỹ thuật đặc trưng nâng cao TF-IDF chuyên sâu\nTerm Frequency: tần suất từ xuất hiện trong tài liệu Inverse Document Frequency: mức độ hiếm của từ trên tất cả tài liệu Công thức: TF-IDF = TF × log(N/DF) Cân bằng giữa các từ phổ biến và đặc trưng Đặc trưng N-gram\nUnigrams: từ đơn Bigrams: hai từ liên tiếp Trigrams: ba từ liên tiếp Character n-grams: hữu ích cho xử lý lỗi chính tả và hình thái học Kỹ thuật phân loại nâng cao Phương pháp Ensemble Tại sao dùng Ensemble?\nKết hợp nhiều mô hình để có hiệu suất tốt hơn Giảm overfitting thông qua đa dạng hóa Mạnh mẽ hơn với nhiễu và outliers Các cách tiếp cận phổ biến\nVoting: bỏ phiếu đa số từ nhiều bộ phân loại Bagging: Bootstrap Aggregating (ví dụ: Random Forest) Boosting: cải thiện mô hình tuần tự (ví dụ: XGBoost, AdaBoost) Stacking: meta-learner kết hợp các mô hình cơ sở Xử lý dữ liệu mất cân bằng Vấn đề:\nDữ liệu thực tế thường có phân phối lớp không đồng đều Mô hình thiên vị về lớp đa số Hiệu suất kém trên lớp thiểu số Giải pháp:\nOversampling: SMOTE (Synthetic Minority Over-sampling) Undersampling: giảm mẫu lớp đa số Trọng số lớp: phạt lỗi trên lớp thiểu số nhiều hơn Phương pháp Ensemble: EasyEnsemble, BalancedRandomForest Chiến lược Cross-Validation K-Fold Cross-Validation\nChia dữ liệu thành K folds Huấn luyện trên K-1 folds, xác thực trên fold còn lại Lặp lại K lần, trung bình kết quả Giảm overfitting, ước tính hiệu suất tốt hơn Stratified K-Fold\nDuy trì phân phối lớp trong mỗi fold Quan trọng cho tập dữ liệu mất cân bằng Đảm bảo tập huấn luyện/xác thực đại diện Những hiểu biết quan trọng Kỹ thuật đặc trưng thường quan trọng hơn lựa chọn thuật toán Luôn baseline với mô hình đơn giản trước khi dùng mô hình phức tạp Cross-validation thiết yếu cho ước tính hiệu suất đáng tin cậy Kiến thức lĩnh vực quan trọng cho lựa chọn đặc trưng Giám sát cả độ chính xác tổng thể và hiệu suất từng lớp Thực hành Lab Lab 1: Đặc trưng TF-IDF nâng cao from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.model_selection import train_test_split from sklearn.linear_model import LogisticRegression from sklearn.metrics import classification_report import pandas as pd # Tập dữ liệu mẫu texts = [ \u0026#34;Machine learning is fascinating\u0026#34;, \u0026#34;Deep learning neural networks\u0026#34;, \u0026#34;Natural language processing\u0026#34;, \u0026#34;Computer vision image recognition\u0026#34;, \u0026#34;Reinforcement learning agents\u0026#34;, \u0026#34;Supervised learning algorithms\u0026#34;, \u0026#34;Unsupervised clustering methods\u0026#34;, \u0026#34;Classification and regression\u0026#34;, ] labels = [\u0026#34;ML\u0026#34;, \u0026#34;DL\u0026#34;, \u0026#34;NLP\u0026#34;, \u0026#34;CV\u0026#34;, \u0026#34;RL\u0026#34;, \u0026#34;ML\u0026#34;, \u0026#34;ML\u0026#34;, \u0026#34;ML\u0026#34;] # TF-IDF nâng cao với n-grams vectorizer = TfidfVectorizer( max_features=100, ngram_range=(1, 3), # unigrams, bigrams, trigrams min_df=1, max_df=0.8, sublinear_tf=True # áp dụng tỷ lệ tf dưới tuyến tính ) X = vectorizer.fit_transform(texts) print(f\u0026#34;Kích thước ma trận đặc trưng: {X.shape}\u0026#34;) print(f\u0026#34;\\nTop đặc trưng: {vectorizer.get_feature_names_out()[:20]}\u0026#34;) # Phân tích tầm quan trọng đặc trưng feature_names = vectorizer.get_feature_names_out() tfidf_scores = X.toarray().sum(axis=0) feature_importance = pd.DataFrame({ \u0026#39;đặc_trưng\u0026#39;: feature_names, \u0026#39;tầm_quan_trọng\u0026#39;: tfidf_scores }).sort_values(\u0026#39;tầm_quan_trọng\u0026#39;, ascending=False) print(\u0026#34;\\nTop 10 đặc trưng quan trọng nhất:\u0026#34;) print(feature_importance.head(10)) Lab 2: Phân loại Ensemble from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier from sklearn.svm import SVC from sklearn.naive_bayes import MultinomialNB import numpy as np # Chuẩn bị dữ liệu mẫu texts = [ \u0026#34;sản phẩm tuyệt vời rất khuyến khích\u0026#34;, \u0026#34;tệ lãng phí tiền\u0026#34;, \u0026#34;giá trị tốt cho giá\u0026#34;, \u0026#34;mua hàng tồi tệ nhất từng có\u0026#34;, \u0026#34;chất lượng tuyệt vời rất hài lòng\u0026#34;, \u0026#34;thất vọng không đáng giá\u0026#34;, \u0026#34;trải nghiệm tuyệt vời thích nó\u0026#34;, \u0026#34;chất lượng kém hỏng nhanh\u0026#34; ] * 10 # Lặp lại để có nhiều dữ liệu hơn labels = [\u0026#34;tích_cực\u0026#34;, \u0026#34;tiêu_cực\u0026#34;, \u0026#34;tích_cực\u0026#34;, \u0026#34;tiêu_cực\u0026#34;, \u0026#34;tích_cực\u0026#34;, \u0026#34;tiêu_cực\u0026#34;, \u0026#34;tích_cực\u0026#34;, \u0026#34;tiêu_cực\u0026#34;] * 10 X_train, X_test, y_train, y_test = train_test_split( texts, labels, test_size=0.2, random_state=42, stratify=labels ) # Vector hóa vectorizer = TfidfVectorizer(max_features=50) X_train_vec = vectorizer.fit_transform(X_train) X_test_vec = vectorizer.transform(X_test) # Các bộ phân loại riêng lẻ nb_clf = MultinomialNB() svm_clf = SVC(kernel=\u0026#39;linear\u0026#39;, probability=True) rf_clf = RandomForestClassifier(n_estimators=100, random_state=42) # Voting Ensemble voting_clf = VotingClassifier( estimators=[ (\u0026#39;nb\u0026#39;, nb_clf), (\u0026#39;svm\u0026#39;, svm_clf), (\u0026#39;rf\u0026#39;, rf_clf) ], voting=\u0026#39;soft\u0026#39; # sử dụng ước tính xác suất ) # Huấn luyện và đánh giá từng bộ phân loại classifiers = { \u0026#39;Naive Bayes\u0026#39;: nb_clf, \u0026#39;SVM\u0026#39;: svm_clf, \u0026#39;Random Forest\u0026#39;: rf_clf, \u0026#39;Voting Ensemble\u0026#39;: voting_clf } for name, clf in classifiers.items(): clf.fit(X_train_vec, y_train) score = clf.score(X_test_vec, y_test) print(f\u0026#34;{name} Độ chính xác: {score:.4f}\u0026#34;) Lab 3: Xử lý dữ liệu mất cân bằng from imblearn.over_sampling import SMOTE from imblearn.under_sampling import RandomUnderSampler from imblearn.pipeline import Pipeline as ImbPipeline from collections import Counter # Tạo tập dữ liệu mất cân bằng texts_imbalanced = [ \u0026#34;tin nhắn spam giành giải\u0026#34;, \u0026#34;spam tiền miễn phí nhấp\u0026#34;, \u0026#34;spam khẩn cấp cập nhật tài khoản\u0026#34;, ] + [ \u0026#34;email bình thường từ đồng nghiệp\u0026#34;, \u0026#34;lời mời họp bình thường ngày mai\u0026#34;, \u0026#34;báo cáo cập nhật dự án bình thường\u0026#34;, \u0026#34;kế hoạch ăn trưa thứ sáu bình thường\u0026#34;, \u0026#34;đính kèm tài liệu xem xét bình thường\u0026#34;, \u0026#34;cuộc họp nhóm hàng tuần bình thường\u0026#34;, \u0026#34;yêu cầu phê duyệt ngân sách bình thường\u0026#34;, ] * 5 labels_imbalanced = [\u0026#34;spam\u0026#34;] * 3 + [\u0026#34;bình_thường\u0026#34;] * 35 print(f\u0026#34;Phân phối gốc: {Counter(labels_imbalanced)}\u0026#34;) # Vector hóa X_imb = vectorizer.fit_transform(texts_imbalanced) y_imb = labels_imbalanced # Chiến lược 1: Trọng số lớp lr_weighted = LogisticRegression(class_weight=\u0026#39;balanced\u0026#39;, max_iter=1000) lr_weighted.fit(X_imb, y_imb) print(f\u0026#34;\\nLogistic Regression có trọng số đã huấn luyện\u0026#34;) # Chiến lược 2: SMOTE smote = SMOTE(random_state=42) X_resampled, y_resampled = smote.fit_resample(X_imb.toarray(), y_imb) print(f\u0026#34;Sau SMOTE: {Counter(y_resampled)}\u0026#34;) lr_smote = LogisticRegression(max_iter=1000) lr_smote.fit(X_resampled, y_resampled) print(f\u0026#34;SMOTE Logistic Regression đã huấn luyện\u0026#34;) # Chiến lược 3: Undersampling undersample = RandomUnderSampler(random_state=42) X_under, y_under = undersample.fit_resample(X_imb.toarray(), y_imb) print(f\u0026#34;Sau Undersampling: {Counter(y_under)}\u0026#34;) Lab 4: Cross-Validation cho đánh giá mạnh mẽ from sklearn.model_selection import cross_val_score, StratifiedKFold from sklearn.metrics import make_scorer, f1_score # Chuẩn bị dữ liệu texts_cv = [ \u0026#34;đánh giá tích cực sản phẩm tuyệt vời\u0026#34;, \u0026#34;đánh giá tiêu cực chất lượng tệ\u0026#34;, \u0026#34;đánh giá tích cực dịch vụ xuất sắc\u0026#34;, \u0026#34;đánh giá tiêu cực trải nghiệm kém\u0026#34;, ] * 20 labels_cv = [\u0026#34;tích_cực\u0026#34;, \u0026#34;tiêu_cực\u0026#34;, \u0026#34;tích_cực\u0026#34;, \u0026#34;tiêu_cực\u0026#34;] * 20 X_cv = vectorizer.fit_transform(texts_cv) y_cv = labels_cv # Stratified K-Fold skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42) classifiers_cv = { \u0026#39;Logistic Regression\u0026#39;: LogisticRegression(max_iter=1000), \u0026#39;Random Forest\u0026#39;: RandomForestClassifier(n_estimators=100, random_state=42), \u0026#39;SVM\u0026#39;: SVC(kernel=\u0026#39;linear\u0026#39;) } for name, clf in classifiers_cv.items(): # Điểm accuracy cv_scores = cross_val_score(clf, X_cv, y_cv, cv=skf, scoring=\u0026#39;accuracy\u0026#39;) # Điểm F1 f1_scores = cross_val_score(clf, X_cv, y_cv, cv=skf, scoring=make_scorer(f1_score, average=\u0026#39;weighted\u0026#39;)) print(f\u0026#34;\\n{name}:\u0026#34;) print(f\u0026#34; Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\u0026#34;) print(f\u0026#34; F1 Score: {f1_scores.mean():.4f} (+/- {f1_scores.std() * 2:.4f})\u0026#34;) print(f\u0026#34; Điểm các fold: {cv_scores}\u0026#34;) Lab 5: Quy trình phân loại nâng cao hoàn chỉnh from sklearn.pipeline import Pipeline from sklearn.model_selection import GridSearchCV # Xây dựng pipeline pipeline = Pipeline([ (\u0026#39;tfidf\u0026#39;, TfidfVectorizer()), (\u0026#39;clf\u0026#39;, RandomForestClassifier(random_state=42)) ]) # Lưới tham số để điều chỉnh param_grid = { \u0026#39;tfidf__max_features\u0026#39;: [50, 100, 200], \u0026#39;tfidf__ngram_range\u0026#39;: [(1, 1), (1, 2), (1, 3)], \u0026#39;tfidf__min_df\u0026#39;: [1, 2], \u0026#39;clf__n_estimators\u0026#39;: [50, 100, 200], \u0026#39;clf__max_depth\u0026#39;: [None, 10, 20], \u0026#39;clf__min_samples_split\u0026#39;: [2, 5] } # Grid search với cross-validation grid_search = GridSearchCV( pipeline, param_grid, cv=5, scoring=\u0026#39;f1_weighted\u0026#39;, n_jobs=-1, verbose=1 ) # Dữ liệu mẫu texts_full = texts_cv labels_full = labels_cv # Fit print(\u0026#34;Bắt đầu grid search...\u0026#34;) grid_search.fit(texts_full, labels_full) # Kết quả print(f\u0026#34;\\nTham số tốt nhất: {grid_search.best_params_}\u0026#34;) print(f\u0026#34;Điểm cross-validation tốt nhất: {grid_search.best_score_:.4f}\u0026#34;) # Kiểm tra mô hình tốt nhất best_model = grid_search.best_estimator_ test_texts = [\u0026#34;sản phẩm tuyệt vời\u0026#34;, \u0026#34;dịch vụ tệ\u0026#34;] predictions = best_model.predict(test_texts) print(f\u0026#34;\\nDự đoán kiểm tra: {predictions}\u0026#34;) Bài tập thực hành Xây dựng bộ phân loại văn bản đa lớp cho các danh mục tin tức Triển khai pipeline với các bộ trích xuất đặc trưng tùy chỉnh So sánh các chiến lược resampling khác nhau trên dữ liệu mất cân bằng Thực hiện điều chỉnh siêu tham số với cross-validation Phân tích tầm quan trọng đặc trưng và khả năng giải thích mô hình "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.10-week10/1.10.2-day47-2025-11-11/","title":"Ngày 47 - Luồng tải sách lên &amp; Presigned URLs","tags":[],"description":"","content":"Ngày: 2025-11-11\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú bài giảng Kiến trúc luồng Upload Chiến lược S3 Presigned URL Tại sao dùng Presigned URLs?\nUpload trực tiếp lên S3 tránh giới hạn payload API Gateway (10MB) Giảm thời gian thực thi và chi phí Lambda Trải nghiệm người dùng tốt hơn với theo dõi tiến trình Kiến trúc Serverless tự động mở rộng Luồng Upload:\nUser → Yêu cầu Upload URL (API) → Lambda tạo Presigned PUT URL → User upload trực tiếp lên S3 → S3 Event Notification → Lambda cập nhật DynamoDB Cân nhắc bảo mật Cấu hình Presigned URL:\nThời gian hết hạn ngắn (15 phút cho upload) Giới hạn kích thước file qua điều kiện content-length-range Giới hạn MIME types cụ thể (application/pdf, application/epub+zip) Upload vào prefix tạm uploads/, không phải thư mục public Chiến lược xác thực:\nClient-side: kiểm tra kích thước và loại file trước khi yêu cầu URL Server-side: Lambda xác thực metadata trước khi tạo URL S3 Event: Lambda sau upload xác thực MIME type thực tế bằng magic bytes Theo dõi trạng thái: PENDING → VALIDATING → APPROVED/REJECTED Triển khai Upload Frontend Quy trình Upload nhiều bước Bước 1: Chọn \u0026amp; Xác thực File\nGiao diện kéo thả hoặc chọn file Xác thực client-side (kích thước ≤50MB, loại PDF/ePub) Xem trước metadata file (tên, kích thước, loại) Bước 2: Thu thập Metadata\nCác trường form: tiêu đề, tác giả, mô tả, ảnh bìa Chọn thể loại/danh mục Tùy chọn: ISBN, năm xuất bản, ngôn ngữ Bước 3: Yêu cầu Upload URL\nPOST đến endpoint API /upload với metadata Nhận presigned URL và book ID Lưu book ID để theo dõi trạng thái Bước 4: Upload trực tiếp S3\nPUT request đến presigned URL với nội dung file Theo dõi tiến trình upload với XMLHttpRequest hoặc fetch Hiển thị thanh tiến trình và thời gian ước tính còn lại Bước 5: Giám sát trạng thái\nPoll endpoint /books/{id}/status Hiển thị trạng thái hiện tại (PENDING, VALIDATING, APPROVED, REJECTED) Hiển thị lý do từ chối nếu có Những hiểu biết quan trọng Presigned URLs là credentials có thời hạn - xử lý hết hạn một cách graceful Luôn xác thực cả client và server để ngăn uploads độc hại Theo dõi tiến trình cải thiện đáng kể trải nghiệm người dùng với files lớn S3 Event Notifications cho phép xác thực async mà không cần polling Thông báo trạng thái rõ ràng giúp người dùng hiểu quy trình upload Công việc đã hoàn thành UI Components Upload\nTạo component upload file với kéo thả Xây dựng form metadata với validation (React Hook Form + Zod) Triển khai chỉ báo tiến trình upload với phần trăm Thêm xác thực loại file và kích thước Tích hợp API\nTạo phương thức API client cho luồng upload Triển khai API call createUploadUrl với metadata Xây dựng upload trực tiếp S3 với theo dõi tiến trình Thêm xử lý lỗi cho network failures Theo dõi trạng thái\nTạo cơ chế polling trạng thái với intervals Xây dựng component status badge (PENDING, APPROVED, REJECTED) Triển khai cập nhật trạng thái thời gian thực Thêm hệ thống thông báo cho thay đổi trạng thái Trải nghiệm người dùng\nThiết kế wizard upload với form nhiều bước Thêm xem trước file trước khi upload Triển khai thông báo thành công/lỗi Tạo trang \u0026ldquo;My Uploads\u0026rdquo; hiển thị tất cả uploads của người dùng Xử lý lỗi\nXử lý hết hạn presigned URL Triển khai logic retry cho uploads thất bại Thêm thông báo lỗi validation Tạo UI fallback cho lỗi upload Thách thức \u0026amp; Giải pháp Thách thức: Upload files lớn bị timeout\nGiải pháp: Triển khai chunked upload với retry logic cho chunks thất bại\nThách thức: Presigned URL hết hạn trong quá trình upload chậm\nGiải pháp: Yêu cầu URL mới nếu upload mất hơn 10 phút\nThách thức: Người dùng đóng browser trong quá trình upload\nGiải pháp: Thêm theo dõi localStorage để resume uploads và hiển thị cảnh báo trước khi unload trang\nThách thức: Theo dõi tiến trình không chính xác\nGiải pháp: Sử dụng XMLHttpRequest upload.onprogress event để theo dõi chính xác ở cấp độ byte\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.2-week2/","title":"Tuần 2 - Dịch vụ Mạng trên AWS","tags":[],"description":"","content":"Tuần: 2025-09-15 đến 2025-09-19\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 2 Tuần này đào sâu các dịch vụ mạng của AWS, từ VPC cơ bản đến giải pháp kết nối nâng cao và cân bằng tải.\nNội dung chính Amazon VPC và Subnet. Security Group và Network ACL. Internet Gateway, NAT Gateway. VPC Peering và AWS Transit Gateway. Elastic Load Balancing (ALB, NLB, GWLB). Labs thực hành Lab 03: Amazon VPC \u0026amp; Networking Basics. Lab 10: Hybrid DNS (Route 53 Resolver). Lab 19: VPC Peering. Lab 20: AWS Transit Gateway. "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/5-workshop/5.2-prerequisite/","title":"Yêu cầu","tags":[],"description":"","content":"Tài khoản \u0026amp; Quyền Tài khoản AWS với quyền tạo Cognito User Pools, IAM roles và tài nguyên Amplify. Không cần quyền VPC hoặc networking nâng cao cho workshop này. Công cụ Node.js 18+ và npm đã cài đặt trên máy local. AWS Amplify CLI: Cài đặt bằng npm install -g @aws-amplify/cli Code editor (VS Code, Sublime hoặc editor bạn thích). Trình duyệt web để test luồng xác thực. Cài đặt nhanh Cấu hình Amplify CLI:\namplify configure Làm theo hướng dẫn để tạo IAM user với quyền phù hợp.\nChọn region gần với bạn (ví dụ: us-east-1 hoặc ap-southeast-1).\nKiểm tra cài đặt:\nnode --version # Phải là 18+ npm --version amplify --version "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Blog 1 - Tăng cường năng suất tổ chức với Amazon Q Business Browser Extension Blog này khám phá cách tiện ích mở rộng trình duyệt Amazon Q Business mang khả năng AI tạo sinh trực tiếp vào trình duyệt web, cho phép nhân viên nhận được hỗ trợ AI nhận biết ngữ cảnh cho các tác vụ hàng ngày. Bài viết trình bày cách các tổ chức có thể triển khai tiện ích mở rộng này để giúp đội ngũ phân tích nội dung web, cải thiện chất lượng nội dung và truy cập thông tin chi tiết dựa trên AI một cách liền mạch. Bao gồm hướng dẫn thực tế về các điều kiện tiên quyết, các bước cấu hình, tùy chọn triển khai, khả năng tùy chỉnh và các trường hợp sử dụng thực tế cho thấy cách tiện ích mở rộng tăng năng suất nơi làm việc bằng cách kết nối dữ liệu công ty và hệ thống doanh nghiệp với quy trình làm việc dựa trên trình duyệt.\nBlog 2 - Xây dựng quy trình Agentic với OpenAI GPT OSS trên Amazon SageMaker AI và Amazon Bedrock AgentCore Blog này trình bày cách xây dựng các quy trình agentic phức tạp sử dụng các mô hình GPT OSS mã nguồn mở của OpenAI (120B và 20B tham số) được triển khai trên Amazon SageMaker AI. Bài viết tập trung vào việc tạo trợ lý agent phân tích cổ phiếu sử dụng LangGraph để điều phối quy trình và quản lý trạng thái, sau đó triển khai các agent này lên Amazon Bedrock AgentCore cho hoạt động sản xuất có thể mở rộng. Người đọc sẽ tìm hiểu về kiến trúc Mixture of Experts (MoE), các mẫu điều phối đa agent và cách tận dụng khả năng suy luận được quản lý hoàn toàn của SageMaker kết hợp với lớp điều phối thống nhất của Bedrock để xây dựng các ứng dụng AI agent thực tế.\nBlog 3 - Bắt đầu với Data Lake trong Y tế: Sử dụng Microservices Blog này giới thiệu cách xây dựng data lake trong y tế sử dụng kiến trúc microservices để chuyển đổi dữ liệu y tế thành thông tin chi tiết kinh doanh hữu ích trong khi bảo vệ quyền riêng tư của bệnh nhân. Bài viết chi tiết về sự phát triển từ dịch vụ nguyên khối sang các microservices liên kết lỏng lẻo được kết nối thông qua trung tâm nhắn tin pub/sub tập trung, cho phép khả năng bảo trì và linh hoạt tốt hơn khi tích hợp các định dạng dữ liệu y tế đa dạng. Người đọc sẽ tìm hiểu về các quyết định thiết kế kiến trúc, xử lý việc nhập và phân tích tin nhắn HL7v2 thông qua giao diện REST, sử dụng Amazon Cognito với Kiểm soát truy cập dựa trên thuộc tính (ABAC) cho xác thực và ủy quyền, và phá vỡ các kho dữ liệu riêng biệt để kết hợp các loại phân tích khác nhau nhằm ra quyết định tốt hơn trong môi trường y tế.\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.6-week6/1.6.3-day28-2025-10-15/","title":"Day 28 - Amazon Redshift","tags":[],"description":"","content":" ⚠️ Bản dịch tiếng Việt đang được cập nhật. Vui lòng xem nội dung chi tiết trong file _index.md (tiếng Anh).\nNội dung tiếng Việt sẽ được bổ sung sớm để phản ánh đầy đủ các ghi chú và bài lab.\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.7-week7/1.7.3-day33-2025-10-22/","title":"Day 33 - Next.js App Router","tags":[],"description":"","content":" ⚠️ Bản dịch tiếng Việt đang được cập nhật. Vui lòng xem nội dung chi tiết trong file _index.md (tiếng Anh).\nNội dung tiếng Việt sẽ được bổ sung sớm để phản ánh đầy đủ các ghi chú và bài lab.\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/5-workshop/5.3-module3/","title":"Đăng ký &amp; Xác thực người dùng","tags":[],"description":"","content":"Khởi tạo ứng dụng React Tạo ứng dụng React mới và thêm Amplify:\nnpx create-react-app auth-workshop cd auth-workshop npm install aws-amplify @aws-amplify/ui-react Khởi tạo dự án Amplify amplify init # Làm theo hướng dẫn: # - Project name: authworkshop # - Environment: dev # - Default editor: Visual Studio Code # - App type: javascript # - Framework: react # - Source directory: src # - Distribution directory: build # - Build command: npm run build # - Start command: npm start Thêm xác thực amplify add auth # Chọn: Default configuration # Sign-in method: Email # Advanced settings: No Triển khai Backend amplify push Xây dựng giao diện đăng ký Tạo file src/components/Register.js:\nimport { Auth } from \u0026#39;aws-amplify\u0026#39;; import { useState } from \u0026#39;react\u0026#39;; function Register() { const [email, setEmail] = useState(\u0026#39;\u0026#39;); const [password, setPassword] = useState(\u0026#39;\u0026#39;); const [code, setCode] = useState(\u0026#39;\u0026#39;); const [step, setStep] = useState(\u0026#39;register\u0026#39;); const handleRegister = async (e) =\u0026gt; { e.preventDefault(); try { await Auth.signUp({ username: email, password: password, attributes: { email } }); setStep(\u0026#39;verify\u0026#39;); } catch (error) { console.error(\u0026#39;Lỗi:\u0026#39;, error); } }; const handleVerify = async (e) =\u0026gt; { e.preventDefault(); try { await Auth.confirmSignUp(email, code); alert(\u0026#39;Xác thực email thành công!\u0026#39;); } catch (error) { console.error(\u0026#39;Lỗi:\u0026#39;, error); } }; return step === \u0026#39;register\u0026#39; ? ( \u0026lt;form onSubmit={handleRegister}\u0026gt; \u0026lt;input type=\u0026#34;email\u0026#34; value={email} onChange={(e) =\u0026gt; setEmail(e.target.value)} placeholder=\u0026#34;Email\u0026#34; required /\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; value={password} onChange={(e) =\u0026gt; setPassword(e.target.value)} placeholder=\u0026#34;Mật khẩu\u0026#34; required /\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;Đăng ký\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; ) : ( \u0026lt;form onSubmit={handleVerify}\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; value={code} onChange={(e) =\u0026gt; setCode(e.target.value)} placeholder=\u0026#34;Mã xác thực\u0026#34; required /\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;Xác thực\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; ); } export default Register; Kiểm tra đăng ký Khởi động ứng dụng: npm start Điều hướng đến trang đăng ký Nhập email và mật khẩu Kiểm tra email để lấy mã xác thực Nhập mã để xác thực tài khoản "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.1-week1/1.1.3-day03-2025-09-10/","title":"Ngày 03 - Công cụ Quản lý AWS","tags":[],"description":"","content":"Ngày: 2025-09-10\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Bộ công cụ quản trị AWS AWS Management Console Đăng nhập bằng Root User hoặc IAM User (cần ID tài khoản 12 chữ số). Tìm kiếm và mở dashboard của từng dịch vụ. Support Center cho phép tạo ticket hỗ trợ trực tiếp. AWS Command Line Interface (CLI) Công cụ dòng lệnh mã nguồn mở tương tác với dịch vụ AWS. Cung cấp tính năng tương đương Console. Đặc điểm chính:\nHỗ trợ đa nền tảng (Windows, macOS, Linux). Dễ script và tự động hóa. Truy cập trực tiếp API dịch vụ AWS. Quản lý nhiều tài khoản thông qua profiles. AWS SDK (Software Development Kit) Đơn giản hóa việc tích hợp dịch vụ AWS vào ứng dụng. Tự động xử lý xác thực, retry và tuần tự hóa dữ liệu. Ngôn ngữ hỗ trợ:\nPython (Boto3) JavaScript/Node.js Java .NET Ruby, PHP, Go và các ngôn ngữ khác "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.2-week2/1.2.3-day08-2025-09-17/","title":"Ngày 08 - Bảo mật VPC &amp; Flow Logs","tags":[],"description":"","content":"Ngày: 2025-09-17\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Bảo mật VPC Security Group (SG) Tường lửa ảo stateful kiểm soát lưu lượng vào/ra tài nguyên AWS. Quy tắc dựa trên giao thức, cổng, nguồn hoặc security group khác. Chỉ hỗ trợ rule cho phép (allow). Áp dụng ở cấp độ Elastic Network Interface (ENI). Đặc điểm của Security Group:\nStateful: lưu lượng trả về được cho phép tự động. Chỉ có rule cho phép. Đánh giá toàn bộ rule trước khi quyết định. Áp dụng ở mức instance/ENI. Network Access Control List (NACL) Tường lửa ảo stateless hoạt động ở cấp subnet. Quy tắc điều khiển lưu lượng vào/ra theo giao thức, cổng và nguồn. NACL mặc định cho phép tất cả lưu lượng. Đặc điểm của NACL:\nStateless: phải cho phép rõ ràng lưu lượng chiều về. Hỗ trợ cả rule allow và deny. Các rule được xử lý theo thứ tự số. Áp dụng ở mức subnet. VPC Flow Logs Ghi nhận metadata về lưu lượng IP đi/đến các network interface trong VPC. Log có thể gửi tới Amazon CloudWatch Logs hoặc S3. Flow Logs không ghi phần payload của gói tin. Trường hợp sử dụng:\nKhắc phục sự cố kết nối. Theo dõi mẫu lưu lượng. Phân tích bảo mật. Đáp ứng yêu cầu tuân thủ. Hands-On Labs Lab 03 – Amazon VPC \u0026amp; Networking (tiếp) Khởi chạy EC2 trong các subnet → 04-1 Kiểm tra kết nối giữa các instance → 04-2 Tạo NAT Gateway (Private ↔ Internet) → 04-3 EC2 Instance Connect Endpoint (không cần bastion) → 04-5 "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.3-week3/1.3.3-day13-2025-09-24/","title":"Ngày 13 - Instance Store &amp; User Data","tags":[],"description":"","content":"Ngày: 2025-09-24\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Tính năng nâng cao của EC2 Instance Store Instance Store cung cấp lưu trữ block tạm thời gắn trực tiếp vào host EC2. Đặc điểm\nI/O và thông lượng rất cao. Dữ liệu mất khi instance dừng hoặc terminate. Không thể tách rời hoặc tạo snapshot. Tình huống sử dụng\nCache hoặc xử lý dữ liệu tạm. Ứng dụng đã có cơ chế nhân bản/replication riêng. So sánh Instance Store và EBS:\nTiêu chí Instance Store EBS Tính bền vững Tạm thời Bền vững Hiệu năng Rất cao Cao Snapshot Không Có Tháo rời Không Có Chi phí Đã bao gồm Tính riêng User Data Script User Data chạy tự động khi instance khởi tạo (mỗi lần provision AMI). Linux dùng bash script, Windows dùng PowerShell. Ví dụ User Data:\n#!/bin/bash yum update -y yum install -y httpd systemctl start httpd systemctl enable httpd echo \u0026#34;\u0026lt;h1\u0026gt;Hello from $(hostname -f)\u0026lt;/h1\u0026gt;\u0026#34; \u0026gt; /var/www/html/index.html Metadata EC2 Instance Metadata cung cấp thông tin về instance đang chạy như IP private/public, hostname, security group. Thường dùng trong User Data để cấu hình động. Truy cập Metadata:\n# Lấy instance ID curl http://169.254.169.254/latest/meta-data/instance-id # Lấy public IP curl http://169.254.169.254/latest/meta-data/public-ipv4 # Lấy credential IAM role curl http://169.254.169.254/latest/meta-data/iam/security-credentials/role-name Hands-On Labs Lab 07 – AWS Budgets \u0026amp; Cost Management Tạo Budget từ template → 07-01 Hướng dẫn tạo Cost Budget → 07-02 Tạo Usage Budget → 07-03 Tạo Budget cho Reserved Instance → 07-04 Tạo Budget cho Savings Plans → 07-05 Dọn dẹp Budget → 07-06 "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.4-week4/1.4.3-day18-2025-10-01/","title":"Ngày 18 - AWS Snow Family &amp; Hybrid Storage","tags":[],"description":"","content":"Ngày: 2025-10-01\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học AWS Snow Family Bộ thiết bị/dịch vụ chuyên dụng để di chuyển khối lượng dữ liệu lớn vào/ra AWS khi băng thông hạn chế hoặc dữ liệu quá khủng.\nAWS Snowcone: Thiết bị nhỏ gọn, chịu va đập (~8 TB). Phù hợp môi trường edge, vùng xa. AWS Snowball: Snowball Edge Storage Optimized: Tối đa ~80 TB lưu trữ khả dụng. Snowball Edge Compute Optimized: Thêm khả năng compute mạnh với ~42 TB lưu trữ. AWS Snowmobile: Trung tâm dữ liệu container hóa, phục vụ chuyển dữ liệu quy mô exabyte (tới 100 PB). So sánh Snow Family:\nThiết bị Lưu trữ Compute Use case Snowcone 8 TB 2 vCPU Edge, IoT Snowball Storage 80 TB 40 vCPU Di chuyển dữ liệu Snowball Compute 42 TB 52 vCPU Edge computing Snowmobile 100 PB N/A Di dời datacenter Khi nào dùng Snow Family:\nBăng thông hạn chế hoặc chi phí cao. Khối lượng dữ liệu rất lớn (TB tới PB). Địa điểm xa xôi, khó kết nối. Nhu cầu xử lý edge computing. Yêu cầu tuân thủ lưu trữ dữ liệu tại chỗ. "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.5-week5/1.5.3-day23-2025-10-08/","title":"Ngày 23 - Amazon Cognito &amp; Organizations","tags":[],"description":"","content":"Ngày: 2025-10-08\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Amazon Cognito Dịch vụ managed cho xác thực/ủy quyền và quản lý người dùng cho web \u0026amp; mobile. Thành phần: User Pools: Thư mục người dùng phục vụ đăng ký/đăng nhập. Identity Pools: Danh tính liên kết (federated) cung cấp credential tạm thời để truy cập dịch vụ AWS. Tính năng của Cognito User Pools:\nĐăng ký và đăng nhập. Hỗ trợ IdP xã hội (Google, Facebook, Amazon). Hỗ trợ IdP SAML. Multi-factor authentication (MFA). Xác thực email và số điện thoại. Tùy biến luồng đăng nhập. Lambda trigger để mở rộng logic. Tính năng của Cognito Identity Pools:\nCredential AWS tạm thời. Phân biệt truy cập authenticated và unauthenticated. Kiểm soát truy cập dựa trên role. Tích hợp với User Pool. Hỗ trợ IdP bên ngoài. AWS Organizations Quản lý tập trung nhiều tài khoản AWS trong một tổ chức. Lợi ích\nQuản lý tài khoản tập trung. Consolidated Billing. Cấu trúc phân cấp bằng Organizational Unit (OU). Thiết lập guardrail bằng Service Control Policy (SCP). Organizational Unit (OU) Gom tài khoản theo phòng ban, dự án hoặc môi trường; có thể lồng OUs để áp policy theo tầng. Ví dụ cấu trúc OU:\nRoot ├── Production OU │ ├── Web App Account │ └── Database Account ├── Development OU │ ├── Dev Account │ └── Test Account └── Security OU └── Audit Account Consolidated Billing Một hóa đơn cho mọi tài khoản; hưởng lợi từ volume pricing; không phát sinh phí thêm. Lợi ích:\nGiảm giá theo khối lượng dùng chung giữa các tài khoản. Dễ theo dõi và lập báo cáo. Đơn giản hóa phương thức thanh toán. Chia sẻ Reserved Instance. Hands-On Labs Lab 28 – IAM Cross-Region Role \u0026amp; Policy (Phần 2) Switch Role → 28-5.1 Truy cập EC2 Console – Tokyo → 28-5.2.1 Truy cập EC2 Console – N. Virginia → 28-5.2.2 Tạo EC2 (không đáp ứng tag) → 28-5.2.3 Chỉnh sửa tag tài nguyên EC2 → 28-5.2.4 Kiểm tra chính sách → 28-5.2.5 Lab 27 – AWS Resource Groups \u0026amp; Tagging (Phần 1) Tạo EC2 Instance kèm Tag → 27-2.1.1 Quản lý tag cho tài nguyên AWS → 27-2.1.2 Lọc tài nguyên theo tag → 27-2.1.3 "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.8-week8/1.8.3-day38-2025-10-29/","title":"Ngày 38 - Phân tích văn bản &amp; Phân tích cảm xúc","tags":[],"description":"","content":"Ngày: 2025-10-29 Trạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú bài giảng Phân tích văn bản cơ bản Phân tích tần suất từ Đếm tần suất xuất hiện của mỗi từ trong văn bản. Xác định các thuật ngữ và chủ đề phổ biến nhất. Nền tảng cho nhiều ứng dụng NLP. Hữu ích để hiểu nội dung tài liệu một cách nhanh chóng. N-grams Chuỗi N từ liên tiếp. Unigrams: từ đơn (\u0026ldquo;machine\u0026rdquo;) Bigrams: hai từ (\u0026ldquo;machine learning\u0026rdquo;) Trigrams: ba từ (\u0026ldquo;natural language processing\u0026rdquo;) Nắm bắt ngữ cảnh và cụm từ phổ biến. Thống kê văn bản Độ dài tài liệu (từ, câu, ký tự) Kích thước từ vựng (từ duy nhất) Độ dài từ trung bình Đa dạng từ vựng (từ duy nhất / tổng từ) Phân tích cảm xúc Phân tích cảm xúc là gì? Xác định cảm xúc của văn bản: tích cực, tiêu cực hoặc trung tính. Ứng dụng: đánh giá khách hàng, giám sát mạng xã hội, danh tiếng thương hiệu. Các cách tiếp cận: dựa trên từ điển, machine learning, deep learning. Độ phân cực \u0026amp; Tính chủ quan Polarity: từ -1 (tiêu cực) đến +1 (tích cực) Subjectivity: từ 0 (khách quan) đến 1 (chủ quan) Cả hai số liệu đều cung cấp sự hiểu biết sâu sắc về văn bản. Thách thức trong phân tích cảm xúc Châm biếm và mỉa mai khó phát hiện. Phụ thuộc ngữ cảnh: \u0026ldquo;This movie was sick!\u0026rdquo; (tiếng lóng tích cực) Xử lý phủ định: \u0026ldquo;not good\u0026rdquo; vs \u0026ldquo;good\u0026rdquo; Ngôn ngữ đặc thù lĩnh vực và sự khác biệt văn hóa. Những hiểu biết quan trọng Phân tích tần suất đơn giản tiết lộ những hiểu biết đáng ngạc nhiên về tài liệu. N-grams nắm bắt ý nghĩa mà các từ riêng lẻ bỏ lỡ. Phân tích cảm xúc mạnh mẽ nhưng không hoàn hảo - luôn xác thực kết quả. Kết hợp nhiều kỹ thuật phân tích cung cấp sự hiểu biết phong phú hơn. Thực hành Lab Lab 1: Phân tích tần suất từ from collections import Counter from nltk.tokenize import word_tokenize from nltk.corpus import stopwords import string text = \u0026#34;\u0026#34;\u0026#34; Natural Language Processing is a subfield of artificial intelligence. It focuses on the interaction between computers and human language. NLP enables machines to understand and generate human language. \u0026#34;\u0026#34;\u0026#34; # Tiền xử lý tokens = word_tokenize(text.lower()) stop_words = set(stopwords.words(\u0026#39;english\u0026#39;)) tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation] # Phân tích tần suất freq_dist = Counter(tokens) print(\u0026#34;Top 10 từ phổ biến nhất:\u0026#34;) for word, count in freq_dist.most_common(10): print(f\u0026#34;{word}: {count}\u0026#34;) Lab 2: Phân tích N-gram from nltk import ngrams from collections import Counter def get_ngrams(text, n): tokens = word_tokenize(text.lower()) n_grams = list(ngrams(tokens, n)) return n_grams text = \u0026#34;Natural language processing enables machine learning applications\u0026#34; # Tạo bigrams bigrams = get_ngrams(text, 2) print(\u0026#34;Bigrams:\u0026#34;, bigrams) # Tạo trigrams trigrams = get_ngrams(text, 3) print(\u0026#34;Trigrams:\u0026#34;, trigrams) # Bigrams phổ biến nhất bigram_freq = Counter(bigrams) print(\u0026#34;\\nBigrams phổ biến nhất:\u0026#34;, bigram_freq.most_common(5)) Lab 3: Thống kê văn bản def calculate_text_statistics(text): # Tokenize words = word_tokenize(text) sentences = sent_tokenize(text) # Tính thống kê stats = { \u0026#39;tổng_từ\u0026#39;: len(words), \u0026#39;từ_duy_nhất\u0026#39;: len(set(words)), \u0026#39;tổng_câu\u0026#39;: len(sentences), \u0026#39;độ_dài_từ_tb\u0026#39;: sum(len(word) for word in words) / len(words), \u0026#39;độ_dài_câu_tb\u0026#39;: len(words) / len(sentences), \u0026#39;đa_dạng_từ_vựng\u0026#39;: len(set(words)) / len(words) } return stats sample_text = \u0026#34;\u0026#34;\u0026#34; Natural Language Processing is fascinating. It enables computers to understand human language. NLP has many practical applications in today\u0026#39;s technology-driven world. \u0026#34;\u0026#34;\u0026#34; stats = calculate_text_statistics(sample_text) for key, value in stats.items(): print(f\u0026#34;{key}: {value:.2f}\u0026#34;) Lab 4: Phân tích cảm xúc với TextBlob from textblob import TextBlob def analyze_sentiment(text): blob = TextBlob(text) sentiment = blob.sentiment # Xác định loại cảm xúc if sentiment.polarity \u0026gt; 0.1: category = \u0026#34;Tích cực\u0026#34; elif sentiment.polarity \u0026lt; -0.1: category = \u0026#34;Tiêu cực\u0026#34; else: category = \u0026#34;Trung tính\u0026#34; return { \u0026#39;polarity\u0026#39;: sentiment.polarity, \u0026#39;subjectivity\u0026#39;: sentiment.subjectivity, \u0026#39;category\u0026#39;: category } # Kiểm tra với các câu khác nhau texts = [ \u0026#34;I love this product! It\u0026#39;s amazing and works perfectly.\u0026#34;, \u0026#34;This is the worst experience I\u0026#39;ve ever had.\u0026#34;, \u0026#34;The item arrived on time and matches the description.\u0026#34;, \u0026#34;I\u0026#39;m not sure if I like this or not.\u0026#34; ] for text in texts: result = analyze_sentiment(text) print(f\u0026#34;\\nVăn bản: {text}\u0026#34;) print(f\u0026#34;Polarity: {result[\u0026#39;polarity\u0026#39;]:.2f}\u0026#34;) print(f\u0026#34;Subjectivity: {result[\u0026#39;subjectivity\u0026#39;]:.2f}\u0026#34;) print(f\u0026#34;Cảm xúc: {result[\u0026#39;category\u0026#39;]}\u0026#34;) Lab 5: Phân tích cảm xúc với VADER from nltk.sentiment import SentimentIntensityAnalyzer import nltk nltk.download(\u0026#39;vader_lexicon\u0026#39;) sia = SentimentIntensityAnalyzer() texts = [ \u0026#34;I absolutely love this! Best purchase ever!!!\u0026#34;, \u0026#34;This product is terrible. Complete waste of money.\u0026#34;, \u0026#34;It\u0026#39;s okay, nothing special.\u0026#34;, \u0026#34;Not bad, but could be better.\u0026#34; ] for text in texts: scores = sia.polarity_scores(text) print(f\u0026#34;\\nVăn bản: {text}\u0026#34;) print(f\u0026#34;Điểm: {scores}\u0026#34;) # Xác định cảm xúc tổng thể if scores[\u0026#39;compound\u0026#39;] \u0026gt;= 0.05: sentiment = \u0026#34;Tích cực\u0026#34; elif scores[\u0026#39;compound\u0026#39;] \u0026lt;= -0.05: sentiment = \u0026#34;Tiêu cực\u0026#34; else: sentiment = \u0026#34;Trung tính\u0026#34; print(f\u0026#34;Tổng thể: {sentiment}\u0026#34;) Bài tập thực hành Phân tích tần suất từ trong cuốn sách hoặc bài báo yêu thích của bạn Trích xuất và phân tích bigrams/trigrams từ bài đăng trên mạng xã hội Xây dựng bộ phân loại cảm xúc cho đánh giá sản phẩm So sánh kết quả cảm xúc từ TextBlob và VADER Tạo trực quan hóa cho tần suất từ và phân phối cảm xúc "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.9-week9/1.9.3-day43-2025-11-05/","title":"Ngày 43 - Hệ thống phân tích cảm xúc Production","tags":[],"description":"","content":"Ngày: 2025-11-05\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú bài giảng Ôn tập phân tích cảm xúc Các khái niệm chính từ Tuần 8 Phân tích cảm xúc xác định cảm xúc: tích cực, tiêu cực, trung tính Các cách tiếp cận: dựa trên từ điển, machine learning, deep learning Số liệu: polarity (-1 đến +1), subjectivity (0 đến 1) Thách thức: châm biếm, ngữ cảnh, phủ định, ngôn ngữ đặc thù lĩnh vực Vượt xa phân tích cảm xúc cơ bản Phân tích cảm xúc dựa trên khía cạnh\nXác định cảm xúc hướng đến các khía cạnh/tính năng cụ thể Ví dụ: \u0026ldquo;Camera tuyệt vời nhưng pin tệ\u0026rdquo; Camera: tích cực Pin: tiêu cực Hiểu biết chi tiết hơn cho đánh giá sản phẩm Phát hiện cảm xúc\nVượt xa tích cực/tiêu cực: vui, giận, buồn, sợ, ngạc nhiên Vấn đề phân loại đa nhãn Hữu ích cho hỗ trợ khách hàng, giám sát sức khỏe tâm thần Hệ thống sẵn sàng Production Yêu cầu cho Production Khả năng mở rộng\nXử lý khối lượng yêu cầu cao Xử lý thời gian thực hoặc gần thời gian thực Xử lý hàng loạt cho tập dữ liệu lớn Độ mạnh mẽ\nXử lý văn bản nhiễu, không chính thức (lỗi chính tả, tiếng lóng, emoji) Xử lý graceful trên các trường hợp biên Điểm tin cậy rõ ràng Giám sát \u0026amp; Bảo trì\nTheo dõi hiệu suất mô hình theo thời gian Phát hiện concept drift (ngôn ngữ thay đổi) A/B testing cho cải thiện mô hình Logging và theo dõi lỗi Thực hành tốt nhất về thiết kế API Xác thực đầu vào\nGiới hạn độ dài văn bản Xử lý mã hóa ký tự Sanitization đầu vào độc hại Định dạng phản hồi\n{ \u0026#34;text\u0026#34;: \u0026#34;văn bản đầu vào\u0026#34;, \u0026#34;sentiment\u0026#34;: \u0026#34;tích_cực\u0026#34;, \u0026#34;confidence\u0026#34;: 0.92, \u0026#34;polarity\u0026#34;: 0.75, \u0026#34;subjectivity\u0026#34;: 0.65, \u0026#34;timestamp\u0026#34;: \u0026#34;2025-11-05T10:00:00Z\u0026#34; } Xử lý lỗi\nThông báo lỗi có ý nghĩa Mã trạng thái HTTP Giới hạn tỷ lệ Xác thực yêu cầu Kỹ thuật nâng cao Transfer Learning Mô hình đã huấn luyện trước (BERT, RoBERTa) cho hiệu suất tốt hơn Fine-tuning trên dữ liệu đặc thù lĩnh vực Giảm yêu cầu dữ liệu huấn luyện Kết quả tiên tiến nhất Cách tiếp cận Ensemble Kết hợp phương pháp dựa trên từ điển và ML Voting hoặc trung bình có trọng số Cải thiện độ mạnh mẽ và độ chính xác Xử lý tốt hơn các trường hợp biên Những hiểu biết quan trọng Hệ thống production yêu cầu nhiều hơn độ chính xác tốt Thích ứng lĩnh vực quan trọng cho hiệu suất thực tế Giám sát liên tục thiết yếu để duy trì chất lượng Thiết kế API ảnh hưởng đến cả khả năng sử dụng và độ tin cậy hệ thống Thực hành Lab Lab 1: Phân tích cảm xúc dựa trên khía cạnh import spacy from textblob import TextBlob import re nlp = spacy.load(\u0026#34;en_core_web_sm\u0026#34;) class AspectSentimentAnalyzer: \u0026#34;\u0026#34;\u0026#34;Phân tích cảm xúc cho các khía cạnh cụ thể\u0026#34;\u0026#34;\u0026#34; def __init__(self): self.aspect_keywords = { \u0026#39;camera\u0026#39;: [\u0026#39;camera\u0026#39;, \u0026#39;photo\u0026#39;, \u0026#39;picture\u0026#39;, \u0026#39;lens\u0026#39;, \u0026#39;image\u0026#39;], \u0026#39;battery\u0026#39;: [\u0026#39;battery\u0026#39;, \u0026#39;charge\u0026#39;, \u0026#39;power\u0026#39;], \u0026#39;screen\u0026#39;: [\u0026#39;screen\u0026#39;, \u0026#39;display\u0026#39;, \u0026#39;brightness\u0026#39;], \u0026#39;performance\u0026#39;: [\u0026#39;speed\u0026#39;, \u0026#39;fast\u0026#39;, \u0026#39;slow\u0026#39;, \u0026#39;lag\u0026#39;, \u0026#39;performance\u0026#39;], \u0026#39;price\u0026#39;: [\u0026#39;price\u0026#39;, \u0026#39;cost\u0026#39;, \u0026#39;expensive\u0026#39;, \u0026#39;cheap\u0026#39;, \u0026#39;value\u0026#39;] } def extract_aspect_sentences(self, text): \u0026#34;\u0026#34;\u0026#34;Trích xuất câu đề cập đến mỗi khía cạnh\u0026#34;\u0026#34;\u0026#34; doc = nlp(text) aspect_sentences = {aspect: [] for aspect in self.aspect_keywords} for sent in doc.sents: sent_text = sent.text.lower() for aspect, keywords in self.aspect_keywords.items(): if any(keyword in sent_text for keyword in keywords): aspect_sentences[aspect].append(sent.text) return aspect_sentences def analyze_aspect_sentiment(self, text): \u0026#34;\u0026#34;\u0026#34;Phân tích cảm xúc cho mỗi khía cạnh\u0026#34;\u0026#34;\u0026#34; aspect_sentences = self.extract_aspect_sentences(text) results = {} for aspect, sentences in aspect_sentences.items(): if not sentences: continue sentiments = [] for sentence in sentences: blob = TextBlob(sentence) sentiments.append(blob.sentiment.polarity) avg_sentiment = sum(sentiments) / len(sentiments) results[aspect] = { \u0026#39;cảm_xúc\u0026#39;: \u0026#39;tích_cực\u0026#39; if avg_sentiment \u0026gt; 0.1 else \u0026#39;tiêu_cực\u0026#39; if avg_sentiment \u0026lt; -0.1 else \u0026#39;trung_tính\u0026#39;, \u0026#39;polarity\u0026#39;: avg_sentiment, \u0026#39;đề_cập\u0026#39;: len(sentences), \u0026#39;ví_dụ\u0026#39;: sentences[:2] # 2 ví dụ đầu } return results # Kiểm tra phân tích dựa trên khía cạnh analyzer = AspectSentimentAnalyzer() review = \u0026#34;\u0026#34;\u0026#34; Điện thoại này có camera tuyệt vời! Ảnh rất rõ nét và sống động. Tuy nhiên, pin thì thất vọng - chỉ dùng được chưa đầy một ngày. Màn hình đẹp với độ sáng xuất sắc. Hiệu suất tốt nhưng không tuyệt vời, đôi khi bị lag. Với mức giá này, nó là giá trị tốt. \u0026#34;\u0026#34;\u0026#34; aspects = analyzer.analyze_aspect_sentiment(review) print(\u0026#34;Phân tích cảm xúc dựa trên khía cạnh:\\n\u0026#34;) for aspect, info in aspects.items(): print(f\u0026#34;{aspect.upper()}:\u0026#34;) print(f\u0026#34; Cảm xúc: {info[\u0026#39;cảm_xúc\u0026#39;]}\u0026#34;) print(f\u0026#34; Polarity: {info[\u0026#39;polarity\u0026#39;]:.2f}\u0026#34;) print(f\u0026#34; Đề cập: {info[\u0026#39;đề_cập\u0026#39;]}\u0026#34;) print(f\u0026#34; Ví dụ: {info[\u0026#39;ví_dụ\u0026#39;]}\u0026#34;) print() Lab 2: Phát hiện cảm xúc đa lớp from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.multioutput import MultiOutputClassifier from sklearn.linear_model import LogisticRegression from sklearn.metrics import classification_report import numpy as np # Tập dữ liệu mẫu với nhiều cảm xúc texts = [ \u0026#34;Tôi rất vui và phấn khích về điều này!\u0026#34;, \u0026#34;Điều này làm tôi rất tức giận và bực bội\u0026#34;, \u0026#34;Tôi sợ hãi và lo lắng về tương lai\u0026#34;, \u0026#34;Thật là một bất ngờ thú vị! Tôi rất vui\u0026#34;, \u0026#34;Đây là tin buồn và thất vọng\u0026#34;, ] * 10 # Cảm xúc đa nhãn (có thể có nhiều cảm xúc) emotions = [ {\u0026#39;vui\u0026#39;: 1, \u0026#39;giận\u0026#39;: 0, \u0026#39;sợ\u0026#39;: 0, \u0026#39;ngạc_nhiên\u0026#39;: 0, \u0026#39;buồn\u0026#39;: 0}, {\u0026#39;vui\u0026#39;: 0, \u0026#39;giận\u0026#39;: 1, \u0026#39;sợ\u0026#39;: 0, \u0026#39;ngạc_nhiên\u0026#39;: 0, \u0026#39;buồn\u0026#39;: 0}, {\u0026#39;vui\u0026#39;: 0, \u0026#39;giận\u0026#39;: 0, \u0026#39;sợ\u0026#39;: 1, \u0026#39;ngạc_nhiên\u0026#39;: 0, \u0026#39;buồn\u0026#39;: 0}, {\u0026#39;vui\u0026#39;: 1, \u0026#39;giận\u0026#39;: 0, \u0026#39;sợ\u0026#39;: 0, \u0026#39;ngạc_nhiên\u0026#39;: 1, \u0026#39;buồn\u0026#39;: 0}, {\u0026#39;vui\u0026#39;: 0, \u0026#39;giận\u0026#39;: 0, \u0026#39;sợ\u0026#39;: 0, \u0026#39;ngạc_nhiên\u0026#39;: 0, \u0026#39;buồn\u0026#39;: 1}, ] * 10 # Chuyển đổi sang định dạng array emotion_labels = [\u0026#39;vui\u0026#39;, \u0026#39;giận\u0026#39;, \u0026#39;sợ\u0026#39;, \u0026#39;ngạc_nhiên\u0026#39;, \u0026#39;buồn\u0026#39;] y = np.array([[e[label] for label in emotion_labels] for e in emotions]) # Vector hóa vectorizer = TfidfVectorizer(max_features=100) X = vectorizer.fit_transform(texts) # Bộ phân loại đa đầu ra classifier = MultiOutputClassifier(LogisticRegression(max_iter=1000)) classifier.fit(X, y) # Kiểm tra test_texts = [ \u0026#34;Tôi phấn khích và ngạc nhiên!\u0026#34;, \u0026#34;Điều này đáng sợ và làm tôi lo lắng\u0026#34;, \u0026#34;Rất thất vọng và buồn bã\u0026#34; ] test_X = vectorizer.transform(test_texts) predictions = classifier.predict(test_X) print(\u0026#34;Kết quả phát hiện cảm xúc:\\n\u0026#34;) for text, pred in zip(test_texts, predictions): detected_emotions = [emotion_labels[i] for i, val in enumerate(pred) if val == 1] print(f\u0026#34;Văn bản: {text}\u0026#34;) print(f\u0026#34;Cảm xúc: {\u0026#39;, \u0026#39;.join(detected_emotions) if detected_emotions else \u0026#39;trung_tính\u0026#39;}\\n\u0026#34;) Lab 3: API sẵn sàng Production với FastAPI from fastapi import FastAPI, HTTPException from pydantic import BaseModel, validator from textblob import TextBlob from datetime import datetime import uvicorn app = FastAPI(title=\u0026#34;API Phân tích Cảm xúc\u0026#34;) class SentimentRequest(BaseModel): text: str @validator(\u0026#39;text\u0026#39;) def validate_text(cls, v): if not v or len(v.strip()) == 0: raise ValueError(\u0026#39;Văn bản không thể trống\u0026#39;) if len(v) \u0026gt; 5000: raise ValueError(\u0026#39;Văn bản quá dài (tối đa 5000 ký tự)\u0026#39;) return v class SentimentResponse(BaseModel): text: str sentiment: str confidence: float polarity: float subjectivity: float timestamp: str @app.post(\u0026#34;/analyze\u0026#34;, response_model=SentimentResponse) async def analyze_sentiment(request: SentimentRequest): \u0026#34;\u0026#34;\u0026#34;Phân tích cảm xúc của văn bản đầu vào\u0026#34;\u0026#34;\u0026#34; try: blob = TextBlob(request.text) polarity = blob.sentiment.polarity subjectivity = blob.sentiment.subjectivity # Xác định danh mục cảm xúc if polarity \u0026gt; 0.1: sentiment = \u0026#34;tích_cực\u0026#34; confidence = min(polarity, 1.0) elif polarity \u0026lt; -0.1: sentiment = \u0026#34;tiêu_cực\u0026#34; confidence = min(abs(polarity), 1.0) else: sentiment = \u0026#34;trung_tính\u0026#34; confidence = 1.0 - abs(polarity) return SentimentResponse( text=request.text, sentiment=sentiment, confidence=round(confidence, 2), polarity=round(polarity, 2), subjectivity=round(subjectivity, 2), timestamp=datetime.utcnow().isoformat() + \u0026#34;Z\u0026#34; ) except Exception as e: raise HTTPException(status_code=500, detail=f\u0026#34;Phân tích thất bại: {str(e)}\u0026#34;) @app.get(\u0026#34;/health\u0026#34;) async def health_check(): \u0026#34;\u0026#34;\u0026#34;Endpoint kiểm tra sức khỏe\u0026#34;\u0026#34;\u0026#34; return {\u0026#34;status\u0026#34;: \u0026#34;healthy\u0026#34;, \u0026#34;timestamp\u0026#34;: datetime.utcnow().isoformat()} # Chạy: uvicorn script_name:app --reload # Kiểm tra: curl -X POST \u0026#34;http://localhost:8000/analyze\u0026#34; -H \u0026#34;Content-Type: application/json\u0026#34; -d \u0026#39;{\u0026#34;text\u0026#34;:\u0026#34;Tôi yêu sản phẩm này!\u0026#34;}\u0026#39; Lab 4: Bộ phân tích cảm xúc Ensemble from textblob import TextBlob from nltk.sentiment import SentimentIntensityAnalyzer import nltk nltk.download(\u0026#39;vader_lexicon\u0026#39;, quiet=True) class EnsembleSentimentAnalyzer: \u0026#34;\u0026#34;\u0026#34;Kết hợp nhiều phương pháp phân tích cảm xúc\u0026#34;\u0026#34;\u0026#34; def __init__(self): self.sia = SentimentIntensityAnalyzer() def textblob_sentiment(self, text): \u0026#34;\u0026#34;\u0026#34;Phân tích TextBlob\u0026#34;\u0026#34;\u0026#34; blob = TextBlob(text) polarity = blob.sentiment.polarity if polarity \u0026gt; 0.1: return \u0026#39;tích_cực\u0026#39;, polarity elif polarity \u0026lt; -0.1: return \u0026#39;tiêu_cực\u0026#39;, polarity else: return \u0026#39;trung_tính\u0026#39;, polarity def vader_sentiment(self, text): \u0026#34;\u0026#34;\u0026#34;Phân tích VADER\u0026#34;\u0026#34;\u0026#34; scores = self.sia.polarity_scores(text) compound = scores[\u0026#39;compound\u0026#39;] if compound \u0026gt;= 0.05: return \u0026#39;tích_cực\u0026#39;, compound elif compound \u0026lt;= -0.05: return \u0026#39;tiêu_cực\u0026#39;, compound else: return \u0026#39;trung_tính\u0026#39;, compound def ensemble_predict(self, text, method=\u0026#39;voting\u0026#39;): \u0026#34;\u0026#34;\u0026#34;Kết hợp dự đoán từ nhiều phương pháp\u0026#34;\u0026#34;\u0026#34; # Lấy dự đoán từ cả hai phương pháp tb_sentiment, tb_score = self.textblob_sentiment(text) vader_sentiment, vader_score = self.vader_sentiment(text) if method == \u0026#39;voting\u0026#39;: # Voting đa số sentiments = [tb_sentiment, vader_sentiment] final_sentiment = max(set(sentiments), key=sentiments.count) elif method == \u0026#39;weighted\u0026#39;: # Trung bình có trọng số (trọng số cao hơn cho độ tin cậy cao hơn) tb_weight = abs(tb_score) vader_weight = abs(vader_score) total_weight = tb_weight + vader_weight if total_weight == 0: return \u0026#39;trung_tính\u0026#39;, 0.0, {\u0026#39;textblob\u0026#39;: tb_sentiment, \u0026#39;vader\u0026#39;: vader_sentiment} # Trọng số cảm xúc sentiment_scores = {\u0026#39;tích_cực\u0026#39;: 0, \u0026#39;tiêu_cực\u0026#39;: 0, \u0026#39;trung_tính\u0026#39;: 0} sentiment_scores[tb_sentiment] += tb_weight sentiment_scores[vader_sentiment] += vader_weight final_sentiment = max(sentiment_scores, key=sentiment_scores.get) confidence = sentiment_scores[final_sentiment] / total_weight return final_sentiment, confidence, { \u0026#39;textblob\u0026#39;: (tb_sentiment, tb_score), \u0026#39;vader\u0026#39;: (vader_sentiment, vader_score) } return final_sentiment, 0.0, {\u0026#39;textblob\u0026#39;: tb_sentiment, \u0026#39;vader\u0026#39;: vader_sentiment} # Kiểm tra ensemble ensemble = EnsembleSentimentAnalyzer() test_sentences = [ \u0026#34;Sản phẩm này tuyệt vời!\u0026#34;, \u0026#34;Mua hàng tồi tệ nhất, lãng phí tiền\u0026#34;, \u0026#34;Tạm được, không có gì đặc biệt\u0026#34;, \u0026#34;Không tệ, nhưng có thể tốt hơn\u0026#34;, \u0026#34;Tôi yêu nó quá!!!\u0026#34; ] print(\u0026#34;Phân tích cảm xúc Ensemble:\\n\u0026#34;) for sentence in test_sentences: sentiment, confidence, details = ensemble.ensemble_predict(sentence, method=\u0026#39;weighted\u0026#39;) print(f\u0026#34;Văn bản: {sentence}\u0026#34;) print(f\u0026#34;Cảm xúc cuối cùng: {sentiment} (tin cậy: {confidence:.2f})\u0026#34;) print(f\u0026#34;TextBlob: {details[\u0026#39;textblob\u0026#39;]}\u0026#34;) print(f\u0026#34;VADER: {details[\u0026#39;vader\u0026#39;]}\u0026#34;) print() Lab 5: Phân tích cảm xúc với giám sát hiệu suất import time from collections import defaultdict from datetime import datetime class MonitoredSentimentAnalyzer: \u0026#34;\u0026#34;\u0026#34;Bộ phân tích cảm xúc với giám sát tích hợp\u0026#34;\u0026#34;\u0026#34; def __init__(self): self.stats = defaultdict(int) self.response_times = [] self.errors = [] def analyze(self, text): \u0026#34;\u0026#34;\u0026#34;Phân tích với giám sát\u0026#34;\u0026#34;\u0026#34; start_time = time.time() try: # Thực hiện phân tích blob = TextBlob(text) polarity = blob.sentiment.polarity if polarity \u0026gt; 0.1: sentiment = \u0026#34;tích_cực\u0026#34; elif polarity \u0026lt; -0.1: sentiment = \u0026#34;tiêu_cực\u0026#34; else: sentiment = \u0026#34;trung_tính\u0026#34; # Ghi lại thống kê self.stats[\u0026#39;tổng_yêu_cầu\u0026#39;] += 1 self.stats[f\u0026#39;{sentiment}_count\u0026#39;] += 1 response_time = time.time() - start_time self.response_times.append(response_time) return { \u0026#39;cảm_xúc\u0026#39;: sentiment, \u0026#39;polarity\u0026#39;: polarity, \u0026#39;thời_gian_phản_hồi\u0026#39;: response_time } except Exception as e: self.stats[\u0026#39;lỗi\u0026#39;] += 1 self.errors.append({ \u0026#39;timestamp\u0026#39;: datetime.now().isoformat(), \u0026#39;error\u0026#39;: str(e), \u0026#39;text_length\u0026#39;: len(text) }) raise def get_metrics(self): \u0026#34;\u0026#34;\u0026#34;Lấy số liệu hiệu suất\u0026#34;\u0026#34;\u0026#34; if not self.response_times: return {} return { \u0026#39;tổng_yêu_cầu\u0026#39;: self.stats[\u0026#39;tổng_yêu_cầu\u0026#39;], \u0026#39;tỷ_lệ_tích_cực\u0026#39;: self.stats[\u0026#39;tích_cực_count\u0026#39;] / self.stats[\u0026#39;tổng_yêu_cầu\u0026#39;], \u0026#39;tỷ_lệ_tiêu_cực\u0026#39;: self.stats[\u0026#39;tiêu_cực_count\u0026#39;] / self.stats[\u0026#39;tổng_yêu_cầu\u0026#39;], \u0026#39;tỷ_lệ_trung_tính\u0026#39;: self.stats[\u0026#39;trung_tính_count\u0026#39;] / self.stats[\u0026#39;tổng_yêu_cầu\u0026#39;], \u0026#39;thời_gian_phản_hồi_tb\u0026#39;: sum(self.response_times) / len(self.response_times), \u0026#39;thời_gian_phản_hồi_min\u0026#39;: min(self.response_times), \u0026#39;thời_gian_phản_hồi_max\u0026#39;: max(self.response_times), \u0026#39;số_lỗi\u0026#39;: self.stats[\u0026#39;lỗi\u0026#39;], \u0026#39;tỷ_lệ_lỗi\u0026#39;: self.stats[\u0026#39;lỗi\u0026#39;] / self.stats[\u0026#39;tổng_yêu_cầu\u0026#39;] if self.stats[\u0026#39;tổng_yêu_cầu\u0026#39;] \u0026gt; 0 else 0 } # Kiểm tra giám sát monitored = MonitoredSentimentAnalyzer() # Mô phỏng yêu cầu test_texts = [ \u0026#34;Sản phẩm tuyệt vời!\u0026#34;, \u0026#34;Dịch vụ tệ\u0026#34;, \u0026#34;Tạm được\u0026#34;, \u0026#34;Yêu nó!\u0026#34;, \u0026#34;Thất vọng\u0026#34; ] * 20 for text in test_texts: result = monitored.analyze(text) # Lấy số liệu metrics = monitored.get_metrics() print(\u0026#34;Số liệu hiệu suất:\\n\u0026#34;) for key, value in metrics.items(): if \u0026#39;thời_gian\u0026#39; in key: print(f\u0026#34;{key}: {value*1000:.2f}ms\u0026#34;) elif \u0026#39;tỷ_lệ\u0026#39; in key: print(f\u0026#34;{key}: {value*100:.2f}%\u0026#34;) else: print(f\u0026#34;{key}: {value}\u0026#34;) Bài tập thực hành Xây dựng bộ phân tích cảm xúc dựa trên khía cạnh cho đánh giá nhà hàng Tạo dashboard cảm xúc thời gian thực bằng Streamlit Triển khai phân tích xu hướng cảm xúc theo thời gian Xây dựng API cảm xúc với giới hạn tỷ lệ và caching So sánh các thư viện và cách tiếp cận phân tích cảm xúc khác nhau "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.10-week10/1.10.3-day48-2025-11-12/","title":"Ngày 48 - Bảng điều khiển Admin &amp; Quy trình duyệt","tags":[],"description":"","content":"Ngày: 2025-11-12\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú bài giảng Kiến trúc bảng điều khiển Admin Kiểm soát truy cập dựa trên vai trò (RBAC) Triển khai Cognito Groups:\nAdmin users được gán vào nhóm Admins trong Cognito User Pool JWT token chứa claim cognito:groups: [\u0026quot;Admins\u0026quot;] Frontend kiểm tra user groups trước khi render admin routes API Gateway xác thực JWT, Lambda xác thực group membership Luồng phân quyền:\nAdmin Login → Cognito trả JWT với groups → Frontend kiểm tra groups → Hiện/Ẩn admin navigation → Admin action → API xác thực JWT + groups → Lambda thực thi Tính năng bảng điều khiển Admin Chức năng cốt lõi:\nXem xét sách Pending: Liệt kê tất cả sách với trạng thái PENDING Hành động Duyệt/Từ chối: Duyệt hoặc từ chối với lý do Quản lý sách: Xem tất cả sách, tìm kiếm, lọc theo trạng thái Quản lý người dùng: Xem uploaders, activity logs Phân tích: Thống kê upload, tỷ lệ duyệt, sử dụng lưu trữ Quy trình trạng thái:\nPENDING → Trạng thái upload ban đầu VALIDATING → Đang xác thực MIME server-side APPROVED → Admin duyệt, sách có thể truy cập công khai REJECTED → Admin từ chối với lý do TAKEDOWN → Nội dung bị gỡ do vi phạm bản quyền Triển khai quy trình duyệt Luồng Backend (Lambda) approveBook Lambda:\n1. Xác thực JWT và kiểm tra nhóm Admins 2. Xác minh sách tồn tại và trạng thái là PENDING 3. Copy file từ uploads/ sang public/books/ 4. Cập nhật DynamoDB: status=APPROVED, approverID, approvalTimestamp 5. Xóa file gốc từ uploads/ 6. Trả response thành công rejectBook Lambda:\n1. Xác thực JWT và kiểm tra nhóm Admins 2. Cập nhật DynamoDB: status=REJECTED, reason, rejectionTimestamp 3. Tùy chọn: Di chuyển file sang quarantine/ thay vì xóa 4. Gửi thông báo cho uploader (cải tiến tương lai) Giao diện Admin Frontend Danh sách sách Pending:\nHiển thị: thumbnail, tiêu đề, tác giả, uploader, ngày upload Hành động: Xem trước (download tạm), Duyệt, Từ chối Bộ lọc: theo ngày, theo uploader, theo loại file Phân trang cho tập dữ liệu lớn Modal duyệt:\nXác nhận hành động với chi tiết sách Tùy chọn: thêm ghi chú duyệt Trạng thái loading trong quá trình xử lý Thông báo thành công/lỗi Modal từ chối:\nBắt buộc chọn/nhập lý do từ chối Lý do định sẵn: bản quyền, không phù hợp, chất lượng, khác Trường message tùy chỉnh Xác nhận trước khi gửi Những hiểu biết quan trọng Bảng điều khiển admin là khu vực có đặc quyền cao - kiểm soát truy cập nghiêm ngặt thiết yếu Audit logging quan trọng cho trách nhiệm giải trình (ai duyệt/từ chối cái gì và khi nào) Soft delete (quarantine) tốt hơn hard delete cho tuân thủ pháp lý Cập nhật trạng thái thời gian thực cải thiện hiệu quả quy trình admin Lý do từ chối rõ ràng giúp uploaders cải thiện submissions tương lai Công việc đã hoàn thành Bảo vệ Route Admin\nTạo wrapper route chỉ dành cho admin kiểm tra Cognito groups Triển khai xử lý truy cập không được phép (chuyển hướng đến dashboard) Thêm menu điều hướng admin (chỉ hiển thị cho admins) Xây dựng trang \u0026ldquo;Access Denied\u0026rdquo; cho non-admin users Giao diện sách Pending\nTạo component danh sách sách pending với DataTable Triển khai modal xem trước sách (hiển thị metadata và bìa) Thêm bulk selection cho batch operations Xây dựng bộ lọc trạng thái (PENDING, VALIDATING, ALL) Hệ thống duyệt\nTạo modal xác nhận duyệt Triển khai tích hợp API approveBook Thêm cập nhật UI optimistic (thay đổi trạng thái ngay lập tức) Xây dựng toast notifications thành công/lỗi Hệ thống từ chối\nTạo modal từ chối với chọn lý do Xây dựng dropdown lý do từ chối (định sẵn + tùy chỉnh) Triển khai tích hợp API rejectBook Thêm xem lịch sử từ chối cho uploaders Bảng điều khiển Admin\nTạo tổng quan dashboard với thẻ thống kê Xây dựng biểu đồ: uploads theo thời gian, tỷ lệ duyệt, phân phối trạng thái Triển khai feed hoạt động gần đây Thêm nút hành động nhanh (badge số lượng pending) Hiển thị Audit Logging\nTạo audit log viewer hiển thị tất cả hành động Triển khai lọc theo loại hành động, khoảng ngày, admin Thêm chức năng xuất audit logs sang CSV Xây dựng xem chi tiết hành động với metadata Thách thức \u0026amp; Giải pháp Thách thức: Cập nhật trạng thái thời gian thực mà không polling\nGiải pháp: Triển khai kết nối WebSocket cho admin panel để nhận thay đổi trạng thái tức thì từ backend\nThách thức: Danh sách lớn sách pending gây vấn đề hiệu suất\nGiải pháp: Triển khai virtual scrolling và phân trang server-side với cursor-based navigation\nThách thức: Duyệt/từ chối nhầm lẫn\nGiải pháp: Thêm modal xác nhận với đếm ngược 2 giây trước khi bật hành động\nThách thức: Hành động admin không phản ánh ngay lập tức\nGiải pháp: Triển khai cập nhật UI optimistic với rollback khi lỗi, plus cache invalidation\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.3-week3/","title":"Tuần 3 - Dịch vụ Compute trên AWS","tags":[],"description":"","content":"Tuần: 2025-09-22 đến 2025-09-26\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 3 Tuần này tập trung vào các dịch vụ Compute của AWS, đặc biệt là Amazon EC2 và những dịch vụ bổ trợ.\nNội dung chính Amazon EC2 và các loại instance. AMI và chiến lược sao lưu. EBS và Instance Store. EC2 Auto Scaling. Lựa chọn mô hình giá cho EC2. Amazon Lightsail, EFS, FSx. Labs thực hành Lab 01: AWS Account \u0026amp; IAM Setup. Lab 07: AWS Budgets \u0026amp; Cost Management. Lab 09: AWS Support Plans. "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":"Trong suốt thời gian thực tập, em đã tham gia hai sự kiện AWS quan trọng giúp mở rộng kiến thức về cloud và AI, đồng thời tạo nhiều cơ hội kết nối chuyên môn.\nEvent 1: Vietnam Cloud Day 2025 Thời gian: 18 tháng 9, 2025 lúc 9:00 sáng\nĐịa điểm: Văn phòng AWS Vietnam (Tầng 36, 2 Hai Triều, Q1, TPHCM)\nVai trò: Người tham dự\nTóm tắt: Hội nghị AWS cả ngày với lãnh đạo chính phủ, điều hành AWS và các nhà đổi mới ngành. Gồm hai luồng chính: keynotes trực tiếp về chuyển đổi GenAI và lãnh đạo cấp cao, cùng các phiên thực hành về nền tảng AI/dữ liệu, lộ trình GenAI, bảo mật và chiến lược hiện đại hóa cloud.\nKết quả: Thu được hiểu biết cấp doanh nghiệp về chiến lược áp dụng AI, học các dịch vụ AWS cho hạ tầng dữ liệu và triển khai GenAI, nắm vững framework bảo mật cho ứng dụng AI và hiện đại hóa hệ thống legacy.\nEvent 2: AWS GenAI Builder Club Thời gian: 3 tháng 10, 2025 lúc 2:00 chiều\nĐịa điểm: AWS Event Hall (L26 Tòa Bitexco, TPHCM)\nVai trò: Người tham dự\nTóm tắt: Workshop kỹ thuật về AI-Driven Development Lifecycle (AI-DLC) với demo trực tiếp Amazon Q Developer và Kiro IDE. Khám phá cách AI tạo sinh biến đổi kỹ thuật phần mềm từ kiến trúc đến triển khai, nhấn mạnh AI như đối tác hợp tác thay vì chỉ là trợ lý code.\nKết quả: Học được tích hợp AI thực tế trong quy trình phát triển, có kinh nghiệm thực hành với Amazon Q Developer và Kiro, hiểu cách tận dụng AI cho năng suất đồng thời duy trì chất lượng code và giám sát của developer.\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.6-week6/1.6.4-day29-2025-10-16/","title":"Day 29 - Amazon ElastiCache","tags":[],"description":"","content":" ⚠️ Bản dịch tiếng Việt đang được cập nhật. Vui lòng xem nội dung chi tiết trong file _index.md (tiếng Anh).\nNội dung tiếng Việt sẽ được bổ sung sớm để phản ánh đầy đủ các ghi chú và bài lab.\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.7-week7/1.7.4-day34-2025-10-23/","title":"Day 34 - FastAPI Clean Architecture","tags":[],"description":"","content":" ⚠️ Bản dịch tiếng Việt đang được cập nhật. Vui lòng xem nội dung chi tiết trong file _index.md (tiếng Anh).\nNội dung tiếng Việt sẽ được bổ sung sớm để phản ánh đầy đủ các ghi chú và bài lab.\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/5-workshop/5.4-module4/","title":"Đăng nhập &amp; Quản lý phiên","tags":[],"description":"","content":"Xây dựng component đăng nhập Tạo file src/components/Login.js:\nimport { Auth } from \u0026#39;aws-amplify\u0026#39;; import { useState } from \u0026#39;react\u0026#39;; function Login() { const [email, setEmail] = useState(\u0026#39;\u0026#39;); const [password, setPassword] = useState(\u0026#39;\u0026#39;); const [user, setUser] = useState(null); const handleLogin = async (e) =\u0026gt; { e.preventDefault(); try { const user = await Auth.signIn(email, password); setUser(user); console.log(\u0026#39;Đăng nhập thành công:\u0026#39;, user); } catch (error) { console.error(\u0026#39;Lỗi đăng nhập:\u0026#39;, error); alert(error.message); } }; const handleLogout = async () =\u0026gt; { try { await Auth.signOut(); setUser(null); console.log(\u0026#39;Đăng xuất thành công\u0026#39;); } catch (error) { console.error(\u0026#39;Lỗi đăng xuất:\u0026#39;, error); } }; return ( \u0026lt;div\u0026gt; {!user ? ( \u0026lt;form onSubmit={handleLogin}\u0026gt; \u0026lt;h2\u0026gt;Đăng nhập\u0026lt;/h2\u0026gt; \u0026lt;input type=\u0026#34;email\u0026#34; value={email} onChange={(e) =\u0026gt; setEmail(e.target.value)} placeholder=\u0026#34;Email\u0026#34; required /\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; value={password} onChange={(e) =\u0026gt; setPassword(e.target.value)} placeholder=\u0026#34;Mật khẩu\u0026#34; required /\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;Đăng nhập\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; ) : ( \u0026lt;div\u0026gt; \u0026lt;h2\u0026gt;Chào mừng, {user.attributes.email}\u0026lt;/h2\u0026gt; \u0026lt;button onClick={handleLogout}\u0026gt;Đăng xuất\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; )} \u0026lt;/div\u0026gt; ); } export default Login; Kiểm tra trạng thái xác thực Thêm vào src/App.js:\nimport { Amplify } from \u0026#39;aws-amplify\u0026#39;; import { Auth } from \u0026#39;aws-amplify\u0026#39;; import { useEffect, useState } from \u0026#39;react\u0026#39;; import awsconfig from \u0026#39;./aws-exports\u0026#39;; import Login from \u0026#39;./components/Login\u0026#39;; Amplify.configure(awsconfig); function App() { const [user, setUser] = useState(null); const [loading, setLoading] = useState(true); useEffect(() =\u0026gt; { checkUser(); }, []); const checkUser = async () =\u0026gt; { try { const user = await Auth.currentAuthenticatedUser(); setUser(user); } catch (error) { setUser(null); } setLoading(false); }; if (loading) return \u0026lt;div\u0026gt;Đang tải...\u0026lt;/div\u0026gt;; return ( \u0026lt;div className=\u0026#34;App\u0026#34;\u0026gt; {user ? \u0026lt;h1\u0026gt;Chào mừng trở lại!\u0026lt;/h1\u0026gt; : \u0026lt;Login /\u0026gt;} \u0026lt;/div\u0026gt; ); } export default App; Quản lý phiên Cognito tự động quản lý phiên:\nAccess Token: Có hiệu lực 1 giờ, dùng để ủy quyền API ID Token: Chứa thuộc tính người dùng, hết hạn sau 1 giờ Refresh Token: Có hiệu lực 30 ngày (có thể cấu hình), làm mới access/ID tokens Tự động làm mới phiên Amplify tự động làm mới tokens:\n// Lấy phiên hiện tại const session = await Auth.currentSession(); console.log(\u0026#39;Access token:\u0026#39;, session.getAccessToken().getJwtToken()); // Amplify tự động xử lý làm mới token // Không cần làm mới thủ công Routes được bảo vệ Tạo routes được bảo vệ trong ứng dụng:\nimport { Route, Navigate } from \u0026#39;react-router-dom\u0026#39;; function ProtectedRoute({ children }) { const [user, setUser] = useState(null); const [loading, setLoading] = useState(true); useEffect(() =\u0026gt; { checkAuth(); }, []); const checkAuth = async () =\u0026gt; { try { await Auth.currentAuthenticatedUser(); setUser(true); } catch { setUser(false); } setLoading(false); }; if (loading) return \u0026lt;div\u0026gt;Đang tải...\u0026lt;/div\u0026gt;; return user ? children : \u0026lt;Navigate to=\u0026#34;/login\u0026#34; /\u0026gt;; } export default ProtectedRoute; "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.1-week1/1.1.4-day04-2025-09-11/","title":"Ngày 04 - Tối ưu Chi phí trên AWS","tags":[],"description":"","content":"Ngày: 2025-09-11\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Tối ưu chi phí trên AWS Chiến lược tối ưu chi phí Chọn đúng loại tài nguyên và Region phù hợp. Sử dụng các mô hình giá như Reserved Instances, Savings Plans, Spot Instances. Tắt hoặc lên lịch các tài nguyên không dùng. Tận dụng kiến trúc serverless để giảm chi phí vận hành. Liên tục rà soát hiệu quả chi phí bằng AWS Budgets và Cost Explorer. Gắn thẻ chi phí (Cost Allocation Tags) để theo dõi theo phòng ban. AWS Pricing Calculator calculator.aws\nTạo và chia sẻ ước tính chi phí cho các dịch vụ phổ biến. Giá thay đổi tùy Region. Tính năng chính:\nƯớc tính chi phí trước khi triển khai. So sánh giá giữa các Region. Xuất và chia sẻ bảng dự toán. Có sẵn template cho từng workload. Gói hỗ trợ AWS Support Plans Bốn cấp độ: Basic, Developer, Business, Enterprise. Có thể nâng cấp tạm thời khi gặp sự cố nghiêm trọng. So sánh các gói hỗ trợ Tính năng Basic Developer Business Enterprise Chi phí Miễn phí 29 USD/tháng 100 USD/tháng 15.000 USD/tháng Thời gian phản hồi Không áp dụng 12-24 giờ 1 giờ (khẩn) 15 phút (nghiêm trọng) Hỗ trợ kỹ thuật Diễn đàn Giờ hành chính 24/7 24/7 + TAM Hands-On Labs Lab 07 – AWS Budgets \u0026amp; Cost Management Tạo Budget từ template → 07-01 Hướng dẫn tạo Cost Budget → 07-02 Tạo Usage Budget → 07-03 Tạo Budget cho Reserved Instance (RI) → 07-04 Tạo Budget cho Savings Plans → 07-05 Dọn dẹp các Budget → 07-06 Lab 09 – AWS Support Plans Các gói hỗ trợ AWS → 09-01 Phân loại yêu cầu hỗ trợ → 09-02 Thay đổi gói hỗ trợ → 09-03 Quản lý ticket hỗ trợ → 09-04 "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.2-week2/1.2.4-day09-2025-09-18/","title":"Ngày 09 - Kết nối VPC &amp; Cân bằng tải","tags":[],"description":"","content":"Ngày: 2025-09-18\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học VPC Peering \u0026amp; Transit Gateway VPC Peering Cho phép kết nối riêng tư trực tiếp giữa hai VPC mà không qua Internet. Không hỗ trợ định tuyến chuyển tiếp (transitive) và không chấp nhận CIDR trùng nhau. Hạn chế của VPC Peering:\nKhông có peering chuyển tiếp. Không được phép trùng CIDR. Mỗi VPC tối đa 125 kết nối peering. Hỗ trợ peering liên vùng (cross-region). AWS Transit Gateway (TGW) Hoạt động như một hub kết nối nhiều VPC và mạng on-premises, đơn giản hóa kiến trúc mesh phức tạp. TGW Attachment gắn các subnet thuộc một AZ cụ thể vào TGW. Các subnet trong cùng AZ có thể truy cập TGW sau khi được attach. Lợi ích của Transit Gateway:\nHub kết nối tập trung. Đơn giản hóa kiến trúc mạng. Mở rộng tới hàng nghìn VPC. Hỗ trợ peering giữa các region. VPN \u0026amp; Direct Connect Site-to-Site VPN Thiết lập kết nối IPSec bảo mật giữa data center on-premises và AWS VPC. Bao gồm: Virtual Private Gateway (VGW): endpoint đa AZ do AWS quản lý. Customer Gateway (CGW): thiết bị hoặc appliance do khách hàng quản lý. AWS Direct Connect Cung cấp đường truyền riêng giữa data center on-prem và AWS. Độ trễ điển hình: 20–30 ms. Tại Việt Nam hiện có thông qua Hosted Connection (đối tác). Có thể điều chỉnh băng thông linh hoạt. Hands-On Labs Lab 10 – Hybrid DNS (Route 53 Resolver) Tạo Key Pair → 10-02.1 Khởi tạo CloudFormation Template → 10-02.2 Cấu hình Security Group → 10-02.3 Thiết lập hệ thống DNS → 10-05 Tạo Route 53 Outbound Endpoint → 10-05.1 Tạo Resolver Rules → 10-05.2 Tạo Inbound Endpoints → 10-05.3 Lab 19 – VPC Peering Khởi tạo CloudFormation Templates → 19-02.1 Tạo Security Group → 19-02.2 Tạo EC2 instance (test peering) → 19-02.3 Tạo kết nối Peering → 19-04 Cấu hình Route Table (Cross-VPC) → 19-05 Bật Cross-Peer DNS → 19-06 "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.3-week3/1.3.4-day14-2025-09-25/","title":"Ngày 14 - EC2 Auto Scaling","tags":[],"description":"","content":"Ngày: 2025-09-25\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Amazon EC2 Auto Scaling EC2 Auto Scaling tự động điều chỉnh số lượng instance EC2 dựa trên nhu cầu. Lợi ích\nCo giãn năng lực linh hoạt. Tăng tính sẵn sàng cho ứng dụng. Tối ưu chi phí. Thành phần chính\nAuto Scaling Group (ASG): nhóm logic chứa các EC2 instance. Launch Template / Configuration: định nghĩa thông số instance. Scaling Policy: quy tắc thêm/bớt instance. Scaling Policy Simple / Step Scaling: thêm/bớt instance khi vượt ngưỡng. Target Tracking: duy trì một metric (ví dụ CPU = 50%). Scheduled Scaling: scale theo lịch định sẵn. Predictive Scaling: dùng ML dự đoán và scale chủ động. Ví dụ Target Tracking:\n{ \u0026#34;TargetTrackingScalingPolicyConfiguration\u0026#34;: { \u0026#34;PredefinedMetricSpecification\u0026#34;: { \u0026#34;PredefinedMetricType\u0026#34;: \u0026#34;ASGAverageCPUUtilization\u0026#34; }, \u0026#34;TargetValue\u0026#34;: 50.0 } } Tích hợp với Load Balancer ASG thường đi kèm Elastic Load Balancer (ELB). Instance mới sẽ tự đăng ký, instance bị hủy sẽ tự hủy đăng ký. Best practices cho Auto Scaling:\nDùng nhiều AZ để tăng độ sẵn sàng. Thiết lập cooldown hợp lý. Giám sát metric trên CloudWatch. Sử dụng lifecycle hook cho tác vụ tùy chỉnh. Kiểm thử policy trước khi đưa vào production. Các mô hình giá của EC2 On-Demand: Trả theo giờ/giây. Linh hoạt nhất nhưng chi phí cao. Reserved Instances: Cam kết 1 hoặc 3 năm để được giảm giá; gắn với loại/family cụ thể. Savings Plans: Cam kết 1 hoặc 3 năm; linh hoạt hơn giữa các family. Spot Instances: Dùng công suất dư thừa, giảm tới 90%; có thể bị thu hồi sau 2 phút báo trước. Nên kết hợp nhiều mô hình giá trong Auto Scaling Group để tối ưu chi phí.\nSo sánh giá:\nMô hình Giảm giá Linh hoạt Cam kết On-Demand 0% Cao Không Reserved 40-60% Thấp 1-3 năm Savings Plans 40-60% Trung bình 1-3 năm Spot 50-90% Thấp Không Hands-On Labs Lab 09 – AWS Support Plans Các gói hỗ trợ AWS → 09-01 Phân loại yêu cầu hỗ trợ → 09-02 Thay đổi gói hỗ trợ → 09-03 Quản lý ticket hỗ trợ → 09-04 "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.4-week4/1.4.4-day19-2025-10-02/","title":"Ngày 19 - Disaster Recovery trên AWS","tags":[],"description":"","content":"Ngày: 2025-10-02\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Disaster Recovery (DR) trên AWS Disaster Recovery là quá trình khôi phục dịch vụ CNTT sau sự cố lớn (mất điện, thiên tai, phần cứng hỏng, tấn công mạng).\nRTO (Recovery Time Objective): Thời gian cần để khôi phục dịch vụ. RPO (Recovery Point Objective): Mức dữ liệu tối đa có thể mất (theo thời gian). Chiến lược DR (tăng dần theo độ phức tạp \u0026amp; chi phí) Backup \u0026amp; Restore\nChỉ lưu backup (snapshot EBS/RDS, S3/Glacier). Khôi phục hạ tầng mới khi gặp sự cố. RTO: vài giờ tới vài ngày. RPO: phụ thuộc tần suất backup. Chi phí: thấp nhất. Pilot Light\nDuy trì các dịch vụ lõi ở trạng thái thu nhỏ trên AWS. Scale lên toàn bộ sản xuất khi DR. RTO: hàng giờ. RPO: vài phút. Chi phí: trung bình. Warm Standby\nHệ thống hoàn chỉnh chạy ở quy mô giảm trên AWS. Scale lên khi failover. RTO: phút – giờ. RPO: giây – phút. Chi phí: cao hơn. Multi-Site (Active/Active hoặc Active/Passive)\nMôi trường production chạy song song giữa on-prem và AWS, hoặc giữa nhiều Region AWS. Có thể chuyển hướng traffic ngay lập tức (Route 53, Global Accelerator). RTO/RPO: gần như bằng 0. Chi phí: cao nhất. So sánh chiến lược DR:\nChiến lược RTO RPO Chi phí Độ phức tạp Backup \u0026amp; Restore Giờ – Ngày Giờ $ Thấp Pilot Light Giờ Phút $$ Trung bình Warm Standby Phút Giây $$$ Trung bình-Cao Multi-Site Giây Gần 0 $$$$ Cao Best Practices cho DR Lập kế hoạch Xác định yêu cầu RTO và RPO. Tài liệu hóa quy trình khôi phục. Nhận diện hệ thống và phụ thuộc quan trọng. Thiết lập kế hoạch truyền thông. Triển khai Tự động hóa quy trình khôi phục. Sử dụng nhiều AZ và Region. Triển khai cơ chế sao chép dữ liệu. Kiểm thử backup định kỳ. Kiểm thử Thực hiện diễn tập DR thường xuyên. Thử nghiệm quy trình khôi phục. Đo lường RTO/RPO thực tế. Cập nhật tài liệu. Hands-On Labs Lab 14 – AWS VM Import/Export (Phần 2) Import máy ảo lên AWS → 14-02.3 Deploy instance từ AMI → 14-02.4 Thiết lập ACL cho S3 Bucket → 14-03.1 Export máy ảo từ instance → 14-03.2 Dọn dẹp tài nguyên trên AWS → 14-05 "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.5-week5/1.5.4-day24-2025-10-09/","title":"Ngày 24 - SCPs, Identity Center &amp; KMS","tags":[],"description":"","content":"Ngày: 2025-10-09\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Service Control Policy (SCP) Xác định quyền tối đa cho tài khoản; chỉ giới hạn chứ không cấp quyền. Áp dụng cho tài khoản hoặc OU; ảnh hưởng tất cả user/role, kể cả root; Deny ghi đè Allow. Ví dụ SCP (cấm xóa bucket):\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;s3:DeleteBucket\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Tình huống dùng SCP:\nNgăn tài khoản rời khỏi organization. Giới hạn region được phép tạo tài nguyên. Ép buộc yêu cầu mã hóa. Ngăn tắt các dịch vụ bảo mật. Bắt buộc gắn tag nhất định cho tài nguyên. Best practice:\nBắt đầu với least privilege. Thử nghiệm ở môi trường non-prod trước. Dùng explicit deny cho kiểm soát quan trọng. Ghi chú mục đích từng SCP. Rà soát và cập nhật định kỳ. AWS Identity Center (trước là AWS SSO) Tập trung hóa truy cập vào tài khoản AWS và ứng dụng bên ngoài. Nguồn danh tính: built-in, AWS Managed Microsoft AD, AD on-prem (trust/AD Connector), hoặc IdP ngoài. Permission Set định nghĩa quyền cho user/group trên tài khoản đích (Identity Center tạo IAM role tương ứng). Có thể cấp nhiều permission set cho một người dùng. Tính năng Identity Center:\nSingle sign-on cho nhiều tài khoản AWS. Tích hợp Microsoft Active Directory. Hỗ trợ SAML 2.0. MFA. Quản lý permission tập trung. Ghi log audit qua CloudTrail. AWS Key Management Service (KMS) Dịch vụ quản lý khóa bảo vệ dữ liệu, tích hợp sâu với các dịch vụ AWS và hỗ trợ audit đầy đủ. Điểm nổi bật\nTạo/quản lý khóa mà không cần tự vận hành HSM. Kiểm soát truy cập chi tiết với IAM \u0026amp; key policy; mọi thao tác được log trong CloudTrail. Các nhóm khóa\nKhóa do khách hàng quản lý (CMK), khóa do AWS quản lý và khóa thuộc AWS-owned. Loại khóa KMS:\nSymmetric: Một khóa duy nhất để mã hóa/giải mã (AES-256). Asymmetric: Cặp khóa public/private (RSA, ECC). Tính năng KMS:\nTự động xoay vòng khóa. Key policy và grant. Envelope encryption. Tích hợp với dịch vụ AWS. Log CloudTrail. Khóa multi-region. Hands-On Labs Lab 33 – AWS KMS \u0026amp; CloudTrail Integration (Phần 1) Tạo Policy và Role → 33-2.1 Tạo Group và User → 33-2.2 Tạo KMS Key → 33-3 Tạo S3 Bucket → 33-4.1 Upload dữ liệu lên S3 → 33-4.2 Lab 30 – IAM Restriction Policy Tạo Restriction Policy → 30-3 Tạo IAM Limited User → 30-4 Kiểm tra giới hạn của IAM User → 30-5 Dọn dẹp tài nguyên → 30-6 "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.8-week8/1.8.4-day39-2025-10-30/","title":"Ngày 39 - Nhận dạng thực thể được đặt tên (NER)","tags":[],"description":"","content":"Ngày: 2025-10-30 Trạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú bài giảng Nhận dạng thực thể được đặt tên (NER) NER là gì? Xác định và phân loại các thực thể được đặt tên trong văn bản. Thực thể: con người, tổ chức, địa điểm, ngày tháng, sản phẩm, v.v. Quan trọng cho trích xuất thông tin và đồ thị tri thức. Nền tảng cho hệ thống trả lời câu hỏi và tìm kiếm. Các loại thực thể phổ biến PERSON: Tên người ORG: Tổ chức, công ty, tổ chức GPE: Thực thể địa chính trị (quốc gia, thành phố, bang) DATE: Biểu thức ngày và thời gian MONEY: Giá trị tiền tệ LOCATION: Địa điểm không phải GPE (núi, sông) PRODUCT: Sản phẩm và đối tượng Các cách tiếp cận NER Dựa trên quy tắc: Khớp mẫu và từ điển Machine Learning: Mô hình thống kê (CRF, HMM) Deep Learning: Mạng nơ-ron (BiLSTM-CRF, Transformers) Mô hình đã huấn luyện trước: spaCy, mô hình dựa trên BERT spaCy cho NER Tại sao chọn spaCy? Nhanh và sẵn sàng cho production Mô hình đã huấn luyện trước cho nhiều ngôn ngữ API dễ sử dụng Hỗ trợ huấn luyện thực thể tùy chỉnh Thư viện NLP chuẩn công nghiệp Quy trình spaCy Văn bản → Tokenizer → Tagger → Parser → NER → Đầu ra Mỗi thành phần xử lý và thêm chú thích Có thể tùy chỉnh hoặc vô hiệu hóa các thành phần để tăng hiệu suất Những hiểu biết quan trọng NER chuyển đổi văn bản không có cấu trúc thành dữ liệu có cấu trúc Độ chính xác thay đổi theo lĩnh vực - NER tài chính khác NER y tế Mô hình đã huấn luyện trước hoạt động tốt cho các thực thể phổ biến Cần huấn luyện tùy chỉnh cho thực thể đặc thù lĩnh vực Luôn xác thực kết quả NER, đặc biệt cho ứng dụng quan trọng Thực hành Lab Lab 1: NER cơ bản với spaCy import spacy # Tải mô hình đã huấn luyện trước nlp = spacy.load(\u0026#34;en_core_web_sm\u0026#34;) text = \u0026#34;\u0026#34;\u0026#34; Apple Inc. was founded by Steve Jobs in Cupertino, California. The company released the iPhone on January 9, 2007. Tim Cook became CEO in August 2011, succeeding Steve Jobs. \u0026#34;\u0026#34;\u0026#34; # Xử lý văn bản doc = nlp(text) # Trích xuất thực thể print(\u0026#34;Các thực thể tìm thấy:\u0026#34;) for ent in doc.ents: print(f\u0026#34;{ent.text:20} - {ent.label_:15} - {spacy.explain(ent.label_)}\u0026#34;) Lab 2: Trực quan hóa thực thể from spacy import displacy text = \u0026#34;\u0026#34;\u0026#34; Amazon, có trụ sở tại Seattle, Washington, được thành lập bởi Jeff Bezos vào năm 1994. Công ty bắt đầu như một cửa hàng sách trực tuyến và đã phát triển thành một trong những công ty công nghệ lớn nhất thế giới. Năm 2021, Andy Jassy trở thành CEO. \u0026#34;\u0026#34;\u0026#34; doc = nlp(text) # Trực quan hóa thực thể trong Jupyter hoặc lưu thành HTML displacy.render(doc, style=\u0026#34;ent\u0026#34;, jupyter=False) # Để lưu vào file: # html = displacy.render(doc, style=\u0026#34;ent\u0026#34;) # with open(\u0026#34;entities.html\u0026#34;, \u0026#34;w\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: # f.write(html) Lab 3: Trích xuất và phân tích thực thể from collections import Counter def extract_entities_by_type(text, entity_type): doc = nlp(text) entities = [ent.text for ent in doc.ents if ent.label_ == entity_type] return entities def analyze_entities(text): doc = nlp(text) # Đếm thực thể theo loại entity_counts = Counter([ent.label_ for ent in doc.ents]) # Nhóm thực thể theo loại entities_by_type = {} for ent in doc.ents: if ent.label_ not in entities_by_type: entities_by_type[ent.label_] = [] entities_by_type[ent.label_].append(ent.text) return entity_counts, entities_by_type news_text = \u0026#34;\u0026#34;\u0026#34; Microsoft thông báo hôm thứ Hai rằng họ sẽ mua GitHub với giá 7,5 tỷ đô la. Giao dịch được hoàn thành vào tháng 10 năm 2018. Satya Nadella, CEO của Microsoft, ca ngợi cộng đồng nhà phát triển của GitHub. GitHub, có trụ sở tại San Francisco, được thành lập năm 2008 bởi Tom Preston-Werner, Chris Wanstrath và PJ Hyett. \u0026#34;\u0026#34;\u0026#34; counts, entities = analyze_entities(news_text) print(\u0026#34;Số lượng thực thể:\u0026#34;) for entity_type, count in counts.items(): print(f\u0026#34;{entity_type}: {count}\u0026#34;) print(\u0026#34;\\nThực thể theo loại:\u0026#34;) for entity_type, entity_list in entities.items(): print(f\u0026#34;\\n{entity_type}:\u0026#34;) for entity in set(entity_list): print(f\u0026#34; - {entity}\u0026#34;) Lab 4: Trích xuất thực thể tùy chỉnh def extract_all_people(text): \u0026#34;\u0026#34;\u0026#34;Trích xuất tất cả tên người từ văn bản\u0026#34;\u0026#34;\u0026#34; doc = nlp(text) people = [ent.text for ent in doc.ents if ent.label_ == \u0026#34;PERSON\u0026#34;] return list(set(people)) # Loại bỏ trùng lặp def extract_all_organizations(text): \u0026#34;\u0026#34;\u0026#34;Trích xuất tất cả tên tổ chức từ văn bản\u0026#34;\u0026#34;\u0026#34; doc = nlp(text) orgs = [ent.text for ent in doc.ents if ent.label_ == \u0026#34;ORG\u0026#34;] return list(set(orgs)) def extract_all_locations(text): \u0026#34;\u0026#34;\u0026#34;Trích xuất tất cả địa điểm từ văn bản\u0026#34;\u0026#34;\u0026#34; doc = nlp(text) locations = [ent.text for ent in doc.ents if ent.label_ in [\u0026#34;GPE\u0026#34;, \u0026#34;LOC\u0026#34;]] return list(set(locations)) article = \u0026#34;\u0026#34;\u0026#34; Công ty Tesla của Elon Musk đang xây dựng một nhà máy mới ở Austin, Texas. Nhà máy sẽ sản xuất Cybertruck và sẽ tuyển dụng hàng nghìn công nhân. SpaceX, một công ty khác được Musk thành lập, có trụ sở tại Hawthorne, California. Musk gần đây đã chuyển từ California sang Texas, nêu ra điều kiện kinh doanh tốt hơn. \u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Người:\u0026#34;, extract_all_people(article)) print(\u0026#34;Tổ chức:\u0026#34;, extract_all_organizations(article)) print(\u0026#34;Địa điểm:\u0026#34;, extract_all_locations(article)) Lab 5: NER cho trích xuất thông tin def extract_structured_info(text): \u0026#34;\u0026#34;\u0026#34;Trích xuất thông tin có cấu trúc từ văn bản\u0026#34;\u0026#34;\u0026#34; doc = nlp(text) info = { \u0026#39;người\u0026#39;: [], \u0026#39;tổ_chức\u0026#39;: [], \u0026#39;địa_điểm\u0026#39;: [], \u0026#39;ngày_tháng\u0026#39;: [], \u0026#39;tiền\u0026#39;: [] } for ent in doc.ents: if ent.label_ == \u0026#34;PERSON\u0026#34;: info[\u0026#39;người\u0026#39;].append(ent.text) elif ent.label_ == \u0026#34;ORG\u0026#34;: info[\u0026#39;tổ_chức\u0026#39;].append(ent.text) elif ent.label_ in [\u0026#34;GPE\u0026#34;, \u0026#34;LOC\u0026#34;]: info[\u0026#39;địa_điểm\u0026#39;].append(ent.text) elif ent.label_ == \u0026#34;DATE\u0026#34;: info[\u0026#39;ngày_tháng\u0026#39;].append(ent.text) elif ent.label_ == \u0026#34;MONEY\u0026#34;: info[\u0026#39;tiền\u0026#39;].append(ent.text) # Loại bỏ trùng lặp for key in info: info[key] = list(set(info[key])) return info business_news = \u0026#34;\u0026#34;\u0026#34; Google thông báo vào ngày 15 tháng 3 năm 2023 rằng Sundar Pichai sẽ tiếp tục làm CEO. Công ty, có trụ sở tại Mountain View, California, báo cáo doanh thu 280 tỷ đô la cho năm tài chính. Công ty mẹ của Google, Alphabet Inc., cũng sở hữu YouTube và có văn phòng tại New York, London và Tokyo. \u0026#34;\u0026#34;\u0026#34; structured_data = extract_structured_info(business_news) print(\u0026#34;Thông tin đã trích xuất:\u0026#34;) for key, values in structured_data.items(): print(f\u0026#34;\\n{key.capitalize()}:\u0026#34;) for value in values: print(f\u0026#34; - {value}\u0026#34;) Bài tập thực hành Trích xuất thực thể từ bài báo và phân loại chúng Xây dựng đồ thị tri thức từ các thực thể đã trích xuất và mối quan hệ của chúng So sánh kết quả NER từ các mô hình spaCy khác nhau (nhỏ vs lớn) Tạo hàm trích xuất mối quan hệ công ty-giám đốc điều hành Phân tích các mẫu đồng xuất hiện thực thể trong tài liệu "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.9-week9/1.9.4-day44-2025-11-06/","title":"Ngày 44 - NER nâng cao &amp; Huấn luyện thực thể tùy chỉnh","tags":[],"description":"","content":"Ngày: 2025-11-06\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú bài giảng Ôn tập NER Các khái niệm chính từ Tuần 8 Named Entity Recognition xác định và phân loại thực thể trong văn bản Các loại phổ biến: PERSON, ORG, GPE, DATE, MONEY, LOCATION Các cách tiếp cận: dựa trên quy tắc, machine learning, deep learning, mô hình đã huấn luyện trước spaCy cung cấp khả năng NER sẵn sàng production Vượt xa NER cơ bản Loại thực thể tùy chỉnh\nThực thể đặc thù lĩnh vực (mã sản phẩm, thuật ngữ y tế, tham chiếu pháp lý) Huấn luyện mô hình tùy chỉnh cho các lĩnh vực chuyên môn Mở rộng mô hình đã huấn luyện trước với các loại thực thể mới Trích xuất quan hệ\nXác định mối quan hệ giữa các thực thể Ví dụ: \u0026ldquo;Steve Jobs founded Apple\u0026rdquo; → (Steve Jobs, founded, Apple) Xây dựng đồ thị tri thức từ văn bản Huấn luyện NER tùy chỉnh Yêu cầu dữ liệu huấn luyện Định dạng chú thích\nTRAIN_DATA = [ (\u0026#34;Apple is looking at buying UK startup\u0026#34;, { \u0026#34;entities\u0026#34;: [(0, 5, \u0026#34;ORG\u0026#34;), (27, 29, \u0026#34;GPE\u0026#34;)] }) ] Hướng dẫn chất lượng\nChú thích nhất quán trên tập dữ liệu Đủ ví dụ cho mỗi loại thực thể (khuyến nghị 100+) Phân phối cân bằng của các loại thực thể Bao gồm ví dụ tiêu cực (văn bản không có thực thể) Quy trình huấn luyện Các bước:\nChuẩn bị dữ liệu huấn luyện đã chú thích Khởi tạo hoặc tải mô hình cơ sở Thêm loại thực thể tùy chỉnh nếu cần Huấn luyện mô hình với nhiều lần lặp Đánh giá trên tập test riêng biệt Tinh chỉnh siêu tham số Thực hành tốt nhất:\nSử dụng transfer learning từ mô hình đã huấn luyện trước Bắt đầu với tốc độ học nhỏ Giám sát overfitting Lưu checkpoints trong quá trình huấn luyện Kỹ thuật nâng cao Entity Linking Kết nối thực thể đã trích xuất với cơ sở tri thức (Wikipedia, Wikidata) Phân biệt thực thể có cùng tên Làm giàu thông tin thực thể với dữ liệu bên ngoài Nhận dạng thực thể theo ngữ cảnh Sử dụng ngữ cảnh xung quanh để có độ chính xác tốt hơn Xử lý các đề cập thực thể mơ hồ Xem xét thông tin cấp độ tài liệu Những hiểu biết quan trọng NER tùy chỉnh thiết yếu cho ứng dụng đặc thù lĩnh vực Chất lượng dữ liệu huấn luyện ảnh hưởng trực tiếp đến hiệu suất mô hình Mô hình đã huấn luyện trước cung cấp điểm khởi đầu tuyệt vời Đánh giá và huấn luyện lại liên tục duy trì độ chính xác Thực hành Lab Lab 1: Tạo dữ liệu huấn luyện tùy chỉnh import spacy from spacy.training import Example # Định nghĩa dữ liệu huấn luyện tùy chỉnh TRAIN_DATA = [ (\u0026#34;Apple iPhone 15 Pro giá $999\u0026#34;, { \u0026#34;entities\u0026#34;: [(0, 5, \u0026#34;CÔNG_TY\u0026#34;), (6, 19, \u0026#34;SẢN_PHẨM\u0026#34;), (24, 28, \u0026#34;TIỀN\u0026#34;)] }), (\u0026#34;Samsung Galaxy S24 có giá $899\u0026#34;, { \u0026#34;entities\u0026#34;: [(0, 7, \u0026#34;CÔNG_TY\u0026#34;), (8, 18, \u0026#34;SẢN_PHẨM\u0026#34;), (27, 31, \u0026#34;TIỀN\u0026#34;)] }), (\u0026#34;Google Pixel 8 có sẵn với giá $699\u0026#34;, { \u0026#34;entities\u0026#34;: [(0, 6, \u0026#34;CÔNG_TY\u0026#34;), (7, 14, \u0026#34;SẢN_PHẨM\u0026#34;), (31, 35, \u0026#34;TIỀN\u0026#34;)] }), (\u0026#34;Microsoft Surface Laptop bắt đầu từ $1299\u0026#34;, { \u0026#34;entities\u0026#34;: [(0, 9, \u0026#34;CÔNG_TY\u0026#34;), (10, 24, \u0026#34;SẢN_PHẨM\u0026#34;), (36, 41, \u0026#34;TIỀN\u0026#34;)] }), (\u0026#34;Tesla Model 3 giá cơ bản là $40000\u0026#34;, { \u0026#34;entities\u0026#34;: [(0, 5, \u0026#34;CÔNG_TY\u0026#34;), (6, 13, \u0026#34;SẢN_PHẨM\u0026#34;), (28, 34, \u0026#34;TIỀN\u0026#34;)] }) ] def create_training_examples(nlp, train_data): \u0026#34;\u0026#34;\u0026#34;Chuyển đổi dữ liệu huấn luyện sang định dạng spaCy Example\u0026#34;\u0026#34;\u0026#34; examples = [] for text, annotations in train_data: doc = nlp.make_doc(text) example = Example.from_dict(doc, annotations) examples.append(example) return examples # Tải mô hình trống nlp = spacy.blank(\u0026#34;en\u0026#34;) # Tạo examples examples = create_training_examples(nlp, TRAIN_DATA) print(f\u0026#34;Đã tạo {len(examples)} ví dụ huấn luyện\u0026#34;) for i, example in enumerate(examples[:3]): print(f\u0026#34;\\nVí dụ {i+1}:\u0026#34;) print(f\u0026#34;Văn bản: {example.text}\u0026#34;) print(f\u0026#34;Thực thể: {[(ent.text, ent.label_) for ent in example.reference.ents]}\u0026#34;) Lab 2: Huấn luyện mô hình NER tùy chỉnh import random from spacy.training import Example from spacy.util import minibatch, compounding def train_ner_model(nlp, train_data, n_iter=30): \u0026#34;\u0026#34;\u0026#34;Huấn luyện mô hình NER tùy chỉnh\u0026#34;\u0026#34;\u0026#34; # Thêm pipeline NER nếu chưa tồn tại if \u0026#34;ner\u0026#34; not in nlp.pipe_names: ner = nlp.add_pipe(\u0026#34;ner\u0026#34;) else: ner = nlp.get_pipe(\u0026#34;ner\u0026#34;) # Thêm nhãn for _, annotations in train_data: for ent in annotations.get(\u0026#34;entities\u0026#34;): ner.add_label(ent[2]) # Vô hiệu hóa các pipeline khác trong quá trình huấn luyện other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \u0026#34;ner\u0026#34;] with nlp.disable_pipes(*other_pipes): # Khởi tạo optimizer optimizer = nlp.begin_training() # Vòng lặp huấn luyện for iteration in range(n_iter): random.shuffle(train_data) losses = {} # Tạo batches batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.001)) for batch in batches: examples = [] for text, annotations in batch: doc = nlp.make_doc(text) example = Example.from_dict(doc, annotations) examples.append(example) # Cập nhật mô hình nlp.update(examples, drop=0.5, losses=losses) if iteration % 5 == 0: print(f\u0026#34;Lần lặp {iteration}, Loss: {losses[\u0026#39;ner\u0026#39;]:.4f}\u0026#34;) return nlp # Dữ liệu huấn luyện mở rộng EXPANDED_TRAIN_DATA = TRAIN_DATA + [ (\u0026#34;Amazon Echo Dot bán lẻ với giá $49\u0026#34;, { \u0026#34;entities\u0026#34;: [(0, 6, \u0026#34;CÔNG_TY\u0026#34;), (7, 16, \u0026#34;SẢN_PHẨM\u0026#34;), (33, 36, \u0026#34;TIỀN\u0026#34;)] }), (\u0026#34;Sony PlayStation 5 có giá $499\u0026#34;, { \u0026#34;entities\u0026#34;: [(0, 4, \u0026#34;CÔNG_TY\u0026#34;), (5, 18, \u0026#34;SẢN_PHẨM\u0026#34;), (27, 31, \u0026#34;TIỀN\u0026#34;)] }), (\u0026#34;Nintendo Switch OLED giá $349\u0026#34;, { \u0026#34;entities\u0026#34;: [(0, 8, \u0026#34;CÔNG_TY\u0026#34;), (9, 20, \u0026#34;SẢN_PHẨM\u0026#34;), (25, 29, \u0026#34;TIỀN\u0026#34;)] }), ] * 5 # Lặp lại để có nhiều dữ liệu huấn luyện hơn # Huấn luyện mô hình nlp = spacy.blank(\u0026#34;en\u0026#34;) nlp = train_ner_model(nlp, EXPANDED_TRAIN_DATA, n_iter=30) # Kiểm tra mô hình đã huấn luyện test_text = \u0026#34;MacBook Pro mới của Apple có sẵn với giá $1999\u0026#34; doc = nlp(test_text) print(f\u0026#34;\\nVăn bản kiểm tra: {test_text}\u0026#34;) print(\u0026#34;Thực thể đã trích xuất:\u0026#34;) for ent in doc.ents: print(f\u0026#34; {ent.text:20} -\u0026gt; {ent.label_}\u0026#34;) Lab 3: Đánh giá mô hình NER from spacy.scorer import Scorer def evaluate_ner_model(nlp, test_data): \u0026#34;\u0026#34;\u0026#34;Đánh giá hiệu suất mô hình NER\u0026#34;\u0026#34;\u0026#34; scorer = Scorer() examples = [] for text, annotations in test_data: doc = nlp.make_doc(text) example = Example.from_dict(doc, annotations) example.predicted = nlp(text) examples.append(example) # Tính điểm scores = scorer.score(examples) return scores # Dữ liệu test TEST_DATA = [ (\u0026#34;HP Spectre x360 bắt đầu từ $1199\u0026#34;, { \u0026#34;entities\u0026#34;: [(0, 2, \u0026#34;CÔNG_TY\u0026#34;), (3, 15, \u0026#34;SẢN_PHẨM\u0026#34;), (29, 34, \u0026#34;TIỀN\u0026#34;)] }), (\u0026#34;Dell XPS 13 có sẵn với giá $999\u0026#34;, { \u0026#34;entities\u0026#34;: [(0, 4, \u0026#34;CÔNG_TY\u0026#34;), (5, 11, \u0026#34;SẢN_PHẨM\u0026#34;), (28, 32, \u0026#34;TIỀN\u0026#34;)] }), (\u0026#34;Lenovo ThinkPad giá $1299\u0026#34;, { \u0026#34;entities\u0026#34;: [(0, 6, \u0026#34;CÔNG_TY\u0026#34;), (7, 15, \u0026#34;SẢN_PHẨM\u0026#34;), (20, 25, \u0026#34;TIỀN\u0026#34;)] }) ] # Đánh giá scores = evaluate_ner_model(nlp, TEST_DATA) print(\u0026#34;\\nĐánh giá mô hình:\u0026#34;) print(f\u0026#34;Precision: {scores[\u0026#39;ents_p\u0026#39;]:.4f}\u0026#34;) print(f\u0026#34;Recall: {scores[\u0026#39;ents_r\u0026#39;]:.4f}\u0026#34;) print(f\u0026#34;F1-Score: {scores[\u0026#39;ents_f\u0026#39;]:.4f}\u0026#34;) print(f\u0026#34;\\nĐiểm theo loại:\u0026#34;) for label, metrics in scores[\u0026#39;ents_per_type\u0026#39;].items(): print(f\u0026#34; {label}: P={metrics[\u0026#39;p\u0026#39;]:.4f}, R={metrics[\u0026#39;r\u0026#39;]:.4f}, F={metrics[\u0026#39;f\u0026#39;]:.4f}\u0026#34;) Lab 4: Trích xuất quan hệ thực thể class RelationExtractor: \u0026#34;\u0026#34;\u0026#34;Trích xuất mối quan hệ giữa các thực thể\u0026#34;\u0026#34;\u0026#34; def __init__(self, nlp): self.nlp = nlp def extract_relations(self, text): \u0026#34;\u0026#34;\u0026#34;Trích xuất bộ ba chủ ngữ-quan hệ-đối tượng\u0026#34;\u0026#34;\u0026#34; doc = self.nlp(text) relations = [] # Lấy tất cả thực thể entities = list(doc.ents) # Mẫu đơn giản: THỰC_THỂ1 ĐỘNG_TỪ THỰC_THỂ2 for i, ent1 in enumerate(entities): for ent2 in entities[i+1:]: # Tìm tokens giữa các thực thể start = ent1.end end = ent2.start if end \u0026gt; start: between_tokens = doc[start:end] # Tìm động từ verbs = [token.lemma_ for token in between_tokens if token.pos_ == \u0026#34;VERB\u0026#34;] if verbs: relations.append({ \u0026#39;chủ_ngữ\u0026#39;: ent1.text, \u0026#39;loại_chủ_ngữ\u0026#39;: ent1.label_, \u0026#39;quan_hệ\u0026#39;: \u0026#39; \u0026#39;.join(verbs), \u0026#39;đối_tượng\u0026#39;: ent2.text, \u0026#39;loại_đối_tượng\u0026#39;: ent2.label_ }) return relations # Tải mô hình spaCy với phân tích dependency nlp_full = spacy.load(\u0026#34;en_core_web_sm\u0026#34;) extractor = RelationExtractor(nlp_full) # Văn bản kiểm tra texts = [ \u0026#34;Steve Jobs thành lập Apple ở Cupertino\u0026#34;, \u0026#34;Tim Cook trở thành CEO của Apple năm 2011\u0026#34;, \u0026#34;Microsoft mua lại GitHub với giá $7.5 tỷ\u0026#34;, \u0026#34;Elon Musk lãnh đạo Tesla và SpaceX\u0026#34; ] print(\u0026#34;Trích xuất quan hệ:\\n\u0026#34;) for text in texts: print(f\u0026#34;Văn bản: {text}\u0026#34;) relations = extractor.extract_relations(text) for rel in relations: print(f\u0026#34; ({rel[\u0026#39;chủ_ngữ\u0026#39;]} [{rel[\u0026#39;loại_chủ_ngữ\u0026#39;]}]) \u0026#34; f\u0026#34;--[{rel[\u0026#39;quan_hệ\u0026#39;]}]--\u0026gt; \u0026#34; f\u0026#34;({rel[\u0026#39;đối_tượng\u0026#39;]} [{rel[\u0026#39;loại_đối_tượng\u0026#39;]}])\u0026#34;) print() Lab 5: Hệ thống NER Production import json from pathlib import Path class ProductionNERSystem: \u0026#34;\u0026#34;\u0026#34;Hệ thống NER hoàn chỉnh cho sử dụng production\u0026#34;\u0026#34;\u0026#34; def __init__(self, model_path=None): if model_path and Path(model_path).exists(): self.nlp = spacy.load(model_path) else: self.nlp = spacy.load(\u0026#34;en_core_web_sm\u0026#34;) def extract_entities(self, text, return_format=\u0026#39;dict\u0026#39;): \u0026#34;\u0026#34;\u0026#34;Trích xuất thực thể với nhiều định dạng trả về\u0026#34;\u0026#34;\u0026#34; doc = self.nlp(text) if return_format == \u0026#39;dict\u0026#39;: return { \u0026#39;văn_bản\u0026#39;: text, \u0026#39;thực_thể\u0026#39;: [ { \u0026#39;văn_bản\u0026#39;: ent.text, \u0026#39;nhãn\u0026#39;: ent.label_, \u0026#39;bắt_đầu\u0026#39;: ent.start_char, \u0026#39;kết_thúc\u0026#39;: ent.end_char } for ent in doc.ents ] } elif return_format == \u0026#39;json\u0026#39;: result = { \u0026#39;văn_bản\u0026#39;: text, \u0026#39;thực_thể\u0026#39;: [ { \u0026#39;văn_bản\u0026#39;: ent.text, \u0026#39;nhãn\u0026#39;: ent.label_, \u0026#39;bắt_đầu\u0026#39;: ent.start_char, \u0026#39;kết_thúc\u0026#39;: ent.end_char } for ent in doc.ents ] } return json.dumps(result, indent=2, ensure_ascii=False) elif return_format == \u0026#39;list\u0026#39;: return [(ent.text, ent.label_, ent.start_char, ent.end_char) for ent in doc.ents] def batch_extract(self, texts): \u0026#34;\u0026#34;\u0026#34;Xử lý nhiều văn bản một cách hiệu quả\u0026#34;\u0026#34;\u0026#34; results = [] for doc in self.nlp.pipe(texts): entities = [ { \u0026#39;văn_bản\u0026#39;: ent.text, \u0026#39;nhãn\u0026#39;: ent.label_, \u0026#39;bắt_đầu\u0026#39;: ent.start_char, \u0026#39;kết_thúc\u0026#39;: ent.end_char } for ent in doc.ents ] results.append({ \u0026#39;văn_bản\u0026#39;: doc.text, \u0026#39;thực_thể\u0026#39;: entities }) return results def save_results(self, results, output_file): \u0026#34;\u0026#34;\u0026#34;Lưu kết quả trích xuất vào file\u0026#34;\u0026#34;\u0026#34; with open(output_file, \u0026#39;w\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: json.dump(results, f, indent=2, ensure_ascii=False) # Kiểm tra hệ thống production ner_system = ProductionNERSystem() # Trích xuất đơn lẻ text = \u0026#34;CEO Apple Inc. Tim Cook công bố iPhone 15 mới tại sự kiện ở Cupertino, California vào ngày 12 tháng 9 năm 2023.\u0026#34; result = ner_system.extract_entities(text, return_format=\u0026#39;dict\u0026#39;) print(\u0026#34;Trích xuất đơn lẻ:\u0026#34;) print(json.dumps(result, indent=2, ensure_ascii=False)) # Trích xuất hàng loạt texts = [ \u0026#34;CEO Amazon Andy Jassy lãnh đạo công ty từ Seattle.\u0026#34;, \u0026#34;Microsoft mua lại LinkedIn với giá $26.2 tỷ năm 2016.\u0026#34;, \u0026#34;Google được thành lập bởi Larry Page và Sergey Brin năm 1998.\u0026#34; ] batch_results = ner_system.batch_extract(texts) print(\u0026#34;\\nTrích xuất hàng loạt:\u0026#34;) for i, result in enumerate(batch_results): print(f\u0026#34;\\nVăn bản {i+1}: {result[\u0026#39;văn_bản\u0026#39;]}\u0026#34;) print(\u0026#34;Thực thể:\u0026#34;) for ent in result[\u0026#39;thực_thể\u0026#39;]: print(f\u0026#34; - {ent[\u0026#39;văn_bản\u0026#39;]} ({ent[\u0026#39;nhãn\u0026#39;]})\u0026#34;) Bài tập thực hành Tạo mô hình NER tùy chỉnh cho một lĩnh vực cụ thể (y tế, pháp lý, tài chính) Xây dựng hệ thống entity linking kết nối thực thể với Wikipedia Triển khai active learning cho chú thích hiệu quả Tạo giao diện web cho chú thích và kiểm tra NER Xây dựng đồ thị tri thức từ các thực thể và quan hệ đã trích xuất "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.10-week10/1.10.4-day49-2025-11-13/","title":"Ngày 49 - Giao diện đọc sách &amp; Triển khai tìm kiếm","tags":[],"description":"","content":"Ngày: 2025-11-13\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú bài giảng Trải nghiệm đọc sách CloudFront Signed URLs cho phân phối nội dung Chiến lược bảo mật:\nSách lưu trong S3 public/books/ nhưng không thể truy cập công khai CloudFront cấu hình với Origin Access Control (OAC) S3 bucket policy chỉ cho phép CloudFront truy cập objects Lambda tạo signed GET URLs với TTL ngắn (15 phút) Người dùng truy cập nội dung chỉ qua signed URLs Luồng Signed URL:\nUser nhấp \u0026#34;Đọc\u0026#34; → Frontend gọi API /books/{id}/read → Lambda xác thực user authentication → Lambda kiểm tra book status (APPROVED) → Lambda tạo CloudFront signed URL → Trả URL cho frontend → Frontend load PDF/ePub qua signed URL Render PDF/ePub Tùy chọn triển khai:\nreact-pdf: Render PDF trong browser với canvas PDF.js: PDF viewer của Mozilla (nhiều tính năng hơn) epub.js: ePub reader với tùy chỉnh iframe: Đơn giản nhưng ít kiểm soát Tính năng Reader:\nĐiều hướng trang (trước/sau) Phóng to/thu nhỏ Chế độ toàn màn hình Hỗ trợ bookmark (lưu trong DynamoDB) Theo dõi tiến trình đọc Tìm kiếm \u0026amp; Khám phá Tìm kiếm dựa trên DynamoDB GSI Chiến lược tìm kiếm:\nTạo Global Secondary Indexes (GSI) cho các trường có thể tìm kiếm GSI1: PK=TITLE#{normalizedTitle}, SK=BOOK#{bookId} GSI2: PK=AUTHOR#{normalizedAuthor}, SK=BOOK#{bookId} Query GSI thay vì Scan operations tốn kém Luồng tìm kiếm:\nUser nhập query tìm kiếm → Frontend gọi API /search với query params → Lambda xác định GSI nào cần query → Query GSI1 (title) và/hoặc GSI2 (author) → Intersection kết quả nếu có nhiều params → BatchGetItem để lấy full book metadata → Trả kết quả cho frontend Triển khai tìm kiếm Frontend Search Components:\nThanh tìm kiếm với autocomplete Bảng lọc (theo tác giả, thể loại, ngày upload) Tùy chọn sắp xếp (mới nhất, cũ nhất, phổ biến) Chuyển đổi xem grid/list Phân trang hoặc infinite scroll Tối ưu tìm kiếm:\nDebounce search input (chờ 300ms sau khi gõ) Cache kết quả tìm kiếm gần đây (5 phút) Hiển thị loading skeleton trong quá trình tìm kiếm Hiển thị \u0026ldquo;No results\u0026rdquo; với suggestions Những hiểu biết quan trọng Signed URLs thiết yếu cho bảo mật nội dung - không bao giờ expose S3 trực tiếp TTL ngắn trên signed URLs ngăn chia sẻ/lạm dụng Query GSI rẻ hơn và nhanh hơn nhiều so với Scan Normalized fields (chữ thường, không ký tự đặc biệt) cải thiện độ chính xác tìm kiếm Caching client-side giảm API calls và cải thiện UX Công việc đã hoàn thành Trang chi tiết sách\nTạo view chi tiết sách với hiển thị metadata Triển khai loading ảnh bìa từ S3 Thêm nút \u0026ldquo;Read Now\u0026rdquo; (chỉ cho sách APPROVED) Xây dựng phần sách liên quan Tích hợp PDF Reader\nTích hợp thư viện react-pdf để render PDF Tạo component reader với navigation controls Triển khai zoom controls (fit-width, fit-page, custom zoom) Thêm chuyển đổi chế độ fullscreen Tích hợp ePub Reader\nTích hợp thư viện epub.js để render ePub Tạo ePub reader với page turn animations Triển khai text selection và note-taking Thêm font size và theme điều chỉnh được Triển khai Signed URL\nTạo phương thức API client getReadUrl Triển khai fetching signed URL khi nhấp \u0026ldquo;Read\u0026rdquo; Thêm xử lý URL expiration (re-fetch khi hết hạn) Xây dựng trạng thái loading khi fetching URL Chức năng tìm kiếm\nTạo component thanh tìm kiếm với autocomplete Triển khai tích hợp API tìm kiếm (endpoint /search) Xây dựng trang kết quả tìm kiếm với grid/list view Thêm sidebar lọc (tác giả, thể loại, trạng thái) Tối ưu tìm kiếm\nTriển khai debounced search input (delay 300ms) Thêm caching kết quả client-side với React Query Tạo lịch sử tìm kiếm (lưu trong localStorage) Xây dựng dropdown \u0026ldquo;Recent Searches\u0026rdquo; Tính năng khám phá\nTạo trang \u0026ldquo;Browse Books\u0026rdquo; với tất cả sách đã duyệt Triển khai lọc category/genre Thêm tùy chọn sắp xếp (mới nhất, title A-Z, author A-Z) Xây dựng phần \u0026ldquo;Recommended for You\u0026rdquo; (tương lai: dựa trên ML) Thách thức \u0026amp; Giải pháp Thách thức: Vấn đề hiệu suất render PDF với files lớn\nGiải pháp: Triển khai lazy loading của pages (chỉ render pages visible) và sử dụng Web Workers cho PDF parsing\nThách thức: Signed URLs hết hạn trong phiên đọc\nGiải pháp: Triển khai cơ chế auto-refresh yêu cầu URL mới 2 phút trước khi hết hạn\nThách thức: Tìm kiếm trả quá nhiều kết quả gây UI chậm\nGiải pháp: Triển khai phân trang server-side với cursor-based navigation và virtual scrolling\nThách thức: Text selection ePub can thiệp page turns\nGiải pháp: Thêm touch/click handlers với gesture detection để phân biệt selection và navigation\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.4-week4/","title":"Tuần 4 - Dịch vụ Lưu trữ trên AWS","tags":[],"description":"","content":"Tuần: 2025-09-29 đến 2025-10-03\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 4 Tuần này tập trung vào các dịch vụ lưu trữ của AWS, từ S3 cho tới giải pháp hybrid và chiến lược DR.\nNội dung chính Amazon S3 và các lớp lưu trữ. S3 Static Website Hosting. S3 Glacier cho lưu trữ dài hạn. AWS Snow Family. AWS Storage Gateway. Chiến lược Disaster Recovery. AWS Backup. Labs thực hành Lab 13: AWS Backup. Lab 14: AWS VM Import/Export. Lab 24: AWS Storage Gateway. Lab 25: Amazon FSx. Lab 57: Amazon S3 \u0026amp; CloudFront. "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.6-week6/1.6.5-day30-2025-10-17/","title":"Day 30 - Database Migration &amp; Best Practices","tags":[],"description":"","content":" ⚠️ Bản dịch tiếng Việt đang được cập nhật. Vui lòng xem nội dung chi tiết trong file _index.md (tiếng Anh).\nNội dung tiếng Việt sẽ được bổ sung sớm để phản ánh đầy đủ các ghi chú và bài lab.\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.7-week7/1.7.5-day35-2025-10-24/","title":"Day 35 - Contract Testing &amp; Retrospective","tags":[],"description":"","content":" ⚠️ Bản dịch tiếng Việt đang được cập nhật. Vui lòng xem nội dung chi tiết trong file _index.md (tiếng Anh).\nNội dung tiếng Việt sẽ được bổ sung sớm để phản ánh đầy đủ các ghi chú và bài lab.\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.1-week1/1.1.5-day05-2025-09-12/","title":"Ngày 05 - AWS Well-Architected Framework","tags":[],"description":"","content":"Ngày: 2025-09-12\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nKhám phá AWS Well-Architected Framework Bộ nguyên tắc thiết kế và phương pháp thực hành tốt nhất để xây dựng kiến trúc cloud tin cậy, bảo mật, hiệu quả và tiết kiệm chi phí. Công cụ Well-Architected trên Console hỗ trợ tự đánh giá và đề xuất hướng cải thiện. Sáu trụ cột của Well-Architected Framework 1. Vận hành xuất sắc (Operational Excellence) Tập trung vận hành và giám sát hệ thống. Liên tục cải thiện quy trình. Tự động hóa thay đổi. Phản ứng kịp thời trước sự kiện. 2. Bảo mật (Security) Bảo vệ thông tin và hệ thống. Quản lý danh tính và quyền truy cập. Thiết lập cơ chế giám sát phát hiện. Bảo vệ hạ tầng. Giữ an toàn cho dữ liệu. 3. Độ tin cậy (Reliability) Tự động phục hồi khi gặp sự cố. Mở rộng ngang để tăng khả năng chịu lỗi. Kiểm thử kịch bản khôi phục. Quản lý thay đổi bằng tự động hóa. 4. Hiệu năng (Performance Efficiency) Sử dụng tài nguyên tính toán hiệu quả. Chọn đúng loại tài nguyên. Giám sát hiệu năng. Đưa ra quyết định dựa trên dữ liệu. 5. Tối ưu chi phí (Cost Optimization) Tránh chi tiêu không cần thiết. Hiểu rõ mô hình sử dụng. Chọn dịch vụ phù hợp. Tối ưu liên tục theo thời gian. 6. Phát triển bền vững (Sustainability) Giảm tác động đến môi trường. Hiểu dấu chân carbon của hệ thống. Tối đa hóa mức sử dụng tài nguyên. Ưu tiên dịch vụ managed. Ôn lại Best Practices Nguyên tắc thiết kế Ngừng đoán dung lượng: Dùng auto scaling. Kiểm thử ở quy mô sản xuất: Dễ dàng nhân bản môi trường. Tự động hóa thử nghiệm kiến trúc: Áp dụng hạ tầng như mã (IaC). Cho phép kiến trúc tiến hóa: Thiết kế linh hoạt để thay đổi. Ra quyết định dựa trên dữ liệu: Luôn giám sát \u0026amp; đo lường. Cải thiện qua game day: Luyện tập kịch bản sự cố. Tổng kết Tuần 1 Tuần này đã hoàn thành kiến thức nền tảng về AWS:\nHiểu về Cloud Computing và lợi ích\nNắm được AWS Global Infrastructure\nBiết cách sử dụng AWS Management Tools\nHọc các chiến lược tối ưu chi phí\nNắm AWS Well-Architected Framework\nLabs đã hoàn tất: 3 labs (IAM Setup, Budgets, Support Plans)\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.2-week2/1.2.5-day10-2025-09-19/","title":"Ngày 10 - Elastic Load Balancing","tags":[],"description":"","content":"Ngày: 2025-09-19\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Elastic Load Balancing (ELB) Tổng quan Dịch vụ fully-managed phân phối lưu lượng tới nhiều target (EC2, container, v.v.). Hỗ trợ giao thức HTTP, HTTPS, TCP, TLS. Có thể triển khai ở subnet public hoặc private. Cung cấp DNS name; chỉ Network Load Balancer hỗ trợ IP tĩnh. Tích hợp health check và ghi log truy cập (lưu S3). Hỗ trợ sticky session (session affinity). Các loại chính: Application, Network, Classic và Gateway Load Balancer. Application Load Balancer (ALB) Hoạt động ở tầng 7 (HTTP/HTTPS). Hỗ trợ định tuyến theo path (ví dụ /mobile vs /desktop). Target: EC2, Lambda, địa chỉ IP, container (ECS/EKS). Tính năng nổi bật của ALB:\nĐịnh tuyến theo host name. Định tuyến theo path. Định tuyến dựa trên HTTP header. Định tuyến theo query string parameter. Hỗ trợ WebSocket. Hỗ trợ HTTP/2. Network Load Balancer (NLB) Hoạt động ở tầng 4 (TCP/TLS). Hỗ trợ IP tĩnh, xử lý hàng triệu request/giây. Target: EC2, địa chỉ IP, container (ECS/EKS). Điểm mạnh của NLB:\nĐộ trễ cực thấp. Cung cấp địa chỉ IP tĩnh. Giữ nguyên nguồn IP truy cập. Hỗ trợ kết nối TCP dài hạn. Có thể chấm dứt TLS (TLS termination). Gateway Load Balancer (GWLB) Hoạt động ở tầng 3 (gói IP). Sử dụng giao thức GENEVE trên cổng 6081. Định tuyến lưu lượng đến các virtual appliance như firewall, công cụ monitor. Danh sách đối tác: aws.amazon.com/elasticloadbalancing/partners Khám phá AWS Advanced Networking – Specialty Study Guide Sách hướng dẫn chính thức bao quát chủ đề kỳ thi, nguyên tắc thiết kế mạng trên AWS và các tình huống kiến trúc thực tế. Hands-On Labs Lab 20 – AWS Transit Gateway Chuẩn bị môi trường → 20-02 Tạo Transit Gateway → 20-03 Tạo TGW Attachment → 20-04 Tạo TGW Route Table → 20-05 Thêm route TGW vào Route Table của VPC → 20-06 Tổng kết Tuần 2 Tuần này đã hoàn thành kiến thức về AWS Networking:\nAmazon VPC và Subnet\nSecurity Group và NACL\nVPC Peering và Transit Gateway\nVPN và Direct Connect\nElastic Load Balancing (ALB, NLB, GWLB)\nLabs đã hoàn tất: 4 labs (VPC Basics, Hybrid DNS, VPC Peering, Transit Gateway)\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.3-week3/1.3.5-day15-2025-09-26/","title":"Ngày 15 - Lightsail, EFS &amp; FSx","tags":[],"description":"","content":"Ngày: 2025-09-26\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học Amazon Lightsail Dịch vụ compute đơn giản với giá cố định hàng tháng (bắt đầu ~3,5 USD/tháng). Bao gồm băng thông đi kèm với giá thấp hơn EC2. Lý tưởng cho workload nhỏ, môi trường dev/test. Hỗ trợ snapshot để sao lưu. Chạy trong VPC được quản lý và có thể kết nối VPC tiêu chuẩn qua peering (một lần nhấp). Trường hợp dùng Lightsail:\nỨng dụng web đơn giản. Trang WordPress. Môi trường phát triển/thử nghiệm. Ứng dụng doanh nghiệp nhỏ. Học tập và thử nghiệm. So sánh Lightsail và EC2:\nTiêu chí Lightsail EC2 Giá Cố định hàng tháng Trả theo dùng Độ phức tạp Đơn giản Nhiều tùy chọn Khả năng mở rộng Giới hạn Không giới hạn Đối tượng Dự án nhỏ Doanh nghiệp Amazon EFS (Elastic File System) Dịch vụ hệ thống file NFSv4 do AWS quản lý, nhiều EC2 có thể mount đồng thời. Tự động scale tới hàng petabyte. Trả tiền theo dung lượng thực tế sử dụng (khác với EBS phải provision). Có thể mount từ on-prem thông qua VPN hoặc Direct Connect. Tính năng EFS:\nTruy cập đồng thời từ nhiều instance. Tự động mở rộng. Dịch vụ cấp độ Region (đa AZ). Quản lý vòng đời. Mã hóa dữ liệu khi lưu trữ và truyền tải. Các lớp lưu trữ EFS:\nStandard: File truy cập thường xuyên. Infrequent Access (IA): Chi phí thấp cho file ít truy cập. One Zone: Một AZ để tiết kiệm chi phí. Amazon FSx Các hệ thống file được quản lý, mở rộng cho Windows, Lustre, NetApp ONTAP. AWS lo phần thiết lập, mở rộng, sao lưu. Truy cập từ EC2, máy chủ on-prem hoặc người dùng qua giao thức SMB/NFS. Các biến thể FSx:\nFSx for Windows File Server Hệ thống file Windows gốc. Hỗ trợ giao thức SMB. Tích hợp Active Directory. Hỗ trợ DFS namespace. FSx for Lustre Phù hợp workload HPC. Machine Learning, mô phỏng. Độ trễ dưới mili giây. Tích hợp S3. FSx for NetApp ONTAP Hỗ trợ đa giao thức (NFS, SMB, iSCSI). Giảm trùng lặp dữ liệu, nén. Snapshots và replication. AWS Application Migration Service (MGN) Dịch vụ migrate/replicate máy chủ vật lý hoặc ảo lên AWS để DR hoặc hiện đại hóa. Liên tục sao chép máy nguồn sang instance staging EC2 nhẹ. Khi cut-over, MGN tạo EC2 đầy đủ chức năng từ dữ liệu đã replicate. Các giai đoạn migration:\nCài agent lên máy nguồn. Sao chép liên tục vào AWS. Kiểm thử bằng instance test không ảnh hưởng. Cutover sang production. Khám phá Microsoft Workloads on AWS Playlist tuyển chọn về triển khai, tối ưu và best practices khi chạy workload Microsoft trên AWS. Tổng kết Tuần 3 Tuần này đã hoàn thành kiến thức về AWS Compute:\nAmazon EC2 và các loại instance\nAMI, EBS, Instance Store\nEC2 Auto Scaling\nCác mô hình giá của EC2\nLightsail, EFS, FSx\nLabs đã hoàn tất: 3 labs (IAM Setup, Budgets, Support Plans)\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.4-week4/1.4.5-day20-2025-10-03/","title":"Ngày 20 - AWS Backup &amp; FSx","tags":[],"description":"","content":"Ngày: 2025-10-03\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học AWS Backup Dịch vụ backup tập trung giúp tự động hóa và quản trị bảo vệ dữ liệu ở quy mô lớn. Khả năng chính Quản lý tập trung: Định nghĩa và áp chính sách backup cho nhiều dịch vụ. Hỗ trợ đa dịch vụ: EC2, EBS, RDS, DynamoDB, EFS, Storage Gateway, S3,\u0026hellip; Lịch và vòng đời: Tự động hóa lịch backup và retention. Tuân thủ: Đáp ứng yêu cầu governance và audit. Lợi ích Đơn giản vận hành: Không cần script tùy biến hay công cụ rời rạc. Tiết kiệm thời gian: Tự động bảo vệ dựa trên policy. Báo cáo \u0026amp; audit: Theo dõi trạng thái backup và tuân thủ. Backup Vault Lock Cơ chế đảm bảo tính bất biến, ngăn chỉnh sửa/xóa backup đã bảo vệ nhằm đáp ứng yêu cầu tuân thủ nghiêm ngặt. Tính năng nổi bật của AWS Backup:\nSao chép backup liên vùng. Backup chéo tài khoản. Backup plan (chính sách) linh hoạt. Quản lý vòng đời (lưu trữ lạnh, xóa theo hạn). Mã hóa dữ liệu khi lưu trữ. Gắn thẻ để điều khiển chính sách backup theo tag. Ví dụ Backup Plan:\n{ \u0026#34;BackupPlanName\u0026#34;: \u0026#34;DailyBackups\u0026#34;, \u0026#34;Rules\u0026#34;: [{ \u0026#34;RuleName\u0026#34;: \u0026#34;DailyRule\u0026#34;, \u0026#34;ScheduleExpression\u0026#34;: \u0026#34;cron(0 5 ? * * *)\u0026#34;, \u0026#34;StartWindowMinutes\u0026#34;: 60, \u0026#34;CompletionWindowMinutes\u0026#34;: 120, \u0026#34;Lifecycle\u0026#34;: { \u0026#34;DeleteAfterDays\u0026#34;: 30, \u0026#34;MoveToColdStorageAfterDays\u0026#34;: 7 } }] } Khám phá AWS Skill Builder Các learning plan chọn lọc và nội dung chuyên sâu dành cho chuyên gia lưu trữ: Storage Learning Plan: Block Storage Storage Learning Plan: Object Storage Hands-On Labs Lab 13 – AWS Backup Tạo S3 Bucket → 13-02.1 Triển khai hạ tầng mẫu → 13-02.2 Tạo Backup Plan → 13-03 Thiết lập thông báo → 13-04 Kiểm tra khôi phục → 13-05 Dọn dẹp tài nguyên → 13-06 Lab 25 – Amazon FSx (File Systems) Tạo File System SSD Multi-AZ → 25-2.2 Tạo File System HDD Multi-AZ → 25-2.3 Tạo File Share mới → 25-3 Kiểm thử hiệu năng → 25-4 Giám sát hiệu năng → 25-5 Bật tính năng Data Deduplication → 25-6 Bật Shadow Copies → 25-7 Quản lý phiên người dùng \u0026amp; file mở → 25-8 Bật quota người dùng → 25-9 Scale thông lượng → 25-11 Mở rộng dung lượng lưu trữ → 25-12 Xóa môi trường → 25-13 Tổng kết Tuần 4 Tuần này đã hoàn tất các chủ đề về AWS Storage:\nAmazon S3 và các lớp lưu trữ\nS3 Static Website và CORS\nAWS Snow Family\nAWS Storage Gateway\nChiến lược Disaster Recovery\nAWS Backup\nLabs đã hoàn tất: 5 labs (Backup, VM Import/Export, Storage Gateway, FSx, S3 \u0026amp; CloudFront)\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.5-week5/1.5.5-day25-2025-10-10/","title":"Ngày 25 - AWS Security Hub &amp; Automation","tags":[],"description":"","content":"Ngày: 2025-10-10\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú Bài học AWS Security Hub Tổng hợp và ưu tiên hóa các phát hiện bảo mật, posture across account/dịch vụ. Khả năng\nKiểm tra tự động, chuẩn hóa findings, workflow xử lý ưu tiên. Hỗ trợ chuẩn tuân thủ: CIS AWS Foundations, PCI DSS, AWS Foundational Security Best Practices. Tích hợp\nGuardDuty, Inspector, Macie, Firewall Manager, IAM Access Analyzer và nhiều công cụ đối tác. Kết quả\nGiảm thời gian thu thập, tập trung khắc phục; cái nhìn hợp nhất và nâng cao hygiene bảo mật. Tính năng Security Hub:\nTheo dõi posture bảo mật liên tục. Kiểm tra tuân thủ tự động. Tổng hợp findings đa tài khoản. Tích hợp 50+ dịch vụ AWS \u0026amp; đối tác. Custom insight và dashboard. Tự động khắc phục qua EventBridge. Chuẩn bảo mật được hỗ trợ:\nAWS Foundational Security Best Practices: hơn 50 control. CIS AWS Foundations Benchmark: chuẩn ngành. PCI DSS: tiêu chuẩn thẻ thanh toán. NIST: khung bảo mật NIST. Security Automation Dịch vụ AWS phục vụ tự động hóa:\nAWS Config: Theo dõi thay đổi cấu hình tài nguyên. Amazon EventBridge: Tự động hóa dựa trên sự kiện. AWS Lambda: Hàm serverless xử lý remediation. AWS Systems Manager: Tự động vá lỗi và quản lý tuân thủ. Mẫu tự động hóa phổ biến:\nTự động khắc phục tài nguyên không tuân thủ. Ứng phó sự cố tự động. Kiểm tra quy tắc security group. Cưỡng chế mã hóa. Đảm bảo tuân thủ tag. Khám phá AWS Certified Security – Specialty: All-in-One Exam Guide (SCS-C01) Tài liệu ôn luyện toàn diện cho chứng chỉ Security Specialty. Hands-On Labs Lab 18 – AWS Security Hub Bật Security Hub → 18-02 Đánh giá từng bộ tiêu chí → 18-03 Dọn dẹp tài nguyên → 18-04 Lab 22 – AWS Lambda Automation with Slack Tạo VPC → 22-2.1 Tạo Security Group → 22-2.2 Tạo EC2 Instance → 22-2.3 Cấu hình Slack Incoming Webhook → 22-2.4 Tạo tag cho instance → 22-3 Tạo role cho Lambda → 22-4 Hàm Stop Instance → 22-5.1 Hàm Start Instance → 22-5.2 Kiểm tra kết quả → 22-6 Dọn dẹp → 22-7 Lab 27 – AWS Resource Groups \u0026amp; Tagging (Phần 2) Sử dụng tag với CLI → 27-2.2 Tạo Resource Group → 27-3 Dọn dẹp tài nguyên → 27-4 Lab 33 – AWS KMS \u0026amp; CloudTrail Integration (Phần 2) Tạo CloudTrail → 33-5.1 Ghi log vào CloudTrail → 33-5.2 Tạo Amazon Athena → 33-5.3 Query bằng Athena → 33-5.4 Kiểm tra \u0026amp; chia sẻ dữ liệu S3 đã mã hóa → 33-6 Dọn dẹp → 33-7 Lab 44 – IAM Advanced Role Control Tạo IAM Group → 44-2 Tạo IAM User → 44-3.1 Kiểm tra quyền → 44-3.2 Tạo IAM Role Admin → 44-4.1 Cấu hình Switch Role → 44-4.2 Giới hạn Switch Role theo IP → 44-4.3.1 Giới hạn Switch Role theo thời gian → 44-4.3.2 Dọn dẹp → 44-5 Tổng kết Tuần 5 Tuần này đã hoàn tất các chủ đề về AWS Security:\nShared Responsibility Model\nAWS IAM (Users, Groups, Roles, Policies)\nAmazon Cognito\nAWS Organizations \u0026amp; SCPs\nAWS Identity Center\nAWS KMS\nAWS Security Hub\nLabs đã hoàn tất: 8 labs (Security Hub, Lambda Automation, Resource Groups, IAM Policies, KMS \u0026amp; CloudTrail, Advanced Role Control)\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.8-week8/1.8.5-day40-2025-10-31/","title":"Ngày 40 - Xây dựng dự án NLP","tags":[],"description":"","content":"Ngày: 2025-10-31\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú bài giảng Xây dựng hệ thống NLP Production Quy trình dự án NLP Thu thập dữ liệu → Tiền xử lý → Kỹ thuật đặc trưng → Huấn luyện mô hình → Đánh giá → Triển khai → Giám sát Mỗi giai đoạn yêu cầu xem xét cẩn thận và lặp lại Chất lượng dữ liệu quyết định chất lượng mô hình Giám sát liên tục thiết yếu cho hệ thống production Các loại dự án NLP phổ biến Phân loại văn bản: Phân loại tài liệu vào các lớp được xác định trước Chatbots: AI đàm thoại cho dịch vụ khách hàng hoặc truy xuất thông tin Trích xuất thông tin: Trích xuất dữ liệu có cấu trúc từ văn bản không có cấu trúc Tóm tắt văn bản: Tạo bản tóm tắt ngắn gọn của tài liệu dài hơn Dịch máy: Dịch văn bản giữa các ngôn ngữ Thực hành tốt nhất Bắt đầu đơn giản: mô hình cơ sở trước các giải pháp phức tạp Kiểm soát phiên bản dữ liệu và mô hình của bạn Ghi chép các quyết định tiền xử lý Kiểm tra trên dữ liệu thực tế, không chỉ tập dữ liệu sạch Giám sát hiệu suất mô hình trong production Có chiến lược dự phòng cho lỗi mô hình Kiến thức cơ bản về phân loại văn bản Cách tiếp cận Chuẩn bị dữ liệu: Thu thập nhãn và làm sạch Trích xuất đặc trưng: TF-IDF, word embeddings hoặc contextual embeddings Lựa chọn mô hình: Naive Bayes, SVM hoặc neural networks Đánh giá: Độ chính xác, precision, recall, F1-score Lặp lại: Cải thiện dựa trên phân tích lỗi Các thuật toán phổ biến Naive Bayes: Nhanh, hoạt động tốt với dữ liệu hạn chế SVM: Hiệu quả cho văn bản với ranh giới rõ ràng Logistic Regression: Đơn giản và có thể giải thích Random Forest: Xử lý các mẫu phi tuyến Neural Networks: Hiệu suất tốt nhất nhưng cần nhiều dữ liệu hơn Kiến trúc Chatbot đơn giản Các thành phần Nhận dạng ý định: Hiểu mục tiêu của người dùng Trích xuất thực thể: Xác định thông tin chính Quản lý hội thoại: Duy trì ngữ cảnh cuộc trò chuyện Tạo phản hồi: Tạo câu trả lời phù hợp Các cách triển khai Dựa trên quy tắc: Khớp mẫu cho truy vấn đơn giản Dựa trên truy xuất: Chọn từ các phản hồi được xác định trước Tạo sinh: Tạo phản hồi bằng mô hình ngôn ngữ Lai: Kết hợp nhiều cách tiếp cận Những hiểu biết quan trọng Bắt đầu với các cách tiếp cận đơn giản và lặp lại Dữ liệu thực tế rất lộn xộn - tiền xử lý mạnh mẽ là quan trọng Khả năng giải thích mô hình quan trọng cho hệ thống production Trải nghiệm người dùng quan trọng không kém độ chính xác mô hình Luôn có tùy chọn human-in-the-loop cho ứng dụng quan trọng Thực hành Lab Lab 1: Phân loại văn bản - Phát hiện Spam from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.model_selection import train_test_split from sklearn.naive_bayes import MultinomialNB from sklearn.metrics import classification_report, confusion_matrix import pandas as pd # Dữ liệu mẫu (trong thực tế, sử dụng tập dữ liệu thực) emails = [ (\u0026#34;Win a free iPhone now!\u0026#34;, \u0026#34;spam\u0026#34;), (\u0026#34;Meeting tomorrow at 3pm\u0026#34;, \u0026#34;ham\u0026#34;), (\u0026#34;Claim your prize money today\u0026#34;, \u0026#34;spam\u0026#34;), (\u0026#34;Project update attached\u0026#34;, \u0026#34;ham\u0026#34;), (\u0026#34;Get rich quick! Click here!\u0026#34;, \u0026#34;spam\u0026#34;), (\u0026#34;Lunch plans for Friday?\u0026#34;, \u0026#34;ham\u0026#34;), # Thêm nhiều ví dụ... ] # Chuẩn bị dữ liệu texts = [email[0] for email in emails] labels = [email[1] for email in emails] # Chia dữ liệu X_train, X_test, y_train, y_test = train_test_split( texts, labels, test_size=0.2, random_state=42 ) # Trích xuất đặc trưng vectorizer = TfidfVectorizer(max_features=1000, stop_words=\u0026#39;english\u0026#39;) X_train_vec = vectorizer.fit_transform(X_train) X_test_vec = vectorizer.transform(X_test) # Huấn luyện mô hình classifier = MultinomialNB() classifier.fit(X_train_vec, y_train) # Dự đoán y_pred = classifier.predict(X_test_vec) # Đánh giá print(\u0026#34;Báo cáo phân loại:\u0026#34;) print(classification_report(y_test, y_pred)) # Kiểm tra email mới new_email = [\u0026#34;Congratulations! You won $1000000\u0026#34;] new_email_vec = vectorizer.transform(new_email) prediction = classifier.predict(new_email_vec) print(f\u0026#34;\\nDự đoán email mới: {prediction[0]}\u0026#34;) Lab 2: Bộ phân loại cảm xúc from sklearn.linear_model import LogisticRegression from nltk.tokenize import word_tokenize from nltk.corpus import stopwords import string # Hàm tiền xử lý def preprocess(text): # Chữ thường và tokenize tokens = word_tokenize(text.lower()) # Loại bỏ stopwords và dấu câu stop_words = set(stopwords.words(\u0026#39;english\u0026#39;)) tokens = [w for w in tokens if w not in stop_words and w not in string.punctuation] return \u0026#39; \u0026#39;.join(tokens) # Đánh giá phim mẫu reviews = [ (\u0026#34;This movie was amazing! Loved every minute.\u0026#34;, \u0026#34;positive\u0026#34;), (\u0026#34;Terrible film, waste of time and money.\u0026#34;, \u0026#34;negative\u0026#34;), (\u0026#34;Great acting and storyline, highly recommend!\u0026#34;, \u0026#34;positive\u0026#34;), (\u0026#34;Boring and predictable, wouldn\u0026#39;t watch again.\u0026#34;, \u0026#34;negative\u0026#34;), (\u0026#34;Masterpiece! One of the best films I\u0026#39;ve seen.\u0026#34;, \u0026#34;positive\u0026#34;), # Thêm nhiều ví dụ... ] # Tiền xử lý dữ liệu texts = [preprocess(review[0]) for review in reviews] labels = [review[1] for review in reviews] # Chia và vector hóa X_train, X_test, y_train, y_test = train_test_split( texts, labels, test_size=0.2, random_state=42 ) vectorizer = TfidfVectorizer() X_train_vec = vectorizer.fit_transform(X_train) X_test_vec = vectorizer.transform(X_test) # Huấn luyện model = LogisticRegression(max_iter=1000) model.fit(X_train_vec, y_train) # Đánh giá accuracy = model.score(X_test_vec, y_test) print(f\u0026#34;Độ chính xác: {accuracy:.2f}\u0026#34;) # Kiểm tra test_review = \u0026#34;This movie exceeded my expectations, truly wonderful!\u0026#34; test_vec = vectorizer.transform([preprocess(test_review)]) prediction = model.predict(test_vec) print(f\u0026#34;\\nĐánh giá: {test_review}\u0026#34;) print(f\u0026#34;Cảm xúc: {prediction[0]}\u0026#34;) Lab 3: Chatbot đơn giản dựa trên quy tắc import re import random class SimpleChatbot: def __init__(self): self.patterns = { r\u0026#39;hi|hello|hey\u0026#39;: [ \u0026#34;Xin chào! Tôi có thể giúp gì cho bạn?\u0026#34;, \u0026#34;Chào bạn! Tôi có thể làm gì cho bạn?\u0026#34;, \u0026#34;Chào! Bạn khỏe không?\u0026#34; ], r\u0026#39;how are you\u0026#39;: [ \u0026#34;Tôi rất tốt, cảm ơn bạn đã hỏi!\u0026#34;, \u0026#34;Tôi khỏe, còn bạn thì sao?\u0026#34;, \u0026#34;Khỏe! Tôi có thể hỗ trợ bạn thế nào?\u0026#34; ], r\u0026#39;what is your name\u0026#39;: [ \u0026#34;Tôi là chatbot đơn giản được tạo để hỗ trợ bạn!\u0026#34;, \u0026#34;Bạn có thể gọi tôi là ChatBot!\u0026#34;, \u0026#34;Tôi là bot trợ lý thân thiện của bạn!\u0026#34; ], r\u0026#39;bye|goodbye|see you\u0026#39;: [ \u0026#34;Tạm biệt! Chúc bạn một ngày tốt lành!\u0026#34;, \u0026#34;Hẹn gặp lại!\u0026#34;, \u0026#34;Tạm biệt! Quay lại sớm nhé!\u0026#34; ], r\u0026#39;thank you|thanks\u0026#39;: [ \u0026#34;Không có gì!\u0026#34;, \u0026#34;Rất vui được giúp đỡ!\u0026#34;, \u0026#34;Bất cứ lúc nào!\u0026#34; ] } self.default_responses = [ \u0026#34;Tôi không chắc tôi hiểu. Bạn có thể diễn đạt lại không?\u0026#34;, \u0026#34;Bạn có thể làm rõ hơn không?\u0026#34;, \u0026#34;Thú vị! Kể cho tôi nghe thêm.\u0026#34; ] def get_response(self, user_input): user_input = user_input.lower() # Kiểm tra từng mẫu for pattern, responses in self.patterns.items(): if re.search(pattern, user_input): return random.choice(responses) # Phản hồi mặc định return random.choice(self.default_responses) def chat(self): print(\u0026#34;Chatbot: Xin chào! Tôi là chatbot đơn giản. Gõ \u0026#39;quit\u0026#39; để thoát.\u0026#34;) while True: user_input = input(\u0026#34;Bạn: \u0026#34;) if user_input.lower() == \u0026#39;quit\u0026#39;: print(\u0026#34;Chatbot: Tạm biệt!\u0026#34;) break response = self.get_response(user_input) print(f\u0026#34;Chatbot: {response}\u0026#34;) # Kiểm tra chatbot bot = SimpleChatbot() # Chế độ tương tác # bot.chat() # Kiểm tra tin nhắn riêng lẻ test_messages = [ \u0026#34;Hello!\u0026#34;, \u0026#34;How are you?\u0026#34;, \u0026#34;What is your name?\u0026#34;, \u0026#34;Thanks for your help!\u0026#34;, \u0026#34;Tell me about NLP\u0026#34; ] for message in test_messages: print(f\u0026#34;Bạn: {message}\u0026#34;) print(f\u0026#34;Bot: {bot.get_response(message)}\\n\u0026#34;) Lab 4: Chatbot dựa trên ý định class IntentChatbot: def __init__(self): self.intents = { \u0026#39;chào_hỏi\u0026#39;: { \u0026#39;patterns\u0026#39;: [\u0026#39;hello\u0026#39;, \u0026#39;hi\u0026#39;, \u0026#39;hey\u0026#39;, \u0026#39;good morning\u0026#39;, \u0026#39;xin chào\u0026#39;, \u0026#39;chào\u0026#39;], \u0026#39;responses\u0026#39;: [\u0026#39;Xin chào!\u0026#39;, \u0026#39;Chào bạn!\u0026#39;, \u0026#39;Chào mừng!\u0026#39;] }, \u0026#39;thời_tiết\u0026#39;: { \u0026#39;patterns\u0026#39;: [\u0026#39;weather\u0026#39;, \u0026#39;temperature\u0026#39;, \u0026#39;forecast\u0026#39;, \u0026#39;thời tiết\u0026#39;, \u0026#39;nhiệt độ\u0026#39;], \u0026#39;responses\u0026#39;: [ \u0026#39;Tôi không thể kiểm tra thời tiết, nhưng bạn có thể thử ứng dụng thời tiết!\u0026#39;, \u0026#39;Để biết thông tin thời tiết, vui lòng kiểm tra dịch vụ thời tiết.\u0026#39; ] }, \u0026#39;thời_gian\u0026#39;: { \u0026#39;patterns\u0026#39;: [\u0026#39;time\u0026#39;, \u0026#39;clock\u0026#39;, \u0026#39;what time\u0026#39;, \u0026#39;giờ\u0026#39;, \u0026#39;mấy giờ\u0026#39;], \u0026#39;responses\u0026#39;: [\u0026#39;Vui lòng kiểm tra đồng hồ hệ thống của bạn.\u0026#39;] }, \u0026#39;khả_năng\u0026#39;: { \u0026#39;patterns\u0026#39;: [\u0026#39;what can you do\u0026#39;, \u0026#39;your features\u0026#39;, \u0026#39;help\u0026#39;, \u0026#39;bạn làm được gì\u0026#39;, \u0026#39;giúp\u0026#39;], \u0026#39;responses\u0026#39;: [ \u0026#39;Tôi có thể trò chuyện với bạn, trả lời câu hỏi đơn giản và hỗ trợ các truy vấn cơ bản!\u0026#39;, \u0026#39;Tôi là chatbot đơn giản có thể có cuộc trò chuyện cơ bản.\u0026#39; ] } } def classify_intent(self, text): text = text.lower() for intent, data in self.intents.items(): for pattern in data[\u0026#39;patterns\u0026#39;]: if pattern in text: return intent return \u0026#39;không_xác_định\u0026#39; def get_response(self, text): intent = self.classify_intent(text) if intent == \u0026#39;không_xác_định\u0026#39;: return \u0026#34;Tôi không chắc cách trả lời điều đó. Thử hỏi về thời tiết, thời gian hoặc tôi có thể làm gì!\u0026#34; return random.choice(self.intents[intent][\u0026#39;responses\u0026#39;]) # Kiểm tra intent_bot = IntentChatbot() queries = [ \u0026#34;Xin chào!\u0026#34;, \u0026#34;Thời tiết thế nào?\u0026#34;, \u0026#34;Mấy giờ rồi?\u0026#34;, \u0026#34;Bạn làm được gì?\u0026#34;, \u0026#34;Kể cho tôi một câu chuyện cười\u0026#34; ] for query in queries: print(f\u0026#34;Người dùng: {query}\u0026#34;) print(f\u0026#34;Bot: {intent_bot.get_response(query)}\u0026#34;) print(f\u0026#34;Ý định: {intent_bot.classify_intent(query)}\\n\u0026#34;) Lab 5: Dự án quy trình NLP hoàn chỉnh import spacy from textblob import TextBlob from collections import Counter class TextAnalyzer: def __init__(self): self.nlp = spacy.load(\u0026#34;en_core_web_sm\u0026#34;) def analyze(self, text): \u0026#34;\u0026#34;\u0026#34;Quy trình phân tích văn bản hoàn chỉnh\u0026#34;\u0026#34;\u0026#34; # Thống kê cơ bản doc = self.nlp(text) word_count = len([token for token in doc if not token.is_punct]) sentence_count = len(list(doc.sents)) # Thực thể entities = [(ent.text, ent.label_) for ent in doc.ents] # Cảm xúc blob = TextBlob(text) sentiment = { \u0026#39;polarity\u0026#39;: blob.sentiment.polarity, \u0026#39;subjectivity\u0026#39;: blob.sentiment.subjectivity } # Từ khóa (các từ có ý nghĩa phổ biến nhất) keywords = Counter([token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct and token.pos_ in [\u0026#39;NOUN\u0026#39;, \u0026#39;VERB\u0026#39;, \u0026#39;ADJ\u0026#39;]]) return { \u0026#39;số_từ\u0026#39;: word_count, \u0026#39;số_câu\u0026#39;: sentence_count, \u0026#39;thực_thể\u0026#39;: entities, \u0026#39;cảm_xúc\u0026#39;: sentiment, \u0026#39;từ_khóa_hàng_đầu\u0026#39;: keywords.most_common(5) } # Kiểm tra analyzer = TextAnalyzer() sample_article = \u0026#34;\u0026#34;\u0026#34; Apple Inc. thông báo hôm nay rằng Tim Cook sẽ phát biểu chính tại hội nghị hàng năm ở Cupertino, California. Sự kiện sẽ giới thiệu các sản phẩm đổi mới bao gồm iPhone mới và các bản cập nhật phần mềm mang tính cách mạng. Các chuyên gia ngành phấn khích về tác động tiềm năng đến thị trường công nghệ trên toàn thế giới. \u0026#34;\u0026#34;\u0026#34; results = analyzer.analyze(sample_article) print(\u0026#34;=== Kết quả phân tích văn bản ===\\n\u0026#34;) print(f\u0026#34;Số từ: {results[\u0026#39;số_từ\u0026#39;]}\u0026#34;) print(f\u0026#34;Số câu: {results[\u0026#39;số_câu\u0026#39;]}\u0026#34;) print(\u0026#34;\\nThực thể được đặt tên:\u0026#34;) for entity, label in results[\u0026#39;thực_thể\u0026#39;]: print(f\u0026#34; {entity} ({label})\u0026#34;) print(f\u0026#34;\\nCảm xúc:\u0026#34;) print(f\u0026#34; Polarity: {results[\u0026#39;cảm_xúc\u0026#39;][\u0026#39;polarity\u0026#39;]:.2f}\u0026#34;) print(f\u0026#34; Subjectivity: {results[\u0026#39;cảm_xúc\u0026#39;][\u0026#39;subjectivity\u0026#39;]:.2f}\u0026#34;) print(\u0026#34;\\nTừ khóa hàng đầu:\u0026#34;) for word, count in results[\u0026#39;từ_khóa_hàng_đầu\u0026#39;]: print(f\u0026#34; {word}: {count}\u0026#34;) Bài tập thực hành Xây dựng bộ phân loại bài báo cho các danh mục khác nhau Tạo chatbot FAQ cho một lĩnh vực cụ thể Triển khai công cụ tóm tắt văn bản Xây dựng hệ thống trích xuất từ khóa Tạo dashboard phân tích cảm xúc hoàn chỉnh Tóm tắt tuần 8 Tuần này bao gồm:\nKiến thức cơ bản về NLP và tiền xử lý văn bản Tiền xử lý nâng cao (stemming, lemmatization) Phân tích văn bản và phân tích cảm xúc Nhận dạng thực thể được đặt tên với spaCy Xây dựng ứng dụng NLP thực tế Kỹ năng đã đạt được:\nQuy trình tiền xử lý văn bản Triển khai phân tích cảm xúc Trích xuất và phân loại thực thể Xây dựng mô hình phân loại văn bản Phát triển chatbot đơn giản "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.9-week9/1.9.5-day45-2025-11-07/","title":"Ngày 45 - Tích hợp NLP &amp; Dự án cuối cùng","tags":[],"description":"","content":"Ngày: 2025-11-07\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú bài giảng Tóm tắt Tuần 9 Các khái niệm được đề cập trong tuần này Ngày 41: Ôn tập kiến thức cơ bản NLP - tokenization, quy trình tiền xử lý Ngày 42: Phân loại văn bản nâng cao - phương pháp ensemble, dữ liệu mất cân bằng Ngày 43: Phân tích cảm xúc production - dựa trên khía cạnh, phát hiện cảm xúc, APIs Ngày 44: NER nâng cao - huấn luyện tùy chỉnh, entity linking, trích xuất quan hệ Ngày 45: Tích hợp \u0026amp; hệ thống NLP hoàn chỉnh Những điều học được chính Xây dựng hệ thống NLP sẵn sàng production đòi hỏi nhiều hơn mô hình tốt Tích hợp nhiều thành phần NLP tạo ra ứng dụng mạnh mẽ Giám sát, đánh giá và cải tiến liên tục là thiết yếu Thích ứng lĩnh vực quan trọng cho hiệu suất thực tế Tích hợp các thành phần NLP Quy trình đa thành phần Đầu vào văn bản → Tiền xử lý → Phân loại → NER → Cảm xúc → Đầu ra Lợi ích của tích hợp:\nAPI đơn cho nhiều tác vụ NLP Tiền xử lý chung giảm tính toán Xử lý lỗi nhất quán trên các thành phần Bảo trì và cập nhật dễ dàng hơn Các mẫu thiết kế Mẫu Pipeline\nXử lý văn bản tuần tự qua nhiều giai đoạn Mỗi giai đoạn có thể được phát triển và kiểm tra độc lập Dễ dàng thêm/xóa giai đoạn Mẫu Microservices\nMỗi tác vụ NLP là dịch vụ riêng biệt Có thể mở rộng và triển khai độc lập Giao tiếp qua REST API hoặc message queues Mẫu Monolithic\nTất cả tác vụ NLP trong một ứng dụng Triển khai đơn giản hơn Phù hợp cho ứng dụng nhỏ hơn Xây dựng ứng dụng NLP hoàn chỉnh Phân tích yêu cầu Yêu cầu chức năng:\nCần những tác vụ NLP nào? Độ chính xác chấp nhận được là bao nhiêu? Xử lý thời gian thực hay hàng loạt? Định dạng đầu vào/đầu ra? Yêu cầu phi chức năng:\nHiệu suất (độ trễ, thông lượng) Khả năng mở rộng (người dùng đồng thời, khối lượng dữ liệu) Độ tin cậy (thời gian hoạt động, tỷ lệ lỗi) Bảo mật (quyền riêng tư dữ liệu, xác thực) Kiến trúc hệ thống Các lớp:\nLớp API: REST/GraphQL endpoints, xác thực yêu cầu Lớp Business Logic: Điều phối quy trình NLP Lớp Processing: Các thành phần NLP riêng lẻ Lớp Data: Lưu trữ mô hình, caching, logging Thực hành tốt nhất Tổ chức code Tách biệt mối quan tâm: tiền xử lý, mô hình, API, utilities Quản lý cấu hình (biến môi trường, config files) Dependency injection cho tính linh hoạt Quy ước đặt tên rõ ràng Chiến lược kiểm thử Unit tests cho các thành phần riêng lẻ Integration tests cho pipelines End-to-end tests cho quy trình hoàn chỉnh Performance/load testing Triển khai Containerization (Docker) cho tính nhất quán CI/CD pipelines cho triển khai tự động Blue-green hoặc canary deployments cho an toàn Health checks và monitoring Những hiểu biết quan trọng Bắt đầu đơn giản, lặp lại dựa trên sử dụng thực tế Log mọi thứ để debug và cải thiện Lên kế hoạch cho lỗi - xử lý graceful Vòng lặp phản hồi người dùng thiết yếu cho cải thiện Tài liệu quan trọng không kém code Thực hành Lab Lab 1: Quy trình NLP đa thành phần import spacy from textblob import TextBlob from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.naive_bayes import MultinomialNB import pickle class ComprehensiveNLPPipeline: \u0026#34;\u0026#34;\u0026#34;Quy trình NLP tích hợp với nhiều thành phần\u0026#34;\u0026#34;\u0026#34; def __init__(self): # Tải mô hình self.nlp = spacy.load(\u0026#34;en_core_web_sm\u0026#34;) # Khởi tạo thành phần self.vectorizer = TfidfVectorizer(max_features=100) self.classifier = MultinomialNB() # Huấn luyện classifier đơn giản (trong production, tải đã huấn luyện trước) sample_texts = [\u0026#34;đánh giá sản phẩm công nghệ\u0026#34;, \u0026#34;bài báo tin tức chính trị\u0026#34;, \u0026#34;tóm tắt trận đấu thể thao\u0026#34;] * 10 sample_labels = [\u0026#34;công nghệ\u0026#34;, \u0026#34;chính trị\u0026#34;, \u0026#34;thể thao\u0026#34;] * 10 X = self.vectorizer.fit_transform(sample_texts) self.classifier.fit(X, sample_labels) def preprocess(self, text): \u0026#34;\u0026#34;\u0026#34;Làm sạch và chuẩn hóa văn bản\u0026#34;\u0026#34;\u0026#34; # Chữ thường text = text.lower() # Loại bỏ khoảng trắng thừa text = \u0026#39; \u0026#39;.join(text.split()) return text def extract_entities(self, text): \u0026#34;\u0026#34;\u0026#34;Trích xuất thực thể được đặt tên\u0026#34;\u0026#34;\u0026#34; doc = self.nlp(text) entities = [ { \u0026#39;văn_bản\u0026#39;: ent.text, \u0026#39;nhãn\u0026#39;: ent.label_, \u0026#39;bắt_đầu\u0026#39;: ent.start_char, \u0026#39;kết_thúc\u0026#39;: ent.end_char } for ent in doc.ents ] return entities def classify_text(self, text): \u0026#34;\u0026#34;\u0026#34;Phân loại văn bản vào danh mục\u0026#34;\u0026#34;\u0026#34; X = self.vectorizer.transform([text]) category = self.classifier.predict(X)[0] probabilities = self.classifier.predict_proba(X)[0] confidence = max(probabilities) return category, confidence def analyze_sentiment(self, text): \u0026#34;\u0026#34;\u0026#34;Phân tích cảm xúc\u0026#34;\u0026#34;\u0026#34; blob = TextBlob(text) polarity = blob.sentiment.polarity if polarity \u0026gt; 0.1: sentiment = \u0026#34;tích_cực\u0026#34; elif polarity \u0026lt; -0.1: sentiment = \u0026#34;tiêu_cực\u0026#34; else: sentiment = \u0026#34;trung_tính\u0026#34; return sentiment, polarity def extract_keywords(self, text, top_n=5): \u0026#34;\u0026#34;\u0026#34;Trích xuất các từ khóa\u0026#34;\u0026#34;\u0026#34; doc = self.nlp(text) # Lấy noun phrases và từ quan trọng keywords = [] for chunk in doc.noun_chunks: keywords.append(chunk.text) # Lấy named entities làm keywords for ent in doc.ents: keywords.append(ent.text) # Loại bỏ trùng lặp và trả về top N keywords = list(set(keywords)) return keywords[:top_n] def analyze(self, text): \u0026#34;\u0026#34;\u0026#34;Quy trình phân tích hoàn chỉnh\u0026#34;\u0026#34;\u0026#34; # Tiền xử lý clean_text = self.preprocess(text) # Chạy tất cả phân tích entities = self.extract_entities(clean_text) category, confidence = self.classify_text(clean_text) sentiment, polarity = self.analyze_sentiment(clean_text) keywords = self.extract_keywords(clean_text) return { \u0026#39;văn_bản_gốc\u0026#39;: text, \u0026#39;văn_bản_đã_xử_lý\u0026#39;: clean_text, \u0026#39;danh_mục\u0026#39;: category, \u0026#39;độ_tin_cậy_danh_mục\u0026#39;: round(confidence, 3), \u0026#39;cảm_xúc\u0026#39;: sentiment, \u0026#39;polarity_cảm_xúc\u0026#39;: round(polarity, 3), \u0026#39;thực_thể\u0026#39;: entities, \u0026#39;từ_khóa\u0026#39;: keywords } # Kiểm tra quy trình toàn diện pipeline = ComprehensiveNLPPipeline() test_text = \u0026#34;\u0026#34;\u0026#34; Apple Inc. công bố iPhone 15 mới hôm nay tại Cupertino, California. CEO Tim Cook ca ngợi các tính năng đổi mới và hiệu suất xuất sắc. Sản phẩm nhận được đánh giá tích cực áp đảo từ các nhà báo công nghệ. \u0026#34;\u0026#34;\u0026#34; result = pipeline.analyze(test_text) print(\u0026#34;=== Phân tích NLP toàn diện ===\\n\u0026#34;) print(f\u0026#34;Văn bản gốc: {result[\u0026#39;văn_bản_gốc\u0026#39;]}\\n\u0026#34;) print(f\u0026#34;Danh mục: {result[\u0026#39;danh_mục\u0026#39;]} (tin cậy: {result[\u0026#39;độ_tin_cậy_danh_mục\u0026#39;]})\u0026#34;) print(f\u0026#34;Cảm xúc: {result[\u0026#39;cảm_xúc\u0026#39;]} (polarity: {result[\u0026#39;polarity_cảm_xúc\u0026#39;]})\u0026#34;) print(f\u0026#34;\\nThực thể:\u0026#34;) for ent in result[\u0026#39;thực_thể\u0026#39;]: print(f\u0026#34; - {ent[\u0026#39;văn_bản\u0026#39;]} ({ent[\u0026#39;nhãn\u0026#39;]})\u0026#34;) print(f\u0026#34;\\nTừ khóa: {\u0026#39;, \u0026#39;.join(result[\u0026#39;từ_khóa\u0026#39;])}\u0026#34;) Lab 2: RESTful NLP API với xử lý lỗi from fastapi import FastAPI, HTTPException, Request from fastapi.responses import JSONResponse from pydantic import BaseModel, validator from datetime import datetime import logging import time # Cấu hình logging logging.basicConfig(level=logging.INFO) logger = logging.getLogger(__name__) app = FastAPI( title=\u0026#34;API NLP toàn diện\u0026#34;, description=\u0026#34;Dịch vụ phân tích NLP đa thành phần\u0026#34;, version=\u0026#34;1.0.0\u0026#34; ) # Khởi tạo pipeline nlp_pipeline = ComprehensiveNLPPipeline() class AnalysisRequest(BaseModel): text: str include_entities: bool = True include_sentiment: bool = True include_classification: bool = True include_keywords: bool = True @validator(\u0026#39;text\u0026#39;) def validate_text(cls, v): if not v or len(v.strip()) == 0: raise ValueError(\u0026#39;Văn bản không thể trống\u0026#39;) if len(v) \u0026gt; 10000: raise ValueError(\u0026#39;Văn bản quá dài (tối đa 10000 ký tự)\u0026#39;) return v class AnalysisResponse(BaseModel): text: str category: str = None category_confidence: float = None sentiment: str = None sentiment_polarity: float = None entities: list = [] keywords: list = [] processing_time: float timestamp: str # Middleware cho logging @app.middleware(\u0026#34;http\u0026#34;) async def log_requests(request: Request, call_next): start_time = time.time() # Log yêu cầu logger.info(f\u0026#34;Yêu cầu: {request.method} {request.url.path}\u0026#34;) # Xử lý yêu cầu response = await call_next(request) # Log phản hồi process_time = time.time() - start_time logger.info(f\u0026#34;Hoàn thành trong {process_time:.2f}s với trạng thái {response.status_code}\u0026#34;) return response @app.exception_handler(Exception) async def global_exception_handler(request: Request, exc: Exception): logger.error(f\u0026#34;Ngoại lệ không xử lý: {exc}\u0026#34;) return JSONResponse( status_code=500, content={ \u0026#34;error\u0026#34;: \u0026#34;Lỗi máy chủ nội bộ\u0026#34;, \u0026#34;message\u0026#34;: str(exc), \u0026#34;timestamp\u0026#34;: datetime.utcnow().isoformat() } ) @app.post(\u0026#34;/analyze\u0026#34;, response_model=AnalysisResponse) async def analyze_text(request: AnalysisRequest): \u0026#34;\u0026#34;\u0026#34;Phân tích văn bản toàn diện\u0026#34;\u0026#34;\u0026#34; try: start_time = time.time() # Chạy phân tích result = nlp_pipeline.analyze(request.text) # Xây dựng phản hồi dựa trên các thành phần được yêu cầu response_data = { \u0026#39;text\u0026#39;: request.text, \u0026#39;processing_time\u0026#39;: time.time() - start_time, \u0026#39;timestamp\u0026#39;: datetime.utcnow().isoformat() + \u0026#34;Z\u0026#34; } if request.include_classification: response_data[\u0026#39;category\u0026#39;] = result[\u0026#39;danh_mục\u0026#39;] response_data[\u0026#39;category_confidence\u0026#39;] = result[\u0026#39;độ_tin_cậy_danh_mục\u0026#39;] if request.include_sentiment: response_data[\u0026#39;sentiment\u0026#39;] = result[\u0026#39;cảm_xúc\u0026#39;] response_data[\u0026#39;sentiment_polarity\u0026#39;] = result[\u0026#39;polarity_cảm_xúc\u0026#39;] if request.include_entities: response_data[\u0026#39;entities\u0026#39;] = result[\u0026#39;thực_thể\u0026#39;] if request.include_keywords: response_data[\u0026#39;keywords\u0026#39;] = result[\u0026#39;từ_khóa\u0026#39;] return response_data except Exception as e: logger.error(f\u0026#34;Phân tích thất bại: {e}\u0026#34;) raise HTTPException(status_code=500, detail=f\u0026#34;Phân tích thất bại: {str(e)}\u0026#34;) @app.get(\u0026#34;/health\u0026#34;) async def health_check(): \u0026#34;\u0026#34;\u0026#34;Endpoint kiểm tra sức khỏe\u0026#34;\u0026#34;\u0026#34; return { \u0026#34;status\u0026#34;: \u0026#34;healthy\u0026#34;, \u0026#34;timestamp\u0026#34;: datetime.utcnow().isoformat(), \u0026#34;components\u0026#34;: { \u0026#34;spacy\u0026#34;: \u0026#34;đã tải\u0026#34;, \u0026#34;classifier\u0026#34;: \u0026#34;sẵn sàng\u0026#34;, \u0026#34;sentiment\u0026#34;: \u0026#34;sẵn sàng\u0026#34; } } @app.get(\u0026#34;/metrics\u0026#34;) async def get_metrics(): \u0026#34;\u0026#34;\u0026#34;Số liệu hệ thống\u0026#34;\u0026#34;\u0026#34; return { \u0026#34;timestamp\u0026#34;: datetime.utcnow().isoformat(), \u0026#34;uptime\u0026#34;: \u0026#34;có sẵn\u0026#34;, \u0026#34;requests_processed\u0026#34;: \u0026#34;được theo dõi trong production\u0026#34; } # Chạy: uvicorn script_name:app --reload Lab 3-5: [Giống như phiên bản tiếng Anh với các thông báo và nhận xét bằng tiếng Việt] Bài tập thực hành Xây dựng dịch vụ NLP hoàn chỉnh với triển khai Docker Tạo hệ thống hỗ trợ đa ngôn ngữ Triển khai caching để cải thiện hiệu suất Xây dựng dashboard giám sát cho số liệu NLP Tạo tài liệu toàn diện và hướng dẫn người dùng Tóm tắt Tuần 9 Các chủ đề được đề cập Ngày 41: Ôn tập kiến thức cơ bản NLP và tokenization nâng cao Ngày 42: Phân loại văn bản nâng cao với phương pháp ensemble Ngày 43: Hệ thống phân tích cảm xúc production Ngày 44: Huấn luyện NER tùy chỉnh và entity linking Ngày 45: Tích hợp hệ thống NLP hoàn chỉnh Kỹ năng đã đạt được Hiểu sâu về kỹ thuật tiền xử lý NLP\nXây dựng hệ thống phân loại sẵn sàng production\nTriển khai phân tích cảm xúc đa thành phần\nHuấn luyện mô hình NER tùy chỉnh cho các lĩnh vực cụ thể\nTích hợp các thành phần NLP thành hệ thống liền mạch\nThiết kế API và thực hành triển khai tốt nhất\nTối ưu hóa hiệu suất và giám sát\nThành tựu chính Nắm vững vòng đời phát triển NLP hoàn chỉnh Xây dựng ứng dụng NLP sẵn sàng production Tích hợp nhiều thành phần NLP hiệu quả Triển khai xử lý lỗi và giám sát mạnh mẽ Tạo chiến lược kiểm thử toàn diện "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.10-week10/1.10.5-day50-2025-11-14/","title":"Ngày 50 - Kiểm thử, Triển khai &amp; Hoàn thành dự án","tags":[],"description":"","content":"Ngày: 2025-11-14\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nGhi chú bài giảng Chiến lược kiểm thử Cách tiếp cận kiểm thử Frontend Unit Testing:\nKiểm thử các components riêng lẻ Mock API calls và dependencies bên ngoài Tập trung vào business logic và tương tác người dùng Công cụ: Jest, React Testing Library Integration Testing:\nKiểm thử tương tác components và luồng dữ liệu Xác thực tích hợp API với mock servers Kiểm thử luồng xác thực end-to-end Công cụ: Cypress, Playwright E2E Testing:\nMô phỏng quy trình người dùng thực tế Kiểm thử các đường dẫn quan trọng (upload, approve, read) Xác thực hành vi môi trường production Công cụ: Cypress E2E, manual QA Checklist kiểm thử Luồng xác thực:\n✓ Người dùng có thể đăng ký với email ✓ Xác thực email hoạt động chính xác ✓ Người dùng có thể đăng nhập và nhận JWT ✓ Protected routes chuyển hướng đến login ✓ Phát hiện vai trò admin hoạt động ✓ Token refresh tự động diễn ra Luồng Upload:\n✓ Xác thực file (size, type) hoạt động ✓ Tạo Presigned URL thành công ✓ Upload trực tiếp S3 với theo dõi tiến trình ✓ Cập nhật trạng thái chính xác (PENDING → VALIDATING) ✓ Xử lý lỗi cho uploads thất bại Duyệt Admin:\n✓ Chỉ admins có thể truy cập trang duyệt ✓ Danh sách sách pending hiển thị chính xác ✓ Hành động duyệt di chuyển file và cập nhật status ✓ Hành động từ chối cập nhật status với lý do ✓ Audit logs ghi lại tất cả hành động Trải nghiệm đọc:\n✓ Danh sách sách chỉ hiển thị sách đã duyệt ✓ Chức năng tìm kiếm trả kết quả chính xác ✓ Tạo Signed URL hoạt động ✓ PDF/ePub render chính xác trong reader ✓ Xử lý hết hạn URL một cách graceful Quy trình triển khai Checklist trước triển khai Chất lượng Code:\nTất cả lỗi TypeScript đã được giải quyết Cảnh báo ESLint đã được xử lý Build thành công không lỗi Không có console.log trong production Biến môi trường:\nTất cả env vars cần thiết đã set trong Amplify Console Endpoint API production đã cấu hình Cognito User Pool IDs chính xác CloudFront distribution ID đã set Kiểm tra bảo mật:\nS3 bucket policies hạn chế truy cập công khai CloudFront OAC cấu hình đúng API Gateway JWT validation bật CORS cấu hình chỉ cho production domain Triển khai Amplify Triển khai tự động:\nGitHub push (main branch) → Amplify webhook triggers → Install dependencies → Build Next.js app → Deploy to CDN → Live tại custom domain Cài đặt Build:\nNode.js version chỉ định (18.x) Build commands cấu hình Environment variables được inject Output directory set chính xác Xác minh sau triển khai:\nSite tải thành công SSL certificate hoạt động Tất cả routes có thể truy cập API calls hoạt động Xác thực chức năng Tối ưu hiệu suất Tối ưu Frontend Code Splitting:\nLazy load các components nặng (PDF reader, ePub viewer) Dynamic imports cho admin pages Route-based code splitting Tối ưu Image:\nNext.js Image component cho bìa sách Lazy loading images below fold Format WebP với fallbacks Chiến lược Caching:\nReact Query caching cho API responses Service worker cho offline capability (tương lai) LocalStorage cho user preferences Thiết lập giám sát Tích hợp CloudWatch:\nFrontend error tracking qua CloudWatch RUM API Gateway access logs Lambda execution logs Custom metrics cho key actions Số liệu hiệu suất:\nTheo dõi page load time Giám sát API response time Tỷ lệ thành công/thất bại upload Số liệu engagement người dùng Những hiểu biết quan trọng Kiểm thử toàn diện phát hiện vấn đề trước khi người dùng gặp phải CI/CD tự động giảm ma sát triển khai và lỗi con người Tối ưu hiệu suất là liên tục - giám sát và lặp lại Phản hồi người dùng sau launch vô giá cho ưu tiên cải thiện Documentation thiết yếu cho onboarding và maintenance Công việc đã hoàn thành Unit Testing\nViết tests cho authentication components Kiểm thử logic validation form upload Tạo tests cho API client methods Kiểm thử custom hooks (useUser, useUpload) Integration Testing\nThiết lập Cypress test suite Viết E2E tests cho auth flow Tạo tests cho upload workflow Kiểm thử quy trình duyệt admin Sửa lỗi\nSửa vấn đề thời gian refresh token Giải quyết độ chính xác tiến trình upload file Sửa kiểm tra quyền admin panel Chỉnh sửa render PDF trên mobile Tối ưu hiệu suất\nTriển khai code splitting cho reader components Thêm React Query caching với stale-while-revalidate Tối ưu image loading với Next.js Image Giảm bundle size 30% Triển khai Production\nCấu hình Amplify build settings Set tất cả environment variables trong Amplify Console Triển khai lên production domain Xác minh SSL certificate và HTTPS Thiết lập giám sát\nBật CloudWatch RUM cho frontend errors Cấu hình CloudWatch alarms cho critical metrics Thiết lập API Gateway logging Tạo CloudWatch dashboard để giám sát Documentation\nCập nhật README với hướng dẫn thiết lập Ghi chép API endpoints và contracts Tạo hướng dẫn người dùng cho uploaders Viết manual admin cho quy trình duyệt Thách thức \u0026amp; Giải pháp Thách thức: Cypress tests thất bại trong CI/CD pipeline\nGiải pháp: Cấu hình base URL phù hợp và thêm retry logic cho tests phụ thuộc network\nThách thức: Build thất bại do vấn đề environment variable\nGiải pháp: Sử dụng prefix NEXT_PUBLIC_ cho client-side env vars và ghi chép tất cả variables cần thiết\nThách thức: Render PDF gây vấn đề memory trên mobile\nGiải pháp: Triển khai page-by-page rendering và vô hiệu hóa pre-caching trên mobile devices\nThách thức: Race condition giữa token refresh và API calls\nGiải pháp: Triển khai request queue đợi token refresh trước khi tiếp tục\nTóm tắt Tuần 10 Trạng thái hoàn thành dự án Xác thực \u0026amp; Quản lý người dùng\nTích hợp Cognito với Amplify UI Xác thực dựa trên JWT Kiểm soát truy cập dựa trên vai trò (User vs Admin) Protected routes và authorization Luồng Upload\nXác thực file và tạo presigned URL Upload trực tiếp S3 với theo dõi tiến trình Theo dõi trạng thái (PENDING, VALIDATING, APPROVED, REJECTED) Lịch sử upload của người dùng Quy trình duyệt Admin\nTruy cập chỉ admin vào giao diện duyệt Xem xét sách pending với preview Duyệt/từ chối với audit logging Hệ thống status badge và notification Giao diện đọc sách\nTrang chi tiết sách với metadata Tạo Signed URL cho truy cập an toàn Render PDF và ePub Chế độ đọc fullscreen Tìm kiếm \u0026amp; Khám phá\nTìm kiếm theo tiêu đề và tác giả sử dụng DynamoDB GSI Tùy chọn lọc và sắp xếp Duyệt tất cả sách đã duyệt Đề xuất sách liên quan Kiểm thử \u0026amp; Đảm bảo chất lượng\nUnit tests cho các components quan trọng Integration tests cho quy trình chính E2E tests với Cypress Sửa lỗi và xử lý errors Triển khai\nCI/CD với Amplify Hosting Môi trường production đã cấu hình Custom domain với SSL Thiết lập giám sát và logging Thành tựu kỹ thuật Kiến trúc Serverless: Xây dựng hoàn toàn trên AWS managed services Tiết kiệm chi phí: Ước tính $9.80/tháng cho MVP (100 users) An toàn: Presigned URLs, CloudFront OAC, JWT authentication Có thể mở rộng: Xử lý 5,000-50,000 users với thay đổi tối thiểu Stack hiện đại: Next.js 14, TypeScript, TailwindCSS, React Query Bài học kinh nghiệm Bắt đầu với vertical slices - Xây dựng từng feature cho phép feedback nhanh hơn Bảo mật trước tiên - Triển khai presigned URLs và OAC sớm ngăn lỗ hổng Kiểm thử liên tục - Automated tests phát hiện vấn đề trước production Giám sát mọi thứ - Tích hợp CloudWatch thiết yếu cho troubleshooting Ghi chép khi xây dựng - Documentation tiết kiệm thời gian khi testing và deployment Các bước tiếp theo (Cải tiến tương lai) Triển khai bookmark và theo dõi tiến trình đọc Thêm categories sách và lọc nâng cao Xây dựng hệ thống recommendation dựa trên lịch sử đọc Thêm tính năng commenting và rating Triển khai batch upload cho admins Thêm analytics dashboard cho thống kê sử dụng Phiên bản mobile app (React Native) Dự án Thư viện Online hoàn thành thành công!\nTổng thời gian phát triển: 2 tuần (Ngày 46-50)\nDòng code: ~5,000+ frontend + backend configurations\nTính năng đã phát hành: 15+ tính năng user-facing\nDịch vụ AWS sử dụng: 10 dịch vụ (Amplify, Cognito, API Gateway, Lambda, S3, CloudFront, DynamoDB, Route 53, CloudWatch, CodePipeline)\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/5-workshop/5.5-module5/","title":"Quản lý mật khẩu","tags":[],"description":"","content":"Quy trình quên mật khẩu Tạo file src/components/ForgotPassword.js:\nimport { Auth } from \u0026#39;aws-amplify\u0026#39;; import { useState } from \u0026#39;react\u0026#39;; function ForgotPassword() { const [email, setEmail] = useState(\u0026#39;\u0026#39;); const [code, setCode] = useState(\u0026#39;\u0026#39;); const [newPassword, setNewPassword] = useState(\u0026#39;\u0026#39;); const [step, setStep] = useState(\u0026#39;request\u0026#39;); const handleRequestReset = async (e) =\u0026gt; { e.preventDefault(); try { await Auth.forgotPassword(email); setStep(\u0026#39;reset\u0026#39;); alert(\u0026#39;Mã xác thực đã được gửi đến email của bạn\u0026#39;); } catch (error) { console.error(\u0026#39;Lỗi:\u0026#39;, error); alert(error.message); } }; const handleResetPassword = async (e) =\u0026gt; { e.preventDefault(); try { await Auth.forgotPasswordSubmit(email, code, newPassword); alert(\u0026#39;Đặt lại mật khẩu thành công!\u0026#39;); setStep(\u0026#39;complete\u0026#39;); } catch (error) { console.error(\u0026#39;Lỗi:\u0026#39;, error); alert(error.message); } }; if (step === \u0026#39;request\u0026#39;) { return ( \u0026lt;form onSubmit={handleRequestReset}\u0026gt; \u0026lt;h2\u0026gt;Quên mật khẩu\u0026lt;/h2\u0026gt; \u0026lt;input type=\u0026#34;email\u0026#34; value={email} onChange={(e) =\u0026gt; setEmail(e.target.value)} placeholder=\u0026#34;Email\u0026#34; required /\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;Gửi mã\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; ); } if (step === \u0026#39;reset\u0026#39;) { return ( \u0026lt;form onSubmit={handleResetPassword}\u0026gt; \u0026lt;h2\u0026gt;Đặt lại mật khẩu\u0026lt;/h2\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; value={code} onChange={(e) =\u0026gt; setCode(e.target.value)} placeholder=\u0026#34;Mã xác thực\u0026#34; required /\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; value={newPassword} onChange={(e) =\u0026gt; setNewPassword(e.target.value)} placeholder=\u0026#34;Mật khẩu mới\u0026#34; required /\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;Đặt lại mật khẩu\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; ); } return \u0026lt;div\u0026gt;Đặt lại mật khẩu hoàn tất! \u0026lt;a href=\u0026#34;/login\u0026#34;\u0026gt;Đi đến Đăng nhập\u0026lt;/a\u0026gt;\u0026lt;/div\u0026gt;; } export default ForgotPassword; Đổi mật khẩu Tạo file src/components/ChangePassword.js:\nimport { Auth } from \u0026#39;aws-amplify\u0026#39;; import { useState } from \u0026#39;react\u0026#39;; function ChangePassword() { const [oldPassword, setOldPassword] = useState(\u0026#39;\u0026#39;); const [newPassword, setNewPassword] = useState(\u0026#39;\u0026#39;); const handleChangePassword = async (e) =\u0026gt; { e.preventDefault(); try { const user = await Auth.currentAuthenticatedUser(); await Auth.changePassword(user, oldPassword, newPassword); alert(\u0026#39;Đổi mật khẩu thành công!\u0026#39;); setOldPassword(\u0026#39;\u0026#39;); setNewPassword(\u0026#39;\u0026#39;); } catch (error) { console.error(\u0026#39;Lỗi:\u0026#39;, error); alert(error.message); } }; return ( \u0026lt;form onSubmit={handleChangePassword}\u0026gt; \u0026lt;h2\u0026gt;Đổi mật khẩu\u0026lt;/h2\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; value={oldPassword} onChange={(e) =\u0026gt; setOldPassword(e.target.value)} placeholder=\u0026#34;Mật khẩu hiện tại\u0026#34; required /\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; value={newPassword} onChange={(e) =\u0026gt; setNewPassword(e.target.value)} placeholder=\u0026#34;Mật khẩu mới\u0026#34; required /\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;Đổi mật khẩu\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; ); } export default ChangePassword; Chính sách mật khẩu Cấu hình yêu cầu mật khẩu trong Amplify:\namplify update auth # Chọn: Walkthrough all the auth configurations # Password policy: Custom # Minimum length: 8 # Require lowercase: Yes # Require uppercase: Yes # Require numbers: Yes # Require symbols: Yes Triển khai thay đổi:\namplify push Xác thực mật khẩu Thêm xác thực phía client:\nconst validatePassword = (password) =\u0026gt; { const minLength = 8; const hasUpperCase = /[A-Z]/.test(password); const hasLowerCase = /[a-z]/.test(password); const hasNumbers = /\\d/.test(password); const hasSymbols = /[!@#$%^\u0026amp;*(),.?\u0026#34;:{}|\u0026lt;\u0026gt;]/.test(password); if (password.length \u0026lt; minLength) { return \u0026#39;Mật khẩu phải có ít nhất 8 ký tự\u0026#39;; } if (!hasUpperCase) { return \u0026#39;Mật khẩu phải chứa chữ in hoa\u0026#39;; } if (!hasLowerCase) { return \u0026#39;Mật khẩu phải chứa chữ thường\u0026#39;; } if (!hasNumbers) { return \u0026#39;Mật khẩu phải chứa số\u0026#39;; } if (!hasSymbols) { return \u0026#39;Mật khẩu phải chứa ký tự đặc biệt\u0026#39;; } return null; }; "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.5-week5/","title":"Tuần 5 - Bảo mật &amp; Danh tính trên AWS","tags":[],"description":"","content":"Tuần: 2025-10-06 đến 2025-10-10\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 5 Tuần này tập trung vào bảo mật và quản lý danh tính trên AWS.\nNội dung chính Mô hình Trách nhiệm chia sẻ. AWS IAM (Users, Groups, Roles, Policies). Amazon Cognito. AWS Organizations \u0026amp; SCPs. AWS Identity Center (SSO). AWS KMS. AWS Security Hub. Labs thực hành Lab 18: AWS Security Hub. Lab 22: AWS Lambda Automation with Slack. Lab 27: AWS Resource Groups \u0026amp; Tagging. Lab 28: IAM Cross-Region Role \u0026amp; Policy. Lab 30: IAM Restriction Policy. Lab 33: AWS KMS \u0026amp; CloudTrail Integration. Lab 44: IAM Advanced Role Control. Lab 48: IAM Access Keys \u0026amp; Roles. "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Xác thực: AWS Amplify \u0026amp; Amazon Cognito Tổng quan Workshop thực hành giới thiệu các nguyên tắc cơ bản về xác thực người dùng với AWS Amplify và Amazon Cognito. Người tham gia xây dựng hệ thống xác thực hoàn chỉnh bao gồm đăng ký người dùng, xác minh email, đăng nhập/đăng xuất, quản lý mật khẩu, xác thực đa yếu tố (MFA), và đăng nhập mạng xã hội. Tập trung vào triển khai xác thực an toàn nhanh chóng mà không cần quản lý hạ tầng, tuân theo các best practices của AWS.\nNội dung chương trình Nền tảng xác thực: tại sao chọn Amplify \u0026amp; Cognito, best practices bảo mật, các trường hợp sử dụng. Bắt đầu: cài đặt Amplify CLI, khởi tạo ứng dụng React, thêm danh mục xác thực. Đăng ký người dùng: xây dựng quy trình đăng ký, xác minh email, thuộc tính tùy chỉnh, chính sách mật khẩu. Đăng nhập \u0026amp; phiên làm việc: triển khai xác thực, xử lý JWT tokens, quản lý phiên người dùng, đăng xuất đúng cách. Quản lý mật khẩu: quy trình quên mật khẩu, đặt lại mật khẩu, thay đổi mật khẩu, yêu cầu bảo mật. Tính năng nâng cao: kích hoạt MFA (TOTP), thêm đăng nhập mạng xã hội (Google/Facebook), nhóm người dùng \u0026amp; vai trò. Triển khai: host với Amplify Hosting, cấu hình CI/CD, tên miền tùy chỉnh, giám sát. Những gì bạn sẽ xây dựng Ứng dụng React với giao diện xác thực hoàn chỉnh (đăng ký, đăng nhập, hồ sơ). Amazon Cognito User Pool với xác minh email và chính sách mật khẩu tùy chỉnh. Xác thực đa yếu tố sử dụng TOTP (Time-based One-Time Password). Tích hợp đăng nhập mạng xã hội với Google và Facebook. Routes được bảo vệ với kiểm soát truy cập dựa trên vai trò (RBAC). Yêu cầu Tài khoản AWS có quyền truy cập console. Node.js 18+ và npm đã cài đặt. Hiểu biết cơ bản về JavaScript/React. Amplify CLI đã cài đặt (npm install -g @aws-amplify/cli). Tài liệu tham khảo Các bước cấu hình Amplify CLI Hướng dẫn thiết lập Cognito User Pool Tích hợp nhà cung cấp danh tính mạng xã hội Danh sách kiểm tra dọn dẹp "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong thời gian thực tập tại [Tên công ty/tổ chức] từ [ngày bắt đầu] đến [ngày kết thúc], em đã có cơ hội học hỏi, thực hành và ứng dụng kiến thức đã học vào môi trường thực tế. Em tham gia [mô tả ngắn gọn dự án/công việc] và cải thiện kỹ năng về [liệt kê kỹ năng: lập trình, phân tích, báo cáo, giao tiếp, v.v.].\nVề thái độ làm việc, em luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ quy định và tích cực tương tác với đồng nghiệp.\nĐể có cái nhìn khách quan về giai đoạn thực tập, em tự đánh giá dựa trên các tiêu chí sau:\nSTT Tiêu chí Mô tả Tốt Khá TB 1 Kiến thức \u0026amp; kỹ năng chuyên môn Hiểu biết lĩnh vực, vận dụng thực tế, thành thạo công cụ, chất lượng công việc ✔️ 2 Khả năng học hỏi Tiếp thu kiến thức mới và học nhanh ✔️ 3 Tính chủ động Chủ động tìm kiếm việc, không chờ chỉ dẫn ✔️ 4 Ý thức trách nhiệm Hoàn thành đúng hạn, đảm bảo chất lượng ✔️ 5 Tính kỷ luật Tuân thủ lịch trình, quy tắc làm việc ✔️ 6 Tinh thần cầu tiến Sẵn sàng nhận phản hồi và cải thiện ✔️ 7 Giao tiếp Trình bày ý tưởng và báo cáo rõ ràng ✔️ 8 Làm việc nhóm Hiệu quả với đồng nghiệp, tham gia nhóm ✔️ 9 Thái độ nghề nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường ✔️ 10 Kỹ năng giải quyết vấn đề Nhận diện, đề xuất giải pháp, sáng tạo ✔️ 11 Đóng góp cho dự án/nhóm Hiệu quả, ý tưởng mới, được ghi nhận ✔️ 12 Tổng thể Đánh giá chung giai đoạn thực tập ✔️ Các điểm cần cải thiện Kỹ năng chuyên môn (TB):\nTăng cường chuyên môn qua khóa học và chứng chỉ Áp dụng kiến thức vào tình huống phức tạp hơn Tính chủ động (TB):\nChủ động hơn trong xác định cơ hội Tình nguyện đảm nhận thêm trách nhiệm Khả năng học (Khá):\nPhát triển chiến lược học hiệu quả Tìm kiếm dự án thách thức Tinh thần cầu tiến (Khá):\nCởi mở với phản hồi xây dựng Tìm kiếm góp ý từ đồng nghiệp Giao tiếp (Khá):\nNâng cao độ rõ ràng khi trình bày Cải thiện kỹ năng viết tài liệu Giải quyết vấn đề (Khá):\nTăng cường tư duy phân tích Phát triển cách tiếp cận sáng tạo Đóng góp nhóm (Khá):\nTăng chất lượng deliverable Đóng góp ý tưởng sáng tạo hơn Kế hoạch hành động Để cải thiện, em cam kết:\nDành thời gian hàng tuần phát triển kỹ năng Tìm kiếm cố vấn từ đồng nghiệp senior Đặt mục tiêu cụ thể, đo lường được Thường xuyên phản ánh và điều chỉnh Tích cực tham gia thảo luận với giải pháp "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/5-workshop/5.6-module6/","title":"Tính năng nâng cao &amp; Dọn dẹp","tags":[],"description":"","content":"Xác thực đa yếu tố (MFA) Kích hoạt MFA dựa trên TOTP:\namplify update auth # Chọn: Walkthrough all the auth configurations # MFA: Optional # MFA type: TOTP (Time-based One-Time Password) amplify push Triển khai MFA trong ứng dụng:\nimport { Auth } from \u0026#39;aws-amplify\u0026#39;; // Thiết lập MFA cho người dùng async function setupMFA() { try { const user = await Auth.currentAuthenticatedUser(); const code = await Auth.setupTOTP(user); // Hiển thị mã QR cho người dùng const qrCodeUrl = `otpauth://totp/AWSCognito:${user.username}?secret=${code}\u0026amp;issuer=AuthWorkshop`; console.log(\u0026#39;QR Code URL:\u0026#39;, qrCodeUrl); // Xác thực token TOTP const token = prompt(\u0026#39;Nhập mã TOTP từ ứng dụng xác thực:\u0026#39;); await Auth.verifyTotpToken(user, token); await Auth.setPreferredMFA(user, \u0026#39;TOTP\u0026#39;); alert(\u0026#39;Kích hoạt MFA thành công!\u0026#39;); } catch (error) { console.error(\u0026#39;Lỗi thiết lập MFA:\u0026#39;, error); } } Đăng nhập mạng xã hội Thêm xác thực Google/Facebook:\namplify update auth # Chọn: Walkthrough all the auth configurations # Social providers: Google, Facebook # Làm theo hướng dẫn để cấu hình OAuth amplify push Thêm nút đăng nhập mạng xã hội:\nimport { Auth } from \u0026#39;aws-amplify\u0026#39;; function SocialLogin() { const handleGoogleLogin = () =\u0026gt; { Auth.federatedSignIn({ provider: \u0026#39;Google\u0026#39; }); }; const handleFacebookLogin = () =\u0026gt; { Auth.federatedSignIn({ provider: \u0026#39;Facebook\u0026#39; }); }; return ( \u0026lt;div\u0026gt; \u0026lt;button onClick={handleGoogleLogin}\u0026gt;Đăng nhập với Google\u0026lt;/button\u0026gt; \u0026lt;button onClick={handleFacebookLogin}\u0026gt;Đăng nhập với Facebook\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; ); } Nhóm người dùng \u0026amp; Vai trò Tạo nhóm người dùng trong Cognito console:\nTruy cập Cognito User Pools Chọn user pool của bạn Điều hướng đến \u0026ldquo;Users and groups\u0026rdquo; \u0026ldquo;Groups\u0026rdquo; Tạo nhóm: Admin, User Gán người dùng vào nhóm qua code:\n// Code phía server (Lambda) const AWS = require(\u0026#39;aws-sdk\u0026#39;); const cognito = new AWS.CognitoIdentityServiceProvider(); async function addUserToGroup(username, groupName, userPoolId) { const params = { GroupName: groupName, UserPoolId: userPoolId, Username: username }; await cognito.adminAddUserToGroup(params).promise(); } Triển khai lên Amplify Hosting Triển khai ứng dụng React:\namplify add hosting # Chọn: Amplify Console # Type: Manual deployment amplify publish Ứng dụng của bạn sẽ được triển khai lên URL trực tiếp.\nDọn dẹp tài nguyên Xóa tất cả tài nguyên AWS:\n# Xóa backend Amplify amplify delete # Xác nhận xóa # Lệnh này sẽ xóa: # - Cognito User Pool # - Tất cả tài nguyên xác thực # - CloudFormation stacks Xóa file local:\n# Xóa file dự án Amplify Remove-Item -Recurse -Force amplify Remove-Item -Force aws-exports.js Tối ưu chi phí Cognito User Pools: Gói miễn phí hỗ trợ 50,000 MAUs (Người dùng hoạt động hàng tháng) Amplify Hosting: Phút build và truyền dữ liệu có giới hạn gói miễn phí Thực hành tốt nhất: Luôn xóa tài nguyên không sử dụng Chúc mừng! Bạn đã hoàn thành Workshop Xác thực bao gồm:\nĐăng ký người dùng và xác thực email Đăng nhập và quản lý phiên Quy trình đặt lại mật khẩu MFA với TOTP Xác thực mạng xã hội Nhóm người dùng và vai trò Triển khai production "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.6-week6/","title":"Week 6 - AWS Database Services","tags":[],"description":"","content":" ⚠️ Bản dịch tiếng Việt đang được cập nhật. Vui lòng xem nội dung chi tiết trong file _index.md (tiếng Anh).\nNội dung tiếng Việt sẽ được bổ sung sớm để phản ánh đầy đủ các ghi chú và bài lab.\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/7-feedback/","title":"Chia sẻ và Góp ý","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên FCJ luôn sẵn sàng giúp đỡ khi em gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái giúp em tập trung tốt hơn.\n2. Sự hỗ trợ từ Mentor / Team Admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi em chưa hiểu và luôn khuyến khích đặt câu hỏi. Team admin hỗ trợ công việc hành chính, cung cấp tài liệu cần thiết và tạo điều kiện thuận lợi. Em đặc biệt đánh giá cao việc mentor cho em tự thử và giải quyết vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp công việc với chuyên ngành\nCông việc được giao phù hợp với kiến thức đã học, đồng thời giới thiệu những lĩnh vực mới chưa từng tiếp xúc. Điều này giúp em vừa củng cố nền tảng vừa có thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, em học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm và giao tiếp chuyên nghiệp trong môi trường doanh nghiệp. Mentor cũng chia sẻ kinh nghiệm thực tế giúp em định hướng nghề nghiệp tốt hơn.\n5. Văn hóa công ty \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau làm và hỗ trợ không phân biệt vị trí. Điều này khiến em cảm thấy như thành viên thực sự dù chỉ là thực tập sinh.\n6. Chính sách / quyền lợi thực tập\nCông ty cung cấp trợ cấp thực tập và cho phép linh hoạt giờ làm khi cần. Ngoài ra, được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nCâu hỏi bổ sung Điều em thấy hài lòng nhất trong thời gian thực tập?\nEm hài lòng nhất với môi trường học hỏi cởi mở và sự hướng dẫn tận tâm từ mentor. Việc được làm việc với dự án thực tế và nhận feedback chi tiết giúp em tiến bộ rất nhiều. Đặc biệt, văn hóa khuyến khích đặt câu hỏi và thử nghiệm giúp em tự tin phát triển kỹ năng.\nNếu giới thiệu cho bạn bè, bạn có gợi ý họ thực tập ở đây không? Tại sao?\nEm chắc chắn sẽ giới thiệu bạn bè thực tập ở đây. Lý do chính là môi trường học hỏi thực tế và đội ngũ nhiệt tình. Thực tập sinh không chỉ làm công việc đơn giản mà được tham gia dự án thực tế, nhận hướng dẫn chi tiết và có cơ hội phát triển kỹ năng chuyên môn lẫn soft skills. Đây là nơi lý tưởng cho những ai muốn học hỏi và phát triển nghiêm túc.\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.7-week7/","title":"Week 7 - Vertical Slice Delivery","tags":[],"description":"","content":" ⚠️ Bản dịch tiếng Việt đang được cập nhật. Vui lòng xem nội dung chi tiết trong file _index.md (tiếng Anh).\nNội dung tiếng Việt sẽ được bổ sung sớm để phản ánh đầy đủ các ghi chú và bài lab.\n"},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.8-week8/","title":"Tuần 8 - Học xử lý ngôn ngữ tự nhiên","tags":[],"description":"","content":"Tuần: 27/10/2025 đến 31/10/2025\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 8 Tuần này tập trung vào việc học xử lý ngôn ngữ tự nhiên (NLP)\nChủ đề chính Giới thiệu về NLP: Hiểu NLP là gì và ứng dụng của nó trong các tình huống thực tế Tiền xử lý văn bản: Học tokenization, stemming, lemmatization và loại bỏ stop word Phân tích văn bản cơ bản: Khám phá tần suất từ, n-grams và thống kê văn bản đơn giản Phân tích cảm xúc: Giới thiệu về phân tích cảm xúc và ý kiến trong dữ liệu văn bản Nhận dạng thực thể được đặt tên (NER): Xác định và phân loại các thực thể như tên, địa điểm và tổ chức Thư viện NLP phổ biến: Bắt đầu với NLTK, spaCy và các ví dụ sử dụng cơ bản Dự án NLP đơn giản: Xây dựng một bộ phân loại văn bản hoặc chatbot cơ bản như bài tập thực hành "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.9-week9/","title":"Tuần 9 - Ôn tập NLP &amp; Khái niệm nâng cao","tags":[],"description":"","content":"Tuần: 03/11/2025 đến 07/11/2025\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 9 Tuần này tập trung vào ôn tập các khái niệm Xử lý Ngôn ngữ Tự nhiên từ Tuần 8 và khám phá các ứng dụng nâng cao.\nChủ đề chính Ôn tập kiến thức cơ bản NLP: Xem lại các khái niệm cốt lõi bao gồm tokenization, kỹ thuật tiền xử lý và chuẩn hóa văn bản Phân loại văn bản chuyên sâu: Các kỹ thuật nâng cao cho phân loại tài liệu và kỹ thuật đặc trưng Ứng dụng phân tích cảm xúc: Xây dựng hệ thống phân tích cảm xúc sẵn sàng production Kỹ thuật NER nâng cao: Huấn luyện thực thể tùy chỉnh và nhận dạng thực thể đặc thù lĩnh vực Tích hợp quy trình NLP: Kết hợp nhiều thành phần NLP thành hệ thống liền mạch Dự án NLP thực tế: Xây dựng ứng dụng end-to-end bao gồm chatbots và công cụ phân tích văn bản Tối ưu hóa hiệu suất: Cải thiện tốc độ và độ chính xác của mô hình NLP "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/1-worklog/1.10-week10/","title":"Tuần 10 - Hoàn thành dự án Thư viện Online (Frontend)","tags":[],"description":"","content":"Tuần: 10/11/2025 đến 14/11/2025\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 10 Tuần này tập trung vào hoàn thành triển khai frontend Thư viện Online, tích hợp với các dịch vụ AWS và hoàn thiện ứng dụng serverless.\nChủ đề chính Tích hợp xác thực: Triển khai đăng nhập, đăng ký và quản lý người dùng dựa trên Cognito với Amplify UI Phát triển luồng Upload: Xây dựng giao diện tải sách lên với S3 presigned URLs và theo dõi trạng thái thời gian thực Tạo bảng điều khiển Admin: Phát triển quy trình duyệt admin, quản lý sách và các tính năng kiểm duyệt Giao diện đọc sách: Triển khai trải nghiệm đọc sách với CloudFront signed URLs và render PDF Tìm kiếm \u0026amp; Khám phá: Xây dựng chức năng tìm kiếm sử dụng DynamoDB GSI và tối ưu trải nghiệm người dùng Kiểm thử \u0026amp; Triển khai: Kiểm thử tích hợp cuối cùng, sửa lỗi và triển khai production qua Amplify CI/CD Tối ưu hiệu suất: Triển khai chiến lược caching và tối ưu thời gian tải "},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://anquoc211.github.io/AWS_Internship/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]